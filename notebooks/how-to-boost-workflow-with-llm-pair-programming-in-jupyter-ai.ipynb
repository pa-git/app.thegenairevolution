{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** How to Boost Workflow with LLM Pair Programming in Jupyter AI\n\n**Description:** Install Jupyter AI, configure LLM providers, leverage %ai/%%ai to write Python, debug faster, and accelerate data science notebooks dramatically today.\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Jupyter AI is a JupyterLab extension that brings LLM\\-powered code generation and debugging directly into your notebook cells. Instead of switching to a browser or IDE plugin, you can ask an LLM to scaffold functions, explain errors, or refactor code without leaving your analysis environment. This tutorial shows you how to install Jupyter AI, configure a provider, and use %ai and %%ai magics to generate, debug, and refine Python code in a reproducible notebook workflow.\n\n## Prerequisites\n\nBefore you begin, make sure you have:\n\n* Python 3\\.8 or later installed locally\n* JupyterLab 3\\.x or Jupyter Notebook 7\\.x. Jupyter AI does not support Google Colab.\n* An API key for at least one supported provider. OpenAI, Anthropic, Google, or Mistral.\n* Basic familiarity with Jupyter notebooks and Python\n\n## Install Jupyter AI and Dependencies\n\nJupyter AI works with JupyterLab 3\\.x and Notebook 7\\.x. Run the following in a terminal to install the magics and common data science dependencies. If you use JupyterLab and want the chat UI, install the optional package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create or activate your environment first if needed\n\n# Core magics and helpful packages\npip install --upgrade pip\npip install jupyter-ai-magics python-dotenv pandas matplotlib\n\n# Optional. Install the JupyterLab chat UI extension if you use JupyterLab.\npip install jupyter-ai\n\n# Optional. Install provider SDKs so you can use their latest models.\n# Install only what you plan to use.\npip install openai anthropic google-generativeai mistralai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After installation, launch JupyterLab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "jupyter lab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Open a new notebook to continue.\n\n## Configure API Keys Securely\n\nJupyter AI reads provider API keys from environment variables. Create a .env file in your project directory and add your keys:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# .env\nOPENAI_API_KEY=your_openai_key_here\nANTHROPIC_API_KEY=your_anthropic_key_here\nGOOGLE_API_KEY=your_google_key_here\nMISTRAL_API_KEY=your_mistral_key_here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the keys at the start of your notebook using the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n_ = load_dotenv()  # Loads variables from .env into the environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This ensures your keys are available before loading the Jupyter AI extension.\n\n## Load Jupyter AI Magics\n\nLoad the Jupyter AI extension to enable %ai and %%ai magics in your notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext jupyter_ai_magics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verify the extension is active by running a simple query:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%ai openai/gpt-4o-mini Say hello in one short sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the extension is loaded correctly, you will see a response from the model.\n\n## Define a Default Model\n\nSet a default model identifier to avoid repeating it in every magic call. You can create a Python variable and interpolate it in prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pick a model you have access to.\n# Examples: \"openai/gpt-4o-mini\", \"anthropic/claude-3-5-sonnet\", \"google/gemini-1.5-pro\", \"mistral/mistral-large\"\nDEFAULT_MODEL = \"openai/gpt-4o-mini\"\nDEFAULT_MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can now use {DEFAULT\\_MODEL} in your prompts for consistency.\n\n## Generate a Data Cleaning Function\n\nUse the %%ai cell magic to generate a function that cleans a pandas DataFrame. The magic must be the first line of the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%ai {DEFAULT_MODEL}\nYou are a Python expert. Write a function named clean_dataframe(df, inplace=False) that performs these steps:\n- Strip whitespace from column names.\n- Drop exact duplicate rows.\n- Trim leading and trailing whitespace in string columns.\n- Convert obvious numeric-like columns to numeric where safe.\n- Fill missing values in numeric columns with the column median.\n- If inplace is True, modify df in place and return df. Otherwise, return a new cleaned DataFrame.\nReturn only valid Python code for the function definition. Do not include any extra text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copy the generated function into a new cell and execute it to make it available in your notebook.\n\n## Refine the Function with Additional Requirements\n\nAsk the model to add error handling and inplace modification support:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%ai {DEFAULT_MODEL}\nYou previously wrote clean_dataframe(df, inplace=False).\nRefine it with:\n- Defensive checks for non-DataFrame inputs. Raise a clear TypeError.\n- More careful numeric conversion using errors='ignore'.\n- A parameter columns_to_trim that accepts a list of column names to trim. Default trims all string columns.\n- Docstring with args, returns, and examples.\nReturn only the updated Python function definition. No extra commentary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copy and run the updated function to replace the previous version.\n\n## Use Prompt Interpolation for Context\\-Aware Code\n\nPrompt interpolation lets you embed live data, error traces, or schema details directly into your %%ai prompts. This gives the model richer context for more accurate code generation. To master this technique and understand its impact on LLM accuracy, check out our explainer on the magic of in\\-context learning.\n\nLoad a sample dataset and pass its schema to the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\nimport numpy as np\n\n# Create a small, reproducible dataset\nrng = np.random.default_rng(42)\ndf = pd.DataFrame({\n    \"total_bill\": rng.normal(20, 8, 200).round(2),\n    \"tip\": rng.normal(3, 1, 200).round(2),\n    \"size\": rng.integers(1, 6, 200)\n}).clip(lower=0)\n\nschema = df.dtypes.to_string()\nschema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate a transformation function using the schema as context:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%ai {DEFAULT_MODEL}\nYou are given this pandas DataFrame schema:\n{schema}\n\nWrite a function transform_data(df) that:\n- Adds a tip_pct column as tip / total_bill. Handle division by zero safely.\n- Buckets size into small (1-2), medium (3-4), large (5+).\n- Returns a new DataFrame with the new columns.\nReturn only valid Python code for the function definition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copy the generated function into a new cell and run it to apply the transformation.\n\n## Debug Errors with AI Assistance\n\nIntroduce a deliberate error to demonstrate debugging:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Deliberate typo in the column name to trigger a KeyError\nbad_df = df.copy()\nbad_df[\"tip_pct\"] = bad_df[\"tip\"] / bad_df[\"total_billl\"]  # incorrect column name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pass the traceback to the model for a fix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import traceback\n\ntry:\n    # Re-run to capture the traceback\n    bad_df[\"tip_pct\"] = bad_df[\"tip\"] / bad_df[\"total_billl\"]\nexcept Exception:\n    error_trace = traceback.format_exc()\n\nerror_trace[:600]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%ai {DEFAULT_MODEL}\nYou are a Python debugging assistant.\nHere is the traceback:\n{error_trace}\n\nGiven this code that caused the error:\nbad_df[\"tip_pct\"] = bad_df[\"tip\"] / bad_df[\"total_billl\"]\n\nExplain the root cause in one sentence, then provide a single corrected line of code.\nReturn only the fixed line of Python code without extra text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apply the suggested fix and validate the result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply the correct code. If the model suggested something equivalent, use that suggestion.\nbad_df[\"tip_pct\"] = bad_df[\"tip\"] / bad_df[\"total_bill\"]\n\n# Quick validation\nbad_df[\"tip_pct\"].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate a Plotting Helper\n\nUse the model to scaffold a reusable plotting function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%ai {DEFAULT_MODEL}\nWrite a function plot_histogram(df, column, bins=30, title=None, figsize=(6, 4)):\n- Use matplotlib only.\n- Validate inputs and raise a ValueError if column is missing or non-numeric.\n- Show grid lines and a tight layout.\n- Return the matplotlib Axes object.\nReturn only valid Python code for the function definition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copy the function into a new cell and run it to visualize the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nax = plot_histogram(df, \"total_bill\", bins=25, title=\"Total Bill\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validate Generated Code\n\nAfter generating a function, add minimal sanity checks to ensure correctness:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sanity checks for clean_dataframe\nimport inspect\nassert \"clean_dataframe\" in globals() and inspect.isfunction(clean_dataframe)\n\ntoy = pd.DataFrame({\"A\": [1, 1, None], \"B\": [\" x \", \" y\", \" z \"]})\nout = clean_dataframe(toy)\nassert isinstance(out, pd.DataFrame)\nassert \"A\" in out.columns and \"B\" in out.columns\nassert out.shape[0] <= toy.shape[0]\nprint(\"clean_dataframe sanity checks passed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These checks catch common issues and help you trust the generated code.\n\n## Handle Provider Errors Gracefully\n\nAPI calls may fail due to rate limits or invalid keys. Wrap magic calls in a try\\-except block to handle errors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython import get_ipython\n\ntry:\n    body = \"Reply with 'ok' if you received this request.\"\n    get_ipython().run_cell_magic(\"ai\", DEFAULT_MODEL, body)\nexcept Exception as e:\n    import logging, time\n    logging.exception(\"AI request failed\")\n    # Simple retry strategy\n    time.sleep(1.5)\n    try:\n        get_ipython().run_cell_magic(\"ai\", DEFAULT_MODEL, body)\n    except Exception as e2:\n        logging.exception(\"Second attempt failed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For production workflows, log errors and retry with exponential backoff.\n\n## Avoid Leaking Sensitive Data\n\nWhen interpolating data into prompts, redact or truncate sensitive columns to prevent PII leakage:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def safe_sample(df, cols_to_redact=None, max_rows=5, truncate=4):\n    \"\"\"\n    Return a safe preview of df for prompts.\n    Redact specified columns and truncate long strings.\n    \"\"\"\n    import pandas as pd\n\n    preview = df.sample(min(len(df), max_rows), random_state=42).copy()\n    if cols_to_redact:\n        for c in cols_to_redact:\n            if c in preview.columns:\n                preview[c] = \"[REDACTED]\"\n    # Truncate long string values\n    def _truncate(x):\n        if isinstance(x, str) and len(x) > truncate:\n            return x[:truncate] + \"...\"\n        return x\n    return preview.applymap(_truncate)\n\n# Example usage\nsafe_preview = safe_sample(df, cols_to_redact=[\"email\", \"ssn\"] if {\"email\", \"ssn\"}.issubset(df.columns) else [], max_rows=5)\nsafe_preview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use safe\\_sample instead of the full dataset in your prompts.\n\n## End\\-to\\-End Runnable Example\n\nHere is a complete, minimal workflow you can run from top to bottom:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Environment and setup\nfrom dotenv import load_dotenv\n_ = load_dotenv()\n\n%load_ext jupyter_ai_magics\n\nimport pandas as pd\nimport numpy as np\n\n# Choose a model you have access to\nDEFAULT_MODEL = \"openai/gpt-4o-mini\"\n\n# Create a simple dataset\nrng = np.random.default_rng(0)\ndf = pd.DataFrame({\n    \"total_bill\": rng.normal(20, 7, 120).round(2),\n    \"tip\": rng.normal(3, 1, 120).round(2),\n    \"size\": rng.integers(1, 6, 120)\n}).clip(lower=0)\n\ndf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate a cleaning function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%ai {DEFAULT_MODEL}\nWrite a function clean_dataframe(df, inplace=False) that:\n- Validates df is a pandas DataFrame.\n- Strips whitespace from column names.\n- Drops duplicate rows.\n- Trims whitespace in string columns.\n- Converts numeric-like columns with errors='ignore'.\n- Fills NaNs in numeric columns with the column median.\n- If inplace is True, modify df in place. Otherwise, return a new DataFrame.\nReturn only valid Python code for the function definition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copy the function, run it, and validate:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage after you paste the generated function\ncleaned = clean_dataframe(df)\ncleaned.info()\n\n# Basic checks\nassert not cleaned.isna().sum().sum()\nassert cleaned.shape[0] <= df.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate a plot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%ai {DEFAULT_MODEL}\nWrite a function plot_histogram(df, column, bins=30, title=None, figsize=(6, 4)):\n- Use matplotlib to plot a histogram of df[column].\n- Validate the column exists and is numeric.\n- Label axes and add a title if provided.\n- Return the Axes object.\nReturn only valid Python code for the function definition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copy the function and run it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nax = plot_histogram(cleaned, \"total_bill\", bins=25, title=\"Total Bill Distribution\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n\nWhen using %ai and %%ai magics, the quality of your prompt directly impacts the usefulness of the generated code or explanations. For a deeper understanding of how to design prompts that yield reliable and accurate outputs, see our guide on prompt engineering with LLM APIs.\n\nIf you want to expand your skills beyond this workflow and become more proficient in AI\\-assisted development, our practical roadmap for aspiring GenAI developers outlines the essential skills and projects to accelerate your growth in this field."
      ]
    }
  ],
  "metadata": {
    "title": "How to Boost Workflow with LLM Pair Programming in Jupyter AI",
    "description": "Install Jupyter AI, configure LLM providers, leverage %ai/%%ai to write Python, debug faster, and accelerate data science notebooks dramatically today.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}