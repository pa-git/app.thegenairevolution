{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** How to Boost Workflow with LLM Pair Programming in Jupyter AI\n\n**Description:** Install Jupyter AI, configure LLM providers, leverage %ai/%%ai to write Python, debug faster, and accelerate data science notebooks dramatically today.\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Jupyter AI is a JupyterLab extension that brings LLM-powered code generation and debugging directly into your notebook cells. Instead of switching to a browser or IDE plugin, you can ask an LLM to scaffold functions, explain errors, or refactor code without leaving your analysis environment. This tutorial shows AI Builders how to install Jupyter AI, configure a provider, and use `%ai` and `%%ai` magics to generate, debug, and refine Python code in a reproducible notebook workflow.\n\n## Prerequisites\n\nBefore you begin, ensure you have:\n\n- Python 3.8 or later installed locally\n- JupyterLab 3.x or Jupyter Notebook 7.x (Jupyter AI does not support Google Colab)\n- An API key for at least one supported provider (OpenAI, Anthropic, Google, or Mistral)\n- Basic familiarity with Jupyter notebooks and Python\n\n## Install Jupyter AI and Dependencies\n\nJupyter AI requires JupyterLab or Notebook 7. Run the following in a terminal to install the extension and required packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install jupyter-ai jupyterlab python-dotenv pandas numpy matplotlib seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After installation, launch JupyterLab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "jupyter lab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Open a new notebook to continue.\n\n## Configure API Keys Securely\n\nJupyter AI reads provider API keys from environment variables. Create a `.env` file in your project directory and add your keys:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "OPENAI_API_KEY=sk-...\nANTHROPIC_API_KEY=sk-ant-..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the keys at the start of your notebook using the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\nimport os\n\nload_dotenv()\n\nrequired_keys = [\"OPENAI_API_KEY\", \"ANTHROPIC_API_KEY\"]\nmissing = [k for k in required_keys if not os.getenv(k)]\n\nif missing:\n    raise EnvironmentError(f\"Missing API keys: {', '.join(missing)}. Add them to your .env file.\")\n\nprint(\"API keys loaded successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This ensures your keys are available before loading the Jupyter AI extension.\n\n## Load Jupyter AI Magics\n\nLoad the Jupyter AI extension to enable `%ai` and `%%ai` magics in your notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext jupyter_ai\n%load_ext jupyter_ai_magics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verify the extension is active by running a simple query:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%ai openai:gpt-4o-mini What is 2 + 2?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the extension is loaded correctly, you will see a response from the model.\n\n## Define a Default Model\n\nSet a default model identifier to avoid repeating it in every magic call:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DEFAULT_MODEL = \"openai:gpt-4o-mini\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can now use `{DEFAULT_MODEL}` in your prompts for consistency.\n\n## Generate a Data Cleaning Function\n\nUse the `%%ai` cell magic to generate a function that cleans a pandas DataFrame. The magic must be the first line of the cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%ai {DEFAULT_MODEL}\nYou are a Python data assistant. Output only valid Python code.\n\nWrite a function clean_users(df: \"pandas.DataFrame\") that:\n- strips whitespace from string columns\n- lowercases column names\n- removes exact duplicate rows\n- ensures a 'signup_date' column is datetime, errors='coerce'\nInclude a concise docstring and type hints. Do not import pandas inside the function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copy the generated function into a new cell and execute it to make it available in your notebook.\n\n## Refine the Function with Additional Requirements\n\nAsk the model to add error handling and inplace modification support:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%ai {DEFAULT_MODEL}\nTake the previous clean_users function design. Output only valid Python code.\n\n- Add parameter strict: bool. If strict, raise ValueError when required columns ['signup_date'] are missing.\n- Add parameter inplace: bool. If True, modify df in place and return df.\n- Keep type hints and docstring."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copy and run the updated function to replace the previous version.\n\n## Use Prompt Interpolation for Context-Aware Code\n\nPrompt interpolation lets you embed live data, error traces, or schema details directly into your `%%ai` prompts, giving the model richer context for more accurate code generation. To master this technique and understand its impact on LLM accuracy, check out our explainer on [the magic of in-context learning](/article/the-magic-of-in-context-learning-teach-your-llm-on-the-fly-3).\n\nLoad a sample dataset and pass its schema to the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\nimport seaborn as sns\n\ntips = sns.load_dataset(\"tips\")\nschema = tips.dtypes.to_string()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate a transformation function using the schema as context:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%ai {DEFAULT_MODEL}\nYou are assisting with pandas code. Output only code. No explanations.\n\nDataset info:\nSchema:\n{schema}\n\nTask:\n- Create a function transform_tips(df) that:\n  - computes total_bill_per_person = total_bill / (size if size > 0 else 1)\n  - returns a DataFrame with original columns plus the new column\n  - includes a short docstring and type hints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copy the generated function into a new cell and run it to apply the transformation.\n\n## Debug Errors with AI Assistance\n\nIntroduce a deliberate error to demonstrate debugging:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import traceback\n\nbroken = tips.copy()\ntry:\n    broken[\"tip_rate\"] = broken[\"tip\"] / broken[\"totalbill\"]\nexcept Exception:\n    error_text = traceback.format_exc()\n\nprint(error_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pass the traceback to the model for a fix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%ai {DEFAULT_MODEL} Explain this Python error and propose a minimal code fix that is safe for division by zero. Error: {error_text}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apply the suggested fix and validate the result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "broken[\"tip_rate\"] = broken[\"tip\"] / broken[\"total_bill\"].replace(0, pd.NA)\nbroken[\"tip_rate\"] = broken[\"tip_rate\"].fillna(0.0)\n\nassert broken[\"tip_rate\"].ge(0).all()\nassert broken[\"tip_rate\"].lt(1.0).mean() > 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate a Plotting Helper\n\nUse the model to scaffold a reusable plotting function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\n%%ai {DEFAULT_MODEL}\nOutput only code. Create a function plot_tip_rate(df) that draws a seaborn boxplot of tip as a percent of total_bill grouped by day. Add labels and a title. Do not load the dataset. Assume seaborn as sns and matplotlib.pyplot as plt are already imported."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copy the function into a new cell and run it to visualize the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_tip_rate(tips)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validate Generated Code\n\nAfter generating a function, add minimal sanity checks to ensure correctness:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tips_clean = clean_users(tips)\n\nassert \"signup_date\" in tips_clean.columns\nassert tips_clean.columns.str.islower().all()\nassert not tips_clean.duplicated().any()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These checks catch common issues and help you trust the generated code.\n\n## Handle Provider Errors Gracefully\n\nAPI calls may fail due to rate limits or invalid keys. Wrap magic calls in a try-except block to handle errors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n    %ai {DEFAULT_MODEL} Generate a summary of this dataset.\nexcept Exception as e:\n    print(f\"API call failed: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For production workflows, log errors and retry with exponential backoff.\n\n## Avoid Leaking Sensitive Data\n\nWhen interpolating data into prompts, redact or truncate sensitive columns to prevent PII leakage:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "safe_sample = tips[[\"total_bill\", \"tip\", \"day\"]].head(3).to_markdown(index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use `safe_sample` instead of the full dataset in your prompts.\n\n## End-to-End Runnable Example\n\nHere is a complete, minimal workflow you can run from top to bottom:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\nimport os\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nload_dotenv()\n\nrequired_keys = [\"OPENAI_API_KEY\"]\nmissing = [k for k in required_keys if not os.getenv(k)]\nif missing:\n    raise EnvironmentError(f\"Missing API keys: {', '.join(missing)}. Add them to your .env file.\")\n\n%load_ext jupyter_ai\n%load_ext jupyter_ai_magics\n\nDEFAULT_MODEL = \"openai:gpt-4o-mini\"\n\ntips = sns.load_dataset(\"tips\")\nschema = tips.dtypes.to_string()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate a cleaning function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%ai {DEFAULT_MODEL}\nOutput only code. Write a function clean_tips(df: \"pandas.DataFrame\") -> \"pandas.DataFrame\" that:\n- strips whitespace in object columns\n- coerces total_bill and tip to numeric with errors='coerce'\n- drops rows where total_bill or tip is null after coercion\n- returns a copy, do not modify in place\n- include a docstring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copy the function, run it, and validate:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tips_clean = clean_tips(tips)\nassert tips_clean[\"total_bill\"].dtype in [\"float64\", \"int64\"]\nassert tips_clean[\"tip\"].dtype in [\"float64\", \"int64\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate a plot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%ai {DEFAULT_MODEL}\nOutput only code. Write a function plot_tip_vs_total(df) that draws a scatter plot of total_bill vs tip with a regression line, colored by day, using seaborn. Add axis labels and a title. Assume imports exist and df is passed in."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copy the function and run it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_tip_vs_total(tips_clean)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n\nWhen using `%ai` and `%%ai` magics, the quality of your prompt directly impacts the usefulness of the generated code or explanations. For a deeper understanding of how to design prompts that yield reliable and accurate outputs, see our guide on [prompt engineering with LLM APIs](/article/prompt-engineering-with-llm-apis-how-to-get-reliable-outputs-4).\n\nIf you are looking to expand your skills beyond this workflow and become more proficient in AI-assisted development, our [practical roadmap for aspiring GenAI developers](/article/practical-roadmap-for-aspiring-genai-developers) outlines the essential skills and projects to accelerate your growth in this field."
      ]
    }
  ],
  "metadata": {
    "title": "How to Boost Workflow with LLM Pair Programming in Jupyter AI",
    "description": "Install Jupyter AI, configure LLM providers, leverage %ai/%%ai to write Python, debug faster, and accelerate data science notebooks dramatically today.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}