{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** How to Build Explainability AI by Design with OPA, MCP, and Neo4j\n\n**Description:** Build production-ready control layers for agent systems using OPA, MCP, and Neo4j. Enforce policies, capture auditable traces, and insert human approvals without slowing teams or shipping velocity.\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Full E2E prototype:\n\n* CrewAI agent\n* MCP enforcement server (FastAPI)\n* OPA ingress and egress policies\n* Small ML (spaCy) PII classifier\n* Human approval\n* Audit trail\n\n# Enterprise AI Agent. Full E2E in Colab\n\nUse this notebook to stand up a governed, auditable agent in Colab. You will run a CrewAI agent behind an MCP enforcement boundary. You will use OPA for policy decisions, a spaCy model for PII detection, and a human approval step. Each cell explains what it does and how it fits into the flow.\n\n## Cell 1\\. Install dependencies\n\nInstall the core packages for the runtime. This includes OPA tooling support, the FastAPI server for the MCP boundary, spaCy and its model for PII classification, and CrewAI for the agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install crewai fastapi uvicorn requests spacy\n!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 2\\. Download and start OPA. Binary and Colab safe\n\nFetch the OPA binary and prepare it to run in Colab. This gives you a local policy engine for both ingress and egress decisions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget https://openpolicyagent.org/downloads/latest/opa_linux_amd64 -O opa\n!chmod +x opa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create OPA folders:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir -p opa/policies opa/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 3\\. OPA tool catalog. Facts only\n\nDefine a static catalog of tools and capabilities that OPA will use as facts. This keeps policy checks deterministic. It also separates facts from decisions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile opa/data/tool_catalog.json\n{\n  \"tools\": {\n    \"initiate_refund\": {\n      \"risk_level\": \"high\",\n      \"data_classification\": \"financial\",\n      \"max_auto_amount\": 500,\n      \"approval_threshold\": 2000\n    }\n  }\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 4\\. OPA ingress policy. Tool access\n\nAuthorize which tools the agent can call. Use clear rules that reference the tool catalog. You can allow or deny access before any tool executes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile opa/policies/tool_access.rego\npackage tool_access\n\ndefault decision = \"deny\"\n\ntool := data.tools[input.tool.id]\n\ndecision = \"allow\" {\n  input.agent.role == \"support_agent\"\n  input.arguments.amount <= tool.max_auto_amount\n}\n\ndecision = \"require_approval\" {\n  input.agent.role == \"support_agent\"\n  input.arguments.amount > tool.max_auto_amount\n  input.arguments.amount <= tool.approval_threshold\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 5\\. OPA egress policy. PII control\n\nControl sensitive output before it leaves the boundary. The policy evaluates the ML classifier result and the approval state. It returns a safe, redacted decision when needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile opa/policies/egress_control.rego\npackage egress_control\n\ndefault action = \"block\"\n\n# No PII â†’ allow\naction = \"allow\" {\n  not input.egress.contains_pii\n}\n\n# PII present, not cleared â†’ redact\naction = \"redact\" {\n  input.egress.contains_pii\n  input.agent.clearance != \"pii_allowed\"\n}\n\n# PII present, cleared â†’ allow\naction = \"allow\" {\n  input.egress.contains_pii\n  input.agent.clearance == \"pii_allowed\"\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 6\\. Start OPA server. Background\n\nStart OPA in the background so you can query it from the client and the MCP server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!./opa run --server opa/policies opa/data &"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OPA now runs at <http://localhost:8181>\n\n## Cell 7\\. Audit logger\n\nCapture every decision and event in a single audit log. Include inputs, policy outcomes, redaction decisions, and timestamps. This gives you traceability across the entire flow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile audit.py\nimport json\nimport uuid\nfrom datetime import datetime\n\ndef audit_log(event: dict) -> str:\n    event[\"event_id\"] = event.get(\"event_id\") or str(uuid.uuid4())\n    event[\"timestamp\"] = datetime.utcnow().isoformat()\n    with open(\"audit.log\", \"a\", encoding=\"utf-8\") as f:\n        f.write(json.dumps(event) + \"\\n\")\n    return event[\"event_id\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 8\\. Approval store\n\nProvide a simple store to record human approvals. This lets the policy check whether a sensitive disclosure has been reviewed before it is released."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile approvals.py\nimport uuid\n\nPENDING_APPROVALS = {}\n\ndef create_approval(facts: dict) -> str:\n    token = str(uuid.uuid4())\n    PENDING_APPROVALS[token] = facts\n    return token\n\ndef consume_approval(token: str):\n    return PENDING_APPROVALS.pop(token, None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 9\\. OPA client\n\nCreate a lightweight client to send structured queries to OPA. Keep the input schema consistent. This ensures policies receive the data they need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile opa_client.py\nimport requests\n\nOPA = \"http://localhost:8181/v1/data\"\n\ndef tool_access_decision(facts: dict) -> str:\n    r = requests.post(f\"{OPA}/tool_access/decision\", json={\"input\": facts})\n    return r.json()[\"result\"]\n\ndef egress_action(facts: dict) -> str:\n    r = requests.post(f\"{OPA}/egress_control/action\", json={\"input\": facts})\n    return r.json()[\"result\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 10\\. Small ML PII classifier. spaCy, not regex\n\nUse a spaCy model to detect PII in tool outputs. This reduces reliance on fragile pattern matching. You can extend the model later with custom entities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile pii_classifier.py\nimport json\nimport spacy\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nLABEL_MAP = {\n    \"PERSON\": \"person_name\",\n    \"GPE\": \"location\",\n    \"LOC\": \"location\",\n    \"ORG\": \"organization\",\n    \"DATE\": \"date\"\n}\n\ndef classify_pii(result):\n    text = result if isinstance(result, str) else json.dumps(result, ensure_ascii=False)\n    doc = nlp(text)\n\n    findings = []\n    for ent in doc.ents:\n        if ent.label_ in LABEL_MAP:\n            findings.append({\n                \"type\": LABEL_MAP[ent.label_],\n                \"text\": ent.text\n            })\n\n    return {\n        \"contains_pii\": len(findings) > 0,\n        \"pii_types\": sorted({f[\"type\"] for f in findings}),\n        \"findings\": findings\n    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 11\\. Tool implementation. Returns PII internally\n\nImplement a sample tool that may return sensitive fields internally. The MCP boundary and policies will control what gets released to the agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile tools.py\ndef initiate_refund(customer_id: str, amount: int):\n    return {\n        \"status\": \"executed\",\n        \"customer_id\": customer_id,\n        \"message\": (\n            f\"Refund of ${amount} issued to customer {customer_id}. \"\n            f\"Contact: John Doe, Montreal.\"\n        )\n    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 12\\. MCP server. Enforcement boundary\n\nRun a FastAPI server that enforces ingress and egress decisions. The server calls tools, runs the ML classifier, applies OPA policies, and writes to the audit log."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile mcp_server.py\nfrom fastapi import FastAPI\nfrom audit import audit_log\nfrom approvals import create_approval\nfrom opa_client import tool_access_decision, egress_action\nfrom pii_classifier import classify_pii\nfrom tools import initiate_refund\n\napp = FastAPI()\n\ndef execute_tool(name, args):\n    if name == \"initiate_refund\":\n        return initiate_refund(**args)\n    raise ValueError(\"Unknown tool\")\n\n@app.post(\"/mcp/tool/{tool_name}\")\ndef call_tool(tool_name: str, payload: dict):\n    facts = {\n        \"agent\": payload[\"agent\"],\n        \"tool\": {\"id\": tool_name},\n        \"arguments\": payload[\"arguments\"],\n        \"environment\": payload.get(\"environment\", \"production\")\n    }\n\n    decision = tool_access_decision(facts)\n    event_id = audit_log({\n        \"phase\": \"access\",\n        \"agent\": facts[\"agent\"],\n        \"tool\": tool_name,\n        \"arguments\": facts[\"arguments\"],\n        \"decision\": decision\n    })\n    facts[\"event_id\"] = event_id\n\n    if decision == \"deny\":\n        return {\"error\": \"Denied by policy\"}\n\n    if decision == \"require_approval\":\n        token = create_approval(facts)\n        audit_log({\"event_id\": event_id, \"phase\": \"approval_requested\", \"token\": token})\n        return {\"status\": \"pending_approval\", \"approval_token\": token}\n\n    raw = execute_tool(tool_name, facts[\"arguments\"])\n    egress = classify_pii(raw)\n    facts[\"egress\"] = egress\n\n    action = egress_action(facts)\n    audit_log({\n        \"event_id\": event_id,\n        \"phase\": \"egress\",\n        \"action\": action,\n        \"egress\": egress\n    })\n\n    if action == \"allow\":\n        return raw\n    if action == \"redact\":\n        return {\"status\": \"redacted\", \"pii_types\": egress[\"pii_types\"]}\n    return {\"error\": \"Blocked by egress policy\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 13\\. Start MCP server. Background\n\nStart the MCP server in the background. The agent will call this server instead of calling tools directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!uvicorn mcp_server:app --port 3333 &"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 14\\. CrewAI tool\n\nExpose an MCP\\-backed tool to the agent. The agent interacts with the tool through the enforcement boundary. This keeps all calls governed and auditable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile crew_tools.py\nimport requests\nfrom crewai.tools import tool\n\nMCP = \"http://localhost:3333/mcp/tool/initiate_refund\"\n\n@tool(\"initiate_refund\")\ndef initiate_refund_tool(customer_id: str, amount: int):\n    payload = {\n        \"agent\": {\n            \"id\": \"agent-1\",\n            \"role\": \"support_agent\",\n            \"clearance\": \"no_pii\"\n        },\n        \"arguments\": {\n            \"customer_id\": customer_id,\n            \"amount\": amount\n        }\n    }\n    return requests.post(MCP, json=payload).json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 15\\. CrewAI agent execution\n\nRun the agent against the MCP tool. The pipeline will evaluate access, classify content, enforce policy, and return a safe response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from crewai import Agent, Task, Crew\nfrom crew_tools import initiate_refund_tool\n\nagent = Agent(\n    role=\"support_agent\",\n    goal=\"Handle refunds safely\",\n    tools=[initiate_refund_tool],\n    verbose=True\n)\n\ntask = Task(\n    description=\"Refund customer 123 for $250\",\n    agent=agent\n)\n\ncrew = Crew(agents=[agent], tasks=[task])\nprint(crew.kickoff())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What you should see\n\n* The tool executes internally\n* PII is detected by the ML classifier\n* The OPA egress policy fires to control disclosure\n* The agent receives a redacted response\n* audit.log contains a full decision trail\n\n## Final mental model\n\nReasoning, Enforcement, Classification, Policy, Audit. This is the end to end path your data and decisions follow. You now have a real, governed, auditable agent system running entirely in Colab."
      ]
    }
  ],
  "metadata": {
    "title": "How to Build Explainability AI by Design with OPA, MCP, and Neo4j",
    "description": "Build production-ready control layers for agent systems using OPA, MCP, and Neo4j. Enforce policies, capture auditable traces, and insert human approvals without slowing teams or shipping velocity.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}