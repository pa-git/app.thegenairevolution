{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** Structured Data Extraction with LLMs: How to Build a Pipeline\n\n**Description:** Build a reliable structured data extraction pipeline using LLMs, LangChain, and OpenAI functionsâ€”JSON schemas, deterministic outputs, zero hallucinations, for production.\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What You Will Build\n\nYou'll build an end-to-end extractor that converts unstructured text (feedback, reports, emails, webpages) into validated JSON objects. It uses OpenAI function calling, LangChain orchestration, and Pydantic validation to guarantee schema-conformant results, even at scale. If you want to avoid subtle bugs when processing text, be sure to review our guide on [tokenization pitfalls and invisible characters that break prompts and RAG](/article/tokenization-pitfalls-invisible-characters-that-break-prompts-and-rag-2).\n\n**Core build objective:** Extract events (name, date, outcome) from any text into a validated Pydantic schema, with no hallucinations or free-form responses.\n\n**What you'll learn:**\n- Schema-first extraction with Pydantic models\n- OpenAI function/tool binding for structured outputs\n- LangChain orchestration and output parsing\n- Test harness for extraction quality\n- Chunking strategy for long documents\n- Production readiness: retries, logging, deduplication\n\n**Prerequisites:**\n- Python 3.9+\n- OpenAI API key\n- Basic familiarity with LangChain and Pydantic\n\n---\n\n## Install Dependencies\n\nRun this cell to install all required packages with pinned versions for reproducibility:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install langchain==0.1.0 langchain-openai==0.0.2 langchain-community==0.0.10 pydantic==1.10.15 python-dotenv beautifulsoup4 requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Configure API Key\n\nSecurely load your OpenAI API key. This cell works in both local environments (via `.env` file) and Colab (via userdata):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: Load OpenAI API key from environment or Colab userdata for secure configuration.\n\nimport os\nfrom dotenv import load_dotenv\n\ntry:\n    from google.colab import userdata\nexcept ImportError:\n    userdata = None  # Not running in Colab\n\n# Load environment variables from .env file if present\nload_dotenv()\n\n# Fetch API key from Colab userdata if not set in environment\nif \"OPENAI_API_KEY\" not in os.environ and userdata is not None:\n    os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n\n# If still not set, prompt the user securely\nif \"OPENAI_API_KEY\" not in os.environ:\n    from getpass import getpass\n    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API Key: \")\n\nassert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY must be set to proceed\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Verify Model Connectivity\n\nConfirm your credentials and model availability with a simple deterministic test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: Confirm OpenAI credentials, model availability, and deterministic response.\n\nfrom langchain_openai import ChatOpenAI\n\n# Initialize the model with temperature=0 for more stable output\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\nresp = llm.invoke(\"Respond with the word OK only.\")\nprint(resp.content)  # Should print: \"OK\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Define the Extraction Schema\n\nCreate a Pydantic model to represent the structure of an event. This schema enforces explicit field types and optional values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: Represent an event with explicit fields for extraction.\n\nfrom typing import List, Optional\nfrom langchain_core.pydantic_v1 import BaseModel, Field\n\nclass Event(BaseModel):\n    \"\"\"\n    Represents a single event extracted from text.\n\n    Args:\n        name (str): The exact event name or label mentioned in the text.\n        date (Optional[str]): The explicit date string if present (e.g., 'June 15, 2024').\n        outcome (Optional[str]): The explicit outcome/result if stated (e.g., 'canceled', 'successful').\n    \"\"\"\n    name: str = Field(..., description=\"The exact event name or label mentioned in the text.\")\n    date: Optional[str] = Field(None, description=\"The explicit date string if present (e.g., 'June 15, 2024').\")\n    outcome: Optional[str] = Field(None, description=\"The explicit outcome/result if stated (e.g., 'canceled', 'successful').\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wrap the list of events in a container schema for validation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: Wrap a list of events for structured extraction and validation.\n\nclass Extracted(BaseModel):\n    \"\"\"\n    Container for all events extracted from a text.\n\n    Args:\n        events (List[Event]): All explicit events found in the text.\n    \"\"\"\n    events: List[Event] = Field(default_factory=list, description=\"All explicit events found in the text.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Build the Extraction Chain\n\nDefine a strict system prompt to prevent hallucinations and enforce extraction discipline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: Instruct the model to extract only explicit information, no inference.\n\nSYSTEM_PROMPT = \"\"\"You are an information extraction engine.\nExtract only what is explicitly stated in the input text.\nDo not infer or assume missing information.\nIf no explicit events exist, return an empty list.\n\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a prompt template that combines the system instruction with user input:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: Structure the prompt for system and user input.\n\nfrom langchain_core.prompts import ChatPromptTemplate\n\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", SYSTEM_PROMPT), (\"human\", \"{text}\")]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialize the model and bind it to the Pydantic schema using LangChain's structured output feature:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: Use LangChain's structured output to return validated Pydantic models.\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\nstructured_llm = llm.with_structured_output(Extracted)\n\n# Compose the full chain: prompt â†’ model â†’ validated output\nchain = prompt | structured_llm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Run and Validate\n\nTest the chain with explicit events to confirm correct extraction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: Validate extraction of multiple events with explicit dates.\n\ntext = \"I attended a music festival on June 15th and a tech conference on July 20th.\"\nresult = chain.invoke({\"text\": text})\nprint(result)\n# Expected: Extracted(events=[Event(name='music festival', date='June 15th', outcome=None), Event(name='tech conference', date='July 20th', outcome=None)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verify that the output matches the schema:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: Ensure output matches schema for both chain types.\n\nassert isinstance(result.events, list)\nassert all(hasattr(e, \"name\") for e in result.events)\nprint(\"âœ“ Schema validation passed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test with irrelevant input to confirm the chain returns an empty list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: Confirm that irrelevant text yields an empty list.\n\nirrelevant = \"This is irrelevant text.\"\nresult_empty = chain.invoke({\"text\": irrelevant})\nassert result_empty.events == []\nprint(\"âœ“ Empty result for irrelevant input\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test with partial data to ensure missing fields remain `None`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: Ensure missing fields are set to None, not guessed.\n\npartial = \"We hosted Analytics Day and later ran the Fall Hackathon.\"\nresult_partial = chain.invoke({\"text\": partial})\nprint(result_partial)\n# Expected: Events with names but no dates or outcomes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Validate stability across repeated runs (note: full determinism requires seed and version pinning):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: Ensure repeated runs yield consistent outputs.\n\nsample = \"Board meeting on March 3rd; outcome: postponed.\"\nr1 = chain.invoke({\"text\": sample})\nr2 = chain.invoke({\"text\": sample})\nassert r1.events[0].name == r2.events[0].name, \"Output should be stable with temperature=0\"\nprint(\"âœ“ Stability check passed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Process Real-World Text Data\n\nLoad a live webpage to extract events from unstructured content:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: Fetch and process real-world unstructured text.\n\nfrom langchain_community.document_loaders import WebBaseLoader\n\nloader = WebBaseLoader(\"https://en.wikipedia.org/wiki/Apollo_program\")\ndocs = loader.load()\npage = docs[0].page_content\nprint(f\"Loaded {len(page)} characters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For long documents, chunk the text to respect model context limits. Use overlap to preserve context across boundaries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: Split large texts and aggregate results safely.\n\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\n\nsplitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=300)\nchunks = splitter.split_text(page)\n\nall_events = []\nfor ch in chunks:\n    # Extend the list with events from each chunk\n    result = chain.invoke({\"text\": ch})\n    all_events.extend(result.events)\n\nprint(f\"Extracted {len(all_events)} events from {len(chunks)} chunks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you're concerned about losing critical information in long prompts or context windows, our article on [placing critical info in long prompts and mitigating recall loss](/article/lost-in-the-middle-placing-critical-info-in-long-prompts) offers practical advice. For a deeper dive into why LLMs may \"forget\" or hallucinate as context grows, see our breakdown of [context rot and how to manage LLM memory effectively](/article/context-rot-why-llms-forget-as-their-memory-grows-3).\n\nDisplay a sample of extracted events:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: Inspect a few results for quality and structure.\n\nfor e in all_events[:5]:\n    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Deduplicate events based on key fields to remove redundant entries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: Remove duplicate events based on key fields.\n\ndef dedupe_events(events):\n    \"\"\"\n    Deduplicate a list of Event objects by (name, date, outcome).\n\n    Args:\n        events (List[Event]): List of Event Pydantic models.\n\n    Returns:\n        List[Event]: Deduplicated list of events.\n    \"\"\"\n    seen = set()\n    unique = []\n    for e in events:\n        # Use a tuple of key fields as the deduplication key\n        key = (e.name, e.date, e.outcome)\n        if key not in seen:\n            seen.add(key)\n            unique.append(e)\n    return unique\n\nall_events = dedupe_events(all_events)\nprint(f\"Unique events: {len(all_events)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Production Readiness\n\nAdd retry logic with exponential backoff to handle rate limits and transient errors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: Add robustness to API calls in production.\n\nimport time\nimport random\n\ndef robust_invoke(chain, text, retries=3):\n    \"\"\"\n    Invoke a chain with retries and exponential backoff.\n\n    Args:\n        chain: The LangChain chain to invoke.\n        text (str): The input text for extraction.\n        retries (int): Number of retry attempts.\n\n    Returns:\n        The result of chain.invoke.\n\n    Raises:\n        Exception: If all retries fail.\n    \"\"\"\n    for i in range(retries):\n        try:\n            return chain.invoke({\"text\": text})\n        except Exception as e:\n            if i == retries - 1:\n                raise\n            # Exponential backoff with jitter\n            wait = (2 ** i) + random.random()\n            print(f\"Retry {i+1}/{retries} after {wait:.2f}s due to: {e}\")\n            time.sleep(wait)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Log token usage and latency to monitor cost and performance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: Capture token usage and latency for cost and performance tracking.\n\nimport time\n\ndef invoke_with_metrics(chain, text):\n    \"\"\"\n    Invoke the chain and log token usage and latency.\n\n    Args:\n        chain: The LangChain chain to invoke.\n        text (str): The input text for extraction.\n\n    Returns:\n        The result of chain.invoke.\n    \"\"\"\n    start = time.time()\n    result = chain.invoke({\"text\": text})\n    elapsed = time.time() - start\n    # Note: Token usage requires callback or response inspection; placeholder here\n    print(f\"Latency: {elapsed*1000:.0f}ms\")\n    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For production logging, consider redacting sensitive data from prompts and outputs to protect PII.\n\n---\n\n## Appendix: Alternative Approach with Function Binding\n\nIf you need fine-grained control over function calling, you can manually bind the function and parse the output. This approach is useful for debugging or custom parsing logic:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: Bind OpenAI function and parse the 'events' key for fine control.\n\nfrom langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n\ntry:\n    from langchain_community.utils.openai_functions import convert_pydantic_to_openai_function\nexcept ImportError:\n    from langchain.output_parsers.openai_functions import convert_pydantic_to_openai_function  # type: ignore\n\nextract_fn = convert_pydantic_to_openai_function(Extracted)\nfunctions = [extract_fn]\n\n# Force the model to call the extraction function for determinism\nmodel_with_fn = llm.bind(functions=functions, function_call={\"name\": extract_fn[\"name\"]})\n\n# Parse only the 'events' key from the function call arguments\nevents_parser = JsonKeyOutputFunctionsParser(key_name=\"events\")\n\nchain_functions = prompt | model_with_fn | events_parser\n\n# Example usage:\nevents = chain_functions.invoke({\"text\": \"I attended a music festival on June 15th.\"})\nprint(events)  # Output: [{'name': 'music festival', 'date': 'June 15th', 'outcome': None}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inspect raw function call output for debugging:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: Debug by viewing both raw and parsed outputs.\n\nfrom langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n\nraw_parser = JsonOutputFunctionsParser()  # Returns full function args as dict\nraw_chain = prompt | model_with_fn | raw_parser\n\nsample = \"Board meeting on March 3rd; outcome: postponed.\"\nprint(\"Raw:\", raw_chain.invoke({\"text\": sample}))\nprint(\"Parsed:\", chain_functions.invoke({\"text\": sample}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Single-File Script\n\nHere's a complete, runnable script that consolidates the entire pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# extractor.py\n# Purpose: End-to-end pipeline for structured event extraction from text.\n\nimport os\nfrom typing import List, Optional\nfrom dotenv import load_dotenv\n\nfrom langchain_core.pydantic_v1 import BaseModel, Field\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\n\n# Load API key from .env or Colab userdata\ntry:\n    from google.colab import userdata\nexcept ImportError:\n    userdata = None\n\nload_dotenv()\nif \"OPENAI_API_KEY\" not in os.environ and userdata is not None:\n    os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n\nif \"OPENAI_API_KEY\" not in os.environ:\n    from getpass import getpass\n    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API Key: \")\n\nassert os.getenv(\"OPENAI_API_KEY\"), \"Set OPENAI_API_KEY in your .env file or Colab userdata\"\n\nSYSTEM_PROMPT = \"\"\"You are an information extraction engine.\nExtract only what is explicitly stated in the input text.\nDo not infer or assume missing information.\nIf no explicit events exist, return an empty list.\n\"\"\"\n\nclass Event(BaseModel):\n    \"\"\"\n    Represents a single event extracted from text.\n\n    Args:\n        name (str): The exact event name or label mentioned in the text.\n        date (Optional[str]): The explicit date string if present.\n        outcome (Optional[str]): The explicit outcome/result if stated.\n    \"\"\"\n    name: str = Field(..., description=\"The exact event name or label mentioned in the text.\")\n    date: Optional[str] = Field(None, description=\"The explicit date string if present (e.g., 'June 15, 2024').\")\n    outcome: Optional[str] = Field(None, description=\"The explicit outcome/result if stated (e.g., 'canceled', 'successful').\")\n\nclass Extracted(BaseModel):\n    \"\"\"\n    Container for all events extracted from a text.\n\n    Args:\n        events (List[Event]): All explicit events found in the text.\n    \"\"\"\n    events: List[Event] = Field(default_factory=list, description=\"All explicit events found in the text.\")\n\ndef build_chain(model_name: str = \"gpt-4o-mini\"):\n    \"\"\"\n    Build a structured output chain using LangChain's with_structured_output.\n\n    Args:\n        model_name (str): The OpenAI model to use.\n\n    Returns:\n        A LangChain chain that returns validated Pydantic models.\n    \"\"\"\n    llm = ChatOpenAI(model=model_name, temperature=0)\n    prompt = ChatPromptTemplate.from_messages([(\"system\", SYSTEM_PROMPT), (\"human\", \"{text}\")])\n    structured_llm = llm.with_structured_output(Extracted)\n    return prompt | structured_llm\n\nif __name__ == \"__main__\":\n    chain = build_chain()\n\n    # Test with sample input containing two events\n    sample = \"I attended a music festival on June 15th and a tech conference on July 20th.\"\n    print(\"Structured:\", chain.invoke({\"text\": sample}))\n\n    # Test with irrelevant input (should return empty)\n    irrelevant = \"This is irrelevant text.\"\n    print(\"Empty structured:\", chain.invoke({\"text\": irrelevant}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Conclusion\n\nYou've built a production-ready JSON extraction pipeline that converts unstructured text into validated, schema-conformant events. The system uses OpenAI function calling, LangChain orchestration, and Pydantic validation to eliminate hallucinations and enforce structure.\n\n**Key takeaways:**\n- Schema-first design with Pydantic ensures type safety and validation\n- Structured output chains simplify extraction and reduce parsing errors\n- Chunking with overlap preserves context in long documents\n- Retry logic and deduplication add production robustness\n\n**Next steps:**\n- Add a FastAPI route to serve the extractor as an API\n- Implement an evaluation harness with golden examples and assertions\n- Normalize extracted dates to ISO format with Pydantic validators\n- Explore vendor fallback by swapping to an open-weight model\n\nYou now have a working, testable system ready to extract structured data from any text source at scale."
      ]
    }
  ],
  "metadata": {
    "title": "Structured Data Extraction with LLMs: How to Build a Pipeline",
    "description": "Build a reliable structured data extraction pipeline using LLMs, LangChain, and OpenAI functionsâ€”JSON schemas, deterministic outputs, zero hallucinations, for production.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}