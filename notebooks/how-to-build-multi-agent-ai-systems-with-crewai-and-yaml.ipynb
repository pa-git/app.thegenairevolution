{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** How to Build Multi-Agent AI Systems with CrewAI and YAML\n\n**Description:** Build production-ready multi-agent AI systems with CrewAI using reusable YAML-first patterns, explicit tools and tasks, guardrails, and interactive training loops.\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n\nThis guide shows you how to build a multi-agent customer feedback analysis system using CrewAI. You'll create three specialized agentsâ€”one for sentiment analysis, one for summarization, and one for visualizationâ€”that work together in a sequential workflow to process customer feedback, extract insights, and generate a final report with charts.\n\nYou'll learn how to define agents and tasks in YAML, integrate the CSVSearchTool for grounded analysis, validate structured outputs, and execute generated plotting code. All code is Colab-ready and runnable end-to-end with minimal setup.\n\nBy the end, you'll have a working multi-agent system that produces reproducible, structured insights from raw feedback data.\n\n---\n\n## Setup and Installation\n\nRun the following cell to install CrewAI and its dependencies. We pin versions for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q crewai==0.28.0 crewai-tools==0.1.6 pandas matplotlib pyyaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set your OpenAI API key. In Colab, use the following cell to securely input your key:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\nfrom getpass import getpass\n\nif \"OPENAI_API_KEY\" not in os.environ:\n    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n\nprint(\"API key set successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Why Use CrewAI for This Problem\n\nCrewAI provides structured agent and task definitions, built-in coordination patterns, and YAML-first configuration. Compared to [LangGraph](/article/how-to-build-a-stateful-ai-agent-with-langgraph-step-by-step-5) (which requires manual node orchestration) and single-agent ReAct patterns, CrewAI minimizes boilerplate and clarifies agent responsibilities. YAML configs enable version control and code-reviewable changes, while the sequential process simplifies testing and auditability.\n\nFor this tutorial, CrewAI's CSV tool integration and memory features allow agents to reference concrete feedback rows and share context across tasks, reducing hallucinations and improving output quality.\n\n---\n\n## Core Concepts\n\n### Agents\n\nAgents encapsulate role, goal, and backstory. You define these in YAML and instantiate them in Python. Agents can be assigned tools (e.g., CSVSearchTool) and memory to make capabilities explicit and auditable.\n\n### Tasks\n\nTasks describe what an agent should do and what output format is expected. CrewAI tasks include a description, expected output schema, and an assigned agent. Tasks execute sequentially by default, passing context forward.\n\n### Tools\n\nTools extend agent capabilities. The CSVSearchTool allows agents to query CSV files directly, grounding analysis in real data and reducing hallucinations.\n\n### Crew and Process\n\nA Crew assembles agents and tasks into a workflow. The Process.sequential mode executes tasks in order, ensuring each task can reference prior outputs.\n\n---\n\n## Using CrewAI in Practice\n\n### Step 1: Create Sample Data\n\nGenerate a sample customer feedback CSV for testing. This cell creates the file if it doesn't exist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\nfrom pathlib import Path\n\nPath(\"figures\").mkdir(exist_ok=True)\ncsv_path = Path(\"customer_feedback.csv\")\n\nif not csv_path.exists():\n    data = [\n        {\"customer_id\": 1, \"feedback_text\": \"Loved the new UI, checkout was smooth!\", \"rating\": 5, \"date\": \"2024-09-01\"},\n        {\"customer_id\": 2, \"feedback_text\": \"Support was slow. Still unresolved ticket.\", \"rating\": 2, \"date\": \"2024-09-03\"},\n        {\"customer_id\": 3, \"feedback_text\": \"Great pricing but the app crashes sometimes.\", \"rating\": 3, \"date\": \"2024-09-05\"},\n        {\"customer_id\": 4, \"feedback_text\": \"The UX is confusing on mobile.\", \"rating\": 2, \"date\": \"2024-09-08\"},\n        {\"customer_id\": 5, \"feedback_text\": \"Fast delivery and friendly service!\", \"rating\": 5, \"date\": \"2024-09-12\"},\n    ]\n    pd.DataFrame(data).to_csv(csv_path, index=False)\n    print(\"Sample customer_feedback.csv created.\")\nelse:\n    print(\"customer_feedback.csv already exists.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Define Agents in YAML\n\nCreate an `agents.yaml` file to define the three agents. This cell writes the file to disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "agents_yaml_content = \"\"\"feedback_analysis_agent:\n  role: \"Customer Sentiment Analyst\"\n  goal: \"Evaluate sentiment and themes from customer feedback accurately and reproducibly.\"\n  backstory: >\n    You analyze feedback at scale, balancing qualitative nuance with structured outputs.\n    You use CSV search to reference concrete feedback rows. You avoid hallucinations.\n\nsummary_report_agent:\n  role: \"Insights Summarization Specialist\"\n  goal: \"Produce an executive-ready summary table and concise narrative from analyzed feedback.\"\n  backstory: >\n    You write clearly, focus on business-relevant insights, and adhere to requested output formats.\n\nvisualization_agent:\n  role: \"Visualization Specialist\"\n  goal: \"Generate executable Python code for sentiment distribution and trend charts.\"\n  backstory: >\n    You produce matplotlib code that reads customer_feedback.csv and saves figures to ./figures/.\n\"\"\"\n\nPath(\"agents.yaml\").write_text(agents_yaml_content, encoding=\"utf-8\")\nprint(\"agents.yaml created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Define Tasks in YAML\n\nCreate a `tasks.yaml` file to define the four tasks. Each task specifies a description, expected output format, and will be assigned to an agent in code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tasks_yaml_content = \"\"\"sentiment_evaluation:\n  description: >\n    Read customer_feedback.csv. For each feedback row, infer sentiment (\"positive\", \"neutral\", or \"negative\"),\n    and extract up to 3 themes (e.g., \"pricing\", \"support\", \"ux\"). Summarize counts per sentiment and\n    top themes overall.\n  expected_output: >\n    JSON with keys:\n    - \"row_sentiments\": list of {customer_id, date, sentiment, themes: [str]}\n    - \"sentiment_counts\": {positive: int, neutral: int, negative: int}\n    - \"top_themes\": list of {theme: str, count: int}\n\nsummary_table_creation:\n  description: >\n    Using sentiment evaluation JSON, create a concise summary table highlighting overall sentiment distribution,\n    top 5 themes with counts, and 3 bullet insights for executives.\n  expected_output: >\n    Markdown containing:\n    - \"Sentiment Distribution\" table with columns [sentiment, count]\n    - \"Top Themes\" table with columns [theme, count]\n    - \"Key Insights\" as 3 bullet points\n\nchart_visualization:\n  description: >\n    Output executable Python/matplotlib code that reads customer_feedback.csv and saves\n    figures to ./figures/sentiment_dist.png and ./figures/sentiment_trend.png.\n  expected_output: >\n    Python code block that generates and saves the two charts.\n\nfinal_report_assembly:\n  description: >\n    Assemble the final report including: a brief narrative (<=150 words), the summary table markdown,\n    and references to the generated figures. Ensure the report is clean and ready to share.\n  expected_output: >\n    Markdown with sections: \"Overview\", \"Summary\", \"Figures\", \"Appendix: Method\".\n\"\"\"\n\nPath(\"tasks.yaml\").write_text(tasks_yaml_content, encoding=\"utf-8\")\nprint(\"tasks.yaml created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Load YAML Configurations\n\nLoad the YAML files into Python dictionaries using this helper function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n\ndef load_yaml(path: str) -> dict:\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        return yaml.safe_load(f)\n\nagents_cfg = load_yaml(\"agents.yaml\")\ntasks_cfg = load_yaml(\"tasks.yaml\")\nprint(\"YAML configurations loaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5: Instantiate the CSVSearchTool\n\nCreate a CSVSearchTool instance for the feedback CSV. This tool will be assigned to the feedback analysis agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from crewai_tools import CSVSearchTool\n\ncsv_tool = CSVSearchTool(csv=\"customer_feedback.csv\")\nprint(\"CSVSearchTool instantiated.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 6: Create Agent Instances\n\nInstantiate the three agents from the YAML configuration. The feedback analysis agent receives the CSV tool and memory. The summary agent also has memory to reference prior outputs. The visualization agent does not need memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from crewai import Agent\n\nfeedback_analysis_agent = Agent(\n    role=agents_cfg[\"feedback_analysis_agent\"][\"role\"],\n    goal=agents_cfg[\"feedback_analysis_agent\"][\"goal\"],\n    backstory=agents_cfg[\"feedback_analysis_agent\"][\"backstory\"],\n    tools=[csv_tool],\n    memory=True\n)\n\nsummary_report_agent = Agent(\n    role=agents_cfg[\"summary_report_agent\"][\"role\"],\n    goal=agents_cfg[\"summary_report_agent\"][\"goal\"],\n    backstory=agents_cfg[\"summary_report_agent\"][\"backstory\"],\n    memory=True\n)\n\nvisualization_agent = Agent(\n    role=agents_cfg[\"visualization_agent\"][\"role\"],\n    goal=agents_cfg[\"visualization_agent\"][\"goal\"],\n    backstory=agents_cfg[\"visualization_agent\"][\"backstory\"],\n    memory=False\n)\n\nprint(\"Agents created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 7: Create Task Instances\n\nInstantiate the four tasks from the YAML configuration and assign each to its corresponding agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from crewai import Task\n\nsentiment_evaluation = Task(\n    description=tasks_cfg[\"sentiment_evaluation\"][\"description\"],\n    expected_output=tasks_cfg[\"sentiment_evaluation\"][\"expected_output\"],\n    agent=feedback_analysis_agent\n)\n\nsummary_table_creation = Task(\n    description=tasks_cfg[\"summary_table_creation\"][\"description\"],\n    expected_output=tasks_cfg[\"summary_table_creation\"][\"expected_output\"],\n    agent=summary_report_agent\n)\n\nchart_visualization = Task(\n    description=tasks_cfg[\"chart_visualization\"][\"description\"],\n    expected_output=tasks_cfg[\"chart_visualization\"][\"expected_output\"],\n    agent=visualization_agent\n)\n\nfinal_report_assembly = Task(\n    description=tasks_cfg[\"final_report_assembly\"][\"description\"],\n    expected_output=tasks_cfg[\"final_report_assembly\"][\"expected_output\"],\n    agent=summary_report_agent\n)\n\nprint(\"Tasks created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 8: Assemble the Crew\n\nCreate a Crew with the agents and tasks. Use Process.sequential to execute tasks in order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from crewai import Crew, Process\n\ncrew = Crew(\n    agents=[feedback_analysis_agent, summary_report_agent, visualization_agent],\n    tasks=[sentiment_evaluation, summary_table_creation, chart_visualization, final_report_assembly],\n    process=Process.sequential\n)\n\nprint(\"Crew assembled.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 9: Run the Workflow\n\nExecute the crew workflow and capture the final report. Measure execution time for performance tracking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n\nstart = time.perf_counter()\nresult = crew.kickoff()\nelapsed = time.perf_counter() - start\n\nprint(\"\\n=== Final Report ===\\n\")\nprint(result)\nprint(f\"\\nElapsed: {elapsed:.2f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Run and Evaluate\n\n### Validate Structured JSON Output\n\nCheck that the sentiment evaluation task produced valid JSON with the expected schema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n\ndef validate_sentiment_json(output: str) -> bool:\n    try:\n        analysis_json = json.loads(output)\n        required_keys = {\"row_sentiments\", \"sentiment_counts\", \"top_themes\"}\n        if not required_keys.issubset(analysis_json.keys()):\n            print(\"Missing required keys in sentiment analysis output.\")\n            return False\n        print(\"Sentiment JSON is valid.\")\n        return True\n    except Exception as e:\n        print(f\"Analysis output is not valid JSON: {e}\")\n        return False\n\n# Assuming sentiment_evaluation.output contains the JSON string\n# validate_sentiment_json(sentiment_evaluation.output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Execute Visualization Code\n\nIf the visualization agent returned executable Python code, run it to generate the charts. This cell executes the code in a sandboxed namespace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_plotting_snippet(snippet: str):\n    namespace = {}\n    try:\n        exec(snippet, namespace, namespace)\n        print(\"Plotting code executed successfully.\")\n    except Exception as e:\n        print(f\"Error executing plotting code: {e}\")\n\n# Example usage:\n# if \"plt.\" in chart_visualization.output:\n#     run_plotting_snippet(chart_visualization.output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verify Generated Figures\n\nCheck that the figures were saved to disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n\nexpected_figures = [\"figures/sentiment_dist.png\", \"figures/sentiment_trend.png\"]\nfor fig in expected_figures:\n    if os.path.exists(fig):\n        print(f\"{fig} exists.\")\n    else:\n        print(f\"{fig} not found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Conclusion\n\nYou've built a multi-agent customer feedback analysis system using CrewAI. You defined agents and tasks in YAML, integrated the CSVSearchTool for grounded analysis, validated structured outputs, and executed generated plotting code. The sequential process ensured each task could reference prior outputs, and the YAML-first approach made the system version-controllable and auditable.\n\nNext steps: add a QA gate to validate outputs before final assembly, or parallelize independent tasks like summary and visualization to reduce execution time. For deeper dives into structured data extraction pipelines, see our [structured data extraction guide](/article/structured-data-extraction-with-llms-how-to-build-a-pipeline-3). If you're curious about building agents from scratch using the ReAct pattern, check out our [GPT-4 ReAct agent tutorial](/article/how-to-build-an-llm-agent-from-scratch-with-gpt-4-react-2)."
      ]
    }
  ],
  "metadata": {
    "title": "How to Build Multi-Agent AI Systems with CrewAI and YAML",
    "description": "Build production-ready multi-agent AI systems with CrewAI using reusable YAML-first patterns, explicit tools and tasks, guardrails, and interactive training loops.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}