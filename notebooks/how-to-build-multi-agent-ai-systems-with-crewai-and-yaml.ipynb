{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** How to Build Multi-Agent AI Systems with CrewAI and YAML\n\n**Description:** Build production-ready multi-agent AI systems with CrewAI using reusable YAML-first patterns, explicit tools and tasks, guardrails, and interactive training loops.\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n\nThis guide walks you through building a multi\\-agent customer feedback analysis system using CrewAI. You will define three specialized agents for sentiment analysis, summarization, and visualization. They work together in a sequential workflow to process raw feedback, extract insights, then produce a final report with charts.\n\nYou will learn how to define agents and tasks in YAML, integrate toolsâ€”such as CSV search or file\\-readâ€”for grounded analysis, validate structured outputs, and execute code for visualization. All code is ready to run in Colab with minimal setup.\n\nBy the end, you will have a reproducible, auditable, multi\\-agent system that turns customer feedback into actionable insights.\n\n---\n\n## Why Structure Matters with CrewAI\n\nCrewAI gives you clear componentsâ€”Agents, Tasks, Tools, Crews, and Processesâ€”that align with how you build a team. Agents have roles, goals, and backstories. Tasks specify what to do and what to produce. Tools deliver concrete supports. Crews coordinate agents, and Processes define collaboration styles.\n\nYou will spend less time on repeated boilerplate. You will make your configurations versionable and readable by defining agents and tasks in YAML. That separation lets you tweak behaviors without touching core code.\n\nYou will also learn the value of grounding results in real data using CSV or file\\-read tools. Grounding reduces hallucination and boosts trust. With memory features, agents can carry context forward.\n\nIf youâ€™re interested in how these concepts compare to other agent frameworks, see our step\\-by\\-step guide on [building a stateful AI agent with LangGraph](https://thegenairevolution.com/blog/44830763/how-to-build-a-stateful-ai-agent-with-langgraph-step-by-step-5), which explores persistent memory and visual debugging.\n\n---\n\n## Core Concepts\n\n**Agents**\nAgents hold three core attributes: role (e.g., \"Customer Feedback Analyst\"), goal (what you want them to accomplish), and backstory (context guiding decisions). You define them in YAML so non\\-technical reviewers can inspect or edit them. Agents can use tools and maintain memory.\n\n**Tasks**\nTasks declare what needs doing. Each has a description, expected output format, and agent assignment. All in YAML. Tasks can run sequentially or in parallel depending on how you build your crew.\n\n**Tools**\nTools supply extra capabilities. You might use a CSV search tool, a file\\-reader, or web\\-external APIs. Assign tools to agents or tasks. Agents use tools to avoid guessingâ€”so output stays grounded and reliable.\n\nFor a deeper dive into building robust data extraction pipelines and minimizing hallucinations, check out our article on [structured data extraction with LLMs](https://thegenairevolution.com/blog/44830763/structured-data-extraction-with-llms-how-to-build-a-pipeline-3).\n\n**Crews \\& Processes**\nA Crew combines agents and tasks into a workable system. Processes define how tasks are coordinated. Sequential workflows are simplest. But hierarchical, parallel, or hybrid processes serve more sophisticated use cases.\n\n**Training and Feedback**\nYour agents will not be perfect at first. Use CrewAIâ€™s training mode to pause at interactions, give corrections, then let the agents adjust. This mirrors how you coach a new team member. Over time, performance improves.\n\n---\n\n## Step\\-by\\-Step Example: Customer Feedback Report\n\nHere you build a feedback analyst system with three agents: for sentiment, summarization, and visualization. Then you build four tasks. Later you assemble and run it.\n\n---\n\n## Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q crewai==0.28.0 crewai-tools==0.1.6 pandas matplotlib pyyaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Securely set your OpenAI API key in Colab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\nfrom getpass import getpass\n\nif \"OPENAI_API_KEY\" not in os.environ:\n    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n\nprint(\"API key set successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Step 1: Sample Feedback Data\n\nCreate a sample CSV file if it does not already exist:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\nfrom pathlib import Path\n\nPath(\"figures\").mkdir(exist_ok=True)\ncsv_path = Path(\"customer_feedback.csv\")\n\nif not csv_path.exists():\n    data = [\n        {\"customer_id\": 1, \"feedback_text\": \"Loved the new UI, checkout was smooth!\", \"rating\": 5, \"date\": \"2024-09-01\"},\n        {\"customer_id\": 2, \"feedback_text\": \"Support was slow. Still unresolved ticket.\", \"rating\": 2, \"date\": \"2024-09-03\"},\n        {\"customer_id\": 3, \"feedback_text\": \"Great pricing but the app crashes sometimes.\", \"rating\": 3, \"date\": \"2024-09-05\"},\n        {\"customer_id\": 4, \"feedback_text\": \"The UX is confusing on mobile.\", \"rating\": 2, \"date\": \"2024-09-08\"},\n        {\"customer_id\": 5, \"feedback_text\": \"Fast delivery and friendly service!\", \"rating\": 5, \"date\": \"2024-09-12\"},\n    ]\n    pd.DataFrame(data).to_csv(csv_path, index=False)\n    print(\"Sample customer_feedback.csv created.\")\nelse:\n    print(\"customer_feedback.csv already exists.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Step 2: Define Agents in YAML\n\nWrite `agents.yaml` defining three agents:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```yaml\nfeedback_analysis_agent:\n  role: \"Customer Sentiment Analyst\"\n  goal: \"Evaluate sentiment and themes from customer feedback accurately and reproducibly.\"\n  backstory: >\n    You analyze feedback at scale, balancing qualitative nuance with structured outputs.\n    You use CSV search to reference concrete feedback rows. You avoid hallucinations.\n\nsummary_report_agent:\n  role: \"Insights Summarization Specialist\"\n  goal: \"Produce an executive-ready summary table and concise narrative from analyzed feedback.\"\n  backstory: >\n    You write clearly, focus on business-relevant insights, and adhere to requested output formats.\n\nvisualization_agent:\n  role: \"Visualization Specialist\"\n  goal: \"Generate executable Python code for sentiment distribution and trend charts.\"\n  backstory: >\n    You produce matplotlib code that reads customer_feedback.csv and saves figures to ./figures/.\n```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Step 3: Define Tasks in YAML\n\nWrite `tasks.yaml` with four tasks:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```yaml\nsentiment_evaluation:\n  description: >\n    Read customer_feedback.csv. For each feedback row, infer sentiment (\"positive\", \"neutral\", or \"negative\"),\n    and extract up to 3 themes (e.g. \"pricing\", \"support\", \"ux\"). Summarize counts per sentiment and\n    top themes overall.\n  expected_output: >\n    JSON with keys:\n    - \"row_sentiments\": list of {customer_id, date, sentiment, themes: [str]}\n    - \"sentiment_counts\": {positive: int, neutral: int, negative: int}\n    - \"top_themes\": list of {theme: str, count: int}\n\nsummary_table_creation:\n  description: >\n    Using sentiment evaluation JSON, create a concise summary table highlighting overall sentiment distribution,\n    top 5 themes with counts, and 3 bullet insights for executives.\n  expected_output: >\n    Markdown containing:\n    - \"Sentiment Distribution\" table with columns [sentiment, count]\n    - \"Top Themes\" table with columns [theme, count]\n    - \"Key Insights\" as 3 bullet points\n\nchart_visualization:\n  description: >\n    Output executable Python/matplotlib code that reads customer_feedback.csv and saves\n    figures to ./figures/sentiment_dist.png and ./figures/sentiment_trend.png.\n  expected_output: >\n    Python code block that generates and saves the two charts.\n\nfinal_report_assembly:\n  description: >\n    Assemble the final report including: a brief narrative (<=150 words), the summary table markdown,\n    and references to the generated figures. Ensure the report is clean and ready to share.\n  expected_output: >\n    Markdown with sections: \"Overview\", \"Summary\", \"Figures\", \"Appendix: Method\".\n```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Step 4: Load Configurations\n\nLoad both YAML files into Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n\ndef load_yaml(path: str) -> dict:\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        return yaml.safe_load(f)\n\nagents_cfg = load_yaml(\"agents.yaml\")\ntasks_cfg = load_yaml(\"tasks.yaml\")\nprint(\"YAML configurations loaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Step 5: Instantiate Tools\n\nAssign tools to agents. For feedback analysis, use a CSV search or file reader tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from crewai_tools import CSVSearchTool\n\ncsv_tool = CSVSearchTool(csv=\"customer_feedback.csv\")\nprint(\"CSVSearchTool instantiated.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Step 6: Create Agents in Code\n\nInstantiate agents using configurations. Include tools and memory settings as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from crewai import Agent\n\nfeedback_analysis_agent = Agent(\n    role=agents_cfg[\"feedback_analysis_agent\"][\"role\"],\n    goal=agents_cfg[\"feedback_analysis_agent\"][\"goal\"],\n    backstory=agents_cfg[\"feedback_analysis_agent\"][\"backstory\"],\n    tools=[csv_tool],\n    memory=True\n)\n\nsummary_report_agent = Agent(\n    role=agents_cfg[\"summary_report_agent\"][\"role\"],\n    goal=agents_cfg[\"summary_report_agent\"][\"goal\"],\n    backstory=agents_cfg[\"summary_report_agent\"][\"backstory\"],\n    memory=True\n)\n\nvisualization_agent = Agent(\n    role=agents_cfg[\"visualization_agent\"][\"role\"],\n    goal=agents_cfg[\"visualization_agent\"][\"goal\"],\n    backstory=agents_cfg[\"visualization_agent\"][\"backstory\"],\n    memory=False\n)\n\nprint(\"Agents created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Step 7: Instantiate Tasks\n\nCreate Task instances assigned to agents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from crewai import Task\n\nsentiment_evaluation = Task(\n    description=tasks_cfg[\"sentiment_evaluation\"][\"description\"],\n    expected_output=tasks_cfg[\"sentiment_evaluation\"][\"expected_output\"],\n    agent=feedback_analysis_agent\n)\n\nsummary_table_creation = Task(\n    description=tasks_cfg[\"summary_table_creation\"][\"description\"],\n    expected_output=tasks_cfg[\"summary_table_creation\"][\"expected_output\"],\n    agent=summary_report_agent\n)\n\nchart_visualization = Task(\n    description=tasks_cfg[\"chart_visualization\"][\"description\"],\n    expected_output=tasks_cfg[\"chart_visualization\"][\"expected_output\"],\n    agent=visualization_agent\n)\n\nfinal_report_assembly = Task(\n    description=tasks_cfg[\"final_report_assembly\"][\"description\"],\n    expected_output=tasks_cfg[\"final_report_assembly\"][\"expected_output\"],\n    agent=summary_report_agent\n)\n\nprint(\"Tasks created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Step 8: Assemble the Crew and Define Process\n\nBuild a Crew with your agents and tasks. Choose sequential execution so tasks follow in order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from crewai import Crew, Process\n\ncrew = Crew(\n    agents=[feedback_analysis_agent, summary_report_agent, visualization_agent],\n    tasks=[sentiment_evaluation, summary_table_creation, chart_visualization, final_report_assembly],\n    process=Process.sequential\n)\n\nprint(\"Crew assembled.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Step 9: Run Your Workflow\n\nExecute the multi\\-agent workflow and capture the final report. Track execution time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n\nstart = time.perf_counter()\nresult = crew.kickoff()\nelapsed = time.perf_counter() - start\n\nprint(\"\\n=== Final Report ===\\n\")\nprint(result)\nprint(f\"\\nElapsed: {elapsed:.2f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Run and Evaluate\n\n### Validate Structured JSON Output\n\nConfirm that sentiment evaluation output matches the expected schema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n\ndef validate_sentiment_json(output: str) -> bool:\n    try:\n        analysis_json = json.loads(output)\n        required_keys = {\"row_sentiments\", \"sentiment_counts\", \"top_themes\"}\n        if not required_keys.issubset(analysis_json.keys()):\n            print(\"Missing required keys in sentiment analysis output.\")\n            return False\n        print(\"Sentiment JSON is valid.\")\n        return True\n    except Exception as e:\n        print(f\"Analysis output is not valid JSON: {e}\")\n        return False\n\n# Example usage:\n# validate_sentiment_json(sentiment_evaluation.output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Execute Visualization Code\n\nRun code snippets produced by the visualization agent to generate the charts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_plotting_snippet(snippet: str):\n    namespace = {}\n    try:\n        exec(snippet, namespace, namespace)\n        print(\"Plotting code executed successfully.\")\n    except Exception as e:\n        print(f\"Error executing plotting code: {e}\")\n\n# Example usage:\n# if \"plt.\" in chart_visualization.output:\n#     run_plotting_snippet(chart_visualization.output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verify Saved Figures\n\nCheck that expected figure files exist:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n\nexpected_figures = [\"figures/sentiment_dist.png\", \"figures/sentiment_trend.png\"]\nfor fig in expected_figures:\n    if os.path.exists(fig):\n        print(f\"{fig} exists.\")\n    else:\n        print(f\"{fig} not found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Conclusion and Next Steps\n\nYou have built a multi\\-agent feedback analysis system with CrewAI. You defined agents and tasks in YAML. You grounded your analysis with CSV/data tools. You validated structured output formats. You ran visualization code. You executed everything in sequence for clarity and auditability.\n\nTo go further: introduce a quality assurance gate to check intermediate outputs before assembling the final report. Or parallelize tasks like summary and visualization to save time when dependencies allow. You might also explore other process types such as hierarchical or hybrid process modes to suit more complex workflows.\n\nFor a broader perspective on building LLM agents from scratchâ€”including tool use and control loopsâ€”see our practical walkthrough on [building an LLM agent with GPT\\-4 ReAct](https://thegenairevolution.com/blog/44830763/how-to-build-an-llm-agent-from-scratch-with-gpt-4-react-2).\n\nFor future reading: see The GenAI Revolutionâ€™s guide on [structured data extraction pipelines](https://thegenairevolution.com/blog/44830763/structured-data-extraction-with-llms-how-to-build-a-pipeline-3). You may also compare building agents from scratch using ReAct patterns or using frameworks like [LangGraph](https://thegenairevolution.com/blog/44830763/how-to-build-a-stateful-ai-agent-with-langgraph-step-by-step-5).\n\nBegin!"
      ]
    }
  ],
  "metadata": {
    "title": "How to Build Multi-Agent AI Systems with CrewAI and YAML",
    "description": "Build production-ready multi-agent AI systems with CrewAI using reusable YAML-first patterns, explicit tools and tasks, guardrails, and interactive training loops.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}