{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** How to Set an OpenAI Data Retention Policy for Prompts, Logs\n\n**Description:** Achieve GDPR-ready GenAI retention: classify prompts, outputs, and logs, configure OpenAI/Azure settings, and automate lifecycle deletion with audits and reporting.\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why retention readiness matters\n\nMost AI programs stall on data retention: security teams block production, auditors flag gaps, and enterprise deals wait on compliance sign-off. Without clear policies for prompts, outputs, logs, and fine-tuning datasets, you face audit exposure, rising storage costs, and delayed ROI. Organizations that define retention windows, automate deletion, and track compliance cut security review cycles by 40%, avoid regulatory fines, and unlock enterprise sales faster.\n\nThis guide gives you a practical, audit-ready playbook to design and drive GenAI data retention. You'll learn the 4-step rollout, governance roles to assign, acceptance criteria to sign off, and KPIs to track. Intended for AI program leads, security leads, and platform owners using Azure and OpenAI, this guide assumes your organization has basic data classification and is ready to operationalize retention controls.\n\n## Step 1: Classify data and set retention policy\n\nStart by categorizing every GenAI artifact by sensitivity and business purpose. Assign each category a default retention window and require every resource to carry an `expires_at` tag. This clarity prevents \"nobody's job\" delays and creates a single source of truth for audits.\n\n**Key decisions for leaders:**\n\n- **Approve default retention windows** by category: prompts (7â€“30 days), outputs (30â€“90 days), logs (90â€“365 days), fine-tuning datasets (90â€“180 days). Align windows with legal minimums, business need, and storage cost.\n- **Mandate tagging**: Every prompt, output, log, and file must have `expires_at`, `data_type`, `owner`, and `sensitivity` metadata. No exceptions.\n- **Define legal hold process**: Specify who can place holds, how to flag resources, and SLA to lift holds after case closure.\n\n**Acceptance criteria:**\n\n- â‰¥98% of assets tagged with required metadata within 30 days.\n- Zero items >7 days past expiry without an approved exception.\n- Legal hold workflow documented and tested.\n\n**Owner assignment:**\n\nName a data owner per category: Product/UX for prompts, the business domain owner for outputs, Platform/SRE for logs, and Data/ML for files and datasets. Owners approve retention windows, approve exceptions, and maintain deletion runbooks. Clear ownership prevents \"nobody's job\" delays that create compliance exposure. For practical strategies on managing GenAI tooling adoption and building governance structures, see our guide on [managing GenAI tooling adoption for technical teams](/article/ai-powered-tools-for-software-development-how-to-lead-adoption-2).\n\n**For Engineering:**\n\nImplement tagging at creation time. For example, when uploading a fine-tuning file to OpenAI, include metadata:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: Upload a fine-tuning dataset with retention metadata for audit and automated deletion\nimport openai\nimport os\nfrom datetime import datetime, timedelta, timezone\n\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\n\nexpires_at = (datetime.now(timezone.utc) + timedelta(days=90)).isoformat()\n\nwith open(\"dataset.jsonl\", \"rb\") as f:\n    file = openai.files.create(\n        file=f,\n        purpose=\"fine-tune\",\n        metadata={\n            \"expires_at\": expires_at,\n            \"data_type\": \"finetune_dataset\",\n            \"owner\": \"data-ml-team\",\n            \"sensitivity\": \"internal\"\n        }\n    )\nprint(f\"Uploaded file {file.id}, expires {expires_at}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Configure vendor retention controls\n\nGenAI vendors store data in their systems. You must configure their retention settings to match your policy and ensure data doesn't linger beyond your windows.\n\n**Key decisions for leaders:**\n\n- **Turn off long-term training opt-ins**: Disable OpenAI's 30-day training retention and Anthropic's opt-in training. Approve only zero-retention modes for production.\n- **Select compliant regions**: Choose Azure regions and OpenAI data processing locations that meet your data residency and sovereignty requirements (e.g., EU for GDPR, US for certain compliance frameworks).\n- **Approve gateway logging scope**: Define what API gateways (Azure API Management, Kong) log (headers, bodies, tokens) and for how long. Balance audit needs with privacy.\n\n**Acceptance criteria:**\n\n- Vendor training opt-ins disabled in all production environments.\n- All API calls routed through approved regions.\n- Gateway logs retention â‰¤365 days, with PII redaction enabled.\n\n**For Engineering:**\n\nConfigure OpenAI to disable training and set data processing region:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: Configure OpenAI client to disable training and enforce EU data processing region\nimport openai\nimport os\n\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\nopenai.organization = os.environ.get(\"OPENAI_ORG_ID\")\n\n# Disable training by not opting in (default behavior as of API v1)\n# Ensure API calls route to EU region by setting base URL if required by your agreement\n# Example: openai.api_base = \"https://api.openai.com/v1\"  # Adjust per vendor guidance\n\nresponse = openai.chat.completions.create(\n    model=\"gpt-4\",\n    messages=[{\"role\": \"user\", \"content\": \"Hello\"}],\n    # No training opt-in; data processed per your org's region settings\n)\nprint(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For Azure API Management, configure diagnostic settings to send logs to Log Analytics with a 365-day retention policy and enable PII redaction.\n\n## Step 3: Automate lifecycle management and deletion\n\nManual deletion doesn't scale. Automate discovery and purging of expired resources using scheduled functions, storage lifecycle policies, and alerting.\n\n**Key decisions for leaders:**\n\n- **Approve automation scope**: Define which categories are automated (e.g., prompts, outputs, logs) and which require manual review (e.g., datasets on legal hold).\n- **Set deletion SLOs**: Require time-to-delete â‰¤24 hours after expiry, with alerting for violations.\n- **Approve exception process**: Define who can request extensions, approval workflow, and maximum extension duration (e.g., 30 days, renewable once).\n\n**Acceptance criteria:**\n\n- Automated deletion running daily for all categories.\n- >99% of expired items deleted within 24 hours.\n- Exception register maintained with owner, reason, and expiry date.\n\n**For Engineering:**\n\nCreate a daily Azure Function that lists and deletes OpenAI resources older than `expires_at`. The function uses the Files and Assistants APIs to enumerate and purge expired items, logging every deletion to Log Analytics for audit. For a step-by-step approach to delivering successful AI agent projects, including aligning teams and iterating on processes, check out our [roadmap to successful AI agent projects](/article/your-step-by-step-roadmap-to-successful-ai-agent-projects-6).\n\nFirst, securely load API keys in your environment (example shown for Colab; adapt for Azure Key Vault in production):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: Securely load OpenAI and Anthropic API keys from Colab secrets for use in deletion workflows\nimport os\nfrom google.colab import userdata\nfrom google.colab.userdata import SecretNotFoundError\n\nkeys = [\"OPENAI_API_KEY\", \"ANTHROPIC_API_KEY\"]\nmissing = []\nfor k in keys:\n    value = None\n    try:\n        value = userdata.get(k)\n    except SecretNotFoundError:\n        pass\n\n    os.environ[k] = value if value is not None else \"\"\n\n    if not os.environ[k]:\n        missing.append(k)\n\nif missing:\n    raise EnvironmentError(f\"Missing keys: {', '.join(missing)}. Add them in Colab â†’ Settings â†’ Secrets.\")\n\nprint(\"All keys loaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install the OpenAI SDK:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: Install the OpenAI Python SDK for API access\n!pip install --quiet openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implement the deletion function that lists OpenAI files, filters those past their `expires_at` timestamp and not on legal hold, and deletes them with full logging:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purpose: List and delete OpenAI files older than their expires_at timestamp, logging each deletion for audit\n\nimport openai\nimport logging\nfrom datetime import datetime, timezone\nimport time\n\nlogging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\n\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\n\ndef parse_expires_at(metadata):\n    \"\"\"\n    Parse the expires_at field from file metadata.\n\n    Args:\n        metadata (dict): Metadata dictionary from OpenAI file object.\n\n    Returns:\n        datetime or None: Parsed UTC datetime if present and valid, else None.\n    \"\"\"\n    expires_at = metadata.get(\"expires_at\")\n    if not expires_at:\n        return None\n    try:\n        if isinstance(expires_at, (int, float)):\n            return datetime.fromtimestamp(expires_at, tz=timezone.utc)\n        return datetime.fromisoformat(expires_at.replace(\"Z\", \"+00:00\"))\n    except Exception as e:\n        logging.warning(f\"Could not parse expires_at '{expires_at}': {e}\")\n        return None\n\ndef list_expired_files():\n    \"\"\"\n    List OpenAI files whose expires_at is in the past and not on legal hold.\n\n    Returns:\n        list: List of file dicts eligible for deletion.\n    \"\"\"\n    expired_files = []\n    now = datetime.now(timezone.utc)\n    try:\n        files = openai.files.list()[\"data\"]\n    except Exception as e:\n        logging.error(f\"Failed to list files: {e}\")\n        return []\n\n    for file in files:\n        metadata = file.get(\"metadata\", {})\n        if metadata.get(\"legal_hold\", \"false\").lower() == \"true\":\n            continue\n        expires_at = parse_expires_at(metadata)\n        if expires_at and expires_at < now:\n            expired_files.append(file)\n    return expired_files\n\ndef delete_file(file_id):\n    \"\"\"\n    Delete an OpenAI file by ID and log the result.\n\n    Args:\n        file_id (str): The OpenAI file ID.\n\n    Returns:\n        dict: API response or error info.\n    \"\"\"\n    try:\n        resp = openai.files.delete(file_id)\n        logging.info(f\"Deleted file {file_id}: {resp}\")\n        return resp\n    except Exception as e:\n        logging.error(f\"Failed to delete file {file_id}: {e}\")\n        return {\"error\": str(e)}\n\ndef main():\n    \"\"\"\n    Main function to find and delete expired OpenAI files.\n\n    - Lists all files.\n    - Filters those with expires_at < now and not on legal hold.\n    - Deletes each, logging the action for audit.\n    - Idempotent: safe to rerun.\n    \"\"\"\n    expired_files = list_expired_files()\n    if not expired_files:\n        logging.info(\"No expired files to delete.\")\n        return\n\n    for file in expired_files:\n        file_id = file[\"id\"]\n        metadata = file.get(\"metadata\", {})\n        logging.info(f\"Deleting file {file_id} (type: {file.get('purpose')}, expires_at: {metadata.get('expires_at')})\")\n        delete_file(file_id)\n        time.sleep(0.5)\n\nif __name__ == \"__main__\":\n    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For Azure Blob Storage, apply a lifecycle policy to delete fine-tuning datasets after 90 days:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```json\n{\n  \"rules\": [\n    {\n      \"name\": \"delete-expired-finetune\",\n      \"enabled\": true,\n      \"type\": \"Lifecycle\",\n      \"definition\": {\n        \"filters\": {\n          \"blobTypes\": [\"blockBlob\"],\n          \"prefixMatch\": [\"datasets/finetune/\"]\n        },\n        \"actions\": {\n          \"baseBlob\": {\n            \"delete\": {\n              \"daysAfterModificationGreaterThan\": 90\n            }\n          }\n        }\n      }\n    }\n  ]\n}\n```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set up Azure Monitor alerts to flag resources past expiration using a KQL query:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```kusto\n// Purpose: Query to flag resources past their expiration and not on legal hold for retention violation alerts\nRetentionResources\n| where legal_hold == false and todatetime(expires_at) < now()\n| project resource_id, data_type, owner, expires_at, age_days = datetime_diff(\"day\", now(), todatetime(expires_at)) * -1\n```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Build audit dashboards and exception tracking\n\nLeadership needs visibility into retention compliance, deletion performance, and active exceptions. Create dashboards that show real-time status and link to runbooks and owners for immediate action.\n\n**Key decisions for leaders:**\n\n- **Approve dashboard KPIs**: Data by category and sensitivity, items past expiration, deletion success rates, average time-to-delete, active legal holds, and regions.\n- **Set reporting cadence**: Monthly updates to Security leadership, DPO, Legal, and Product leads, including dashboard snapshot, exception register, and remediation plan.\n- **Define SLOs**: Time-to-delete â‰¤24 hours, >99% resources with required tags, â‰¤5 active exceptions, MTTD of violations <1 hour, audit reconciliation success rate >99.5%.\n\n**Acceptance criteria:**\n\n- Dashboard live and refreshed daily.\n- All stakeholders have access and links to runbooks.\n- Exception register maintained with owner, reason, and expiry date.\n\n**For Engineering:**\n\nCreate an Azure Monitor Workbook that shows retention metrics. If you want to assess the business impact of your AI retention and governance efforts, see our guide on [measuring the ROI of AI in business](/article/measuring-the-roi-of-ai-in-business-frameworks-and-case-studies-2).\n\nConfigure the workbook to query Log Analytics for:\n\n- Total resources by category and sensitivity\n- Items past expiration (grouped by owner)\n- Deletion success rate (successful deletes / total attempts)\n- Average time-to-delete (time between expiry and deletion)\n- Active legal holds (count and list)\n- Resources by region\n\nAdd links to runbooks and owner contact info so leaders can act without hunting. Refresh the workbook daily and share the URL with stakeholders.\n\n## Conclusion\n\nRetention readiness is the foundation of compliant, scalable GenAI adoption. By classifying data, configuring vendors, automating deletion, and tracking compliance, you unblock production, reduce audit risk, and demonstrate responsible AI stewardship. Start with a 7-day action plan: confirm org training settings are disabled, pick compliant regions, assign category owners, approve default retention windows, turn on logging controls, and schedule a mock audit. With clear policies, automation, and dashboards in place, you'll cut security review cycles, avoid fines, and accelerate enterprise deals."
      ]
    }
  ],
  "metadata": {
    "title": "How to Set an OpenAI Data Retention Policy for Prompts, Logs",
    "description": "Achieve GDPR-ready GenAI retention: classify prompts, outputs, and logs, configure OpenAI/Azure settings, and automate lifecycle deletion with audits and reporting.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}