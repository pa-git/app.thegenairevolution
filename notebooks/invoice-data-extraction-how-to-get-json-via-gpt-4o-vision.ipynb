{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** Invoice Data Extraction: How to Get JSON via GPT-4o Vision\n\n**Description:** Ship a production-ready, template-less invoice data extractor: jsonschema-validated JSON, retryable GPT-4o Vision, OCR fallback, and idempotent Postgres upserts with logs.\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What You'll Build\n\nYou'll build a Colab-ready invoice extraction pipeline that converts PDF and image invoices into schema-validated JSON, persists results to Postgres, and logs every API call for observability. The system uses GPT-4o Vision for extraction, validates output against a strict JSON Schema, repairs failures with targeted retry loops, falls back to OCR when vision fails, and ensures idempotent writes. You'll run it on sample invoices and verify correctness end-to-end.\n\n**Prerequisites:** OpenAI API key, Postgres DSN (or use a free-tier managed instance like Neon or ElephantSQL), and ~30 minutes. This tutorial focuses on the extraction and validation pipeline; deployment and UI are out of scope.\n\n---\n\n## How It Works (High-Level Overview)\n\n1. **File ingestion** â€“ Load PDF or image invoices and convert to images\n2. **Image preprocessing** â€“ Optionally resize and enhance for OCR\n3. **Vision extraction** â€“ Call GPT-4o Vision to extract structured JSON\n4. **Schema validation** â€“ Validate against JSON Schema; collect all errors\n5. **Repair loop** â€“ If validation fails, send errors back to the model with retry logic\n6. **Numeric consistency check** â€“ Verify line item totals match subtotal and tax\n7. **OCR fallback** â€“ If vision fails, preprocess image, run Tesseract, and extract from text\n8. **Postgres upsert** â€“ Persist document and line items idempotently by hash\n9. **Logging** â€“ Record latency, token usage, and errors for every run\n10. **Verification** â€“ Query results and confirm idempotency on re-run\n\n---\n\n## Setup: Install Dependencies\n\nRun this cell first to install Python packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --quiet openai pytesseract Pillow opencv-python pdf2image jsonschema psycopg2-binary tenacity python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install system dependencies for Tesseract and Poppler (PDF rendering):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!apt-get update && apt-get install -y tesseract-ocr poppler-utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Configure Credentials\n\nPrompt for API key and database connection string:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\nfrom getpass import getpass\n\nif \"OPENAI_API_KEY\" not in os.environ:\n    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n\nif \"POSTGRES_DSN\" not in os.environ:\n    os.environ[\"POSTGRES_DSN\"] = getpass(\"Enter your Postgres DSN (postgresql://user:pass@host:port/db): \")\n\n# Verify credentials are set\nassert os.environ.get(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY is required\"\nassert os.environ.get(\"POSTGRES_DSN\"), \"POSTGRES_DSN is required\"\n\nprint(\"âœ“ Credentials configured\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Alternative for Colab:** Use `from google.colab import userdata` and store secrets in Colab's secret manager.\n\n---\n\n## Initialize Database Schema\n\nCreate tables for documents, line items, and processing logs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import psycopg2\n\nconn = psycopg2.connect(os.environ[\"POSTGRES_DSN\"])\ncur = conn.cursor()\n\ncur.execute(\"\"\"\nCREATE TABLE IF NOT EXISTS documents (\n    id SERIAL PRIMARY KEY,\n    document_hash TEXT UNIQUE NOT NULL,\n    filename TEXT,\n    vendor TEXT,\n    invoice_number TEXT,\n    invoice_date DATE,\n    currency TEXT,\n    subtotal NUMERIC(12,2),\n    tax NUMERIC(12,2),\n    total NUMERIC(12,2),\n    data JSONB,\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW()\n)\n\"\"\")\n\ncur.execute(\"\"\"\nCREATE TABLE IF NOT EXISTS line_items (\n    id SERIAL PRIMARY KEY,\n    document_id INTEGER REFERENCES documents(id) ON DELETE CASCADE,\n    line_number INTEGER,\n    description TEXT,\n    quantity NUMERIC(12,3),\n    unit_price NUMERIC(12,2),\n    line_total NUMERIC(12,2)\n)\n\"\"\")\n\ncur.execute(\"\"\"\nCREATE TABLE IF NOT EXISTS processing_logs (\n    id SERIAL PRIMARY KEY,\n    document_hash TEXT,\n    request_id TEXT,\n    status TEXT,\n    latency_ms INTEGER,\n    prompt_tokens INTEGER,\n    completion_tokens INTEGER,\n    total_tokens INTEGER,\n    error_message TEXT,\n    created_at TIMESTAMP DEFAULT NOW()\n)\n\"\"\")\n\nconn.commit()\ncur.close()\nconn.close()\n\nprint(\"âœ“ Database schema initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Provision Sample Invoices\n\nDownload sample invoices to `/content/invoices`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\nimport urllib.request\n\nos.makedirs(\"/content/invoices\", exist_ok=True)\n\nsamples = [\n    (\"https://templates.invoicehome.com/invoice-template-us-neat-750px.png\", \"sample1.png\"),\n    (\"https://www.freshbooks.com/wp-content/uploads/2021/10/invoice-sample.jpg\", \"sample2.jpg\"),\n]\n\nfor url, filename in samples:\n    path = f\"/content/invoices/{filename}\"\n    if not os.path.exists(path):\n        urllib.request.urlretrieve(url, path)\n        print(f\"âœ“ Downloaded {filename}\")\n    else:\n        print(f\"âœ“ {filename} already exists\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note:** Replace with your own invoice files if needed.\n\n---\n\n## Define the Invoice JSON Schema\n\nStrict schema with required fields and types:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "invoice_schema = {\n    \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n    \"title\": \"Invoice\",\n    \"type\": \"object\",\n    \"required\": [\"vendor\", \"invoice_number\", \"invoice_date\", \"currency\", \"subtotal\", \"tax\", \"total\", \"line_items\"],\n    \"properties\": {\n        \"vendor\": {\"type\": \"string\", \"minLength\": 1},\n        \"invoice_number\": {\"type\": \"string\", \"pattern\": \"^[A-Za-z0-9._\\\\-/]+$\"},\n        \"invoice_date\": {\"type\": \"string\", \"pattern\": \"^\\\\d{4}-\\\\d{2}-\\\\d{2}$\"},\n        \"due_date\": {\"type\": \"string\", \"pattern\": \"^\\\\d{4}-\\\\d{2}-\\\\d{2}$\"},\n        \"currency\": {\"type\": \"string\", \"pattern\": \"^[A-Z]{3}$\"},\n        \"subtotal\": {\"type\": \"number\"},\n        \"tax\": {\"type\": \"number\"},\n        \"total\": {\"type\": \"number\"},\n        \"vendor_address\": {\"type\": \"string\"},\n        \"customer\": {\"type\": \"string\"},\n        \"customer_address\": {\"type\": \"string\"},\n        \"notes\": {\"type\": \"string\"},\n        \"line_items\": {\n            \"type\": \"array\",\n            \"minItems\": 1,\n            \"items\": {\n                \"type\": \"object\",\n                \"required\": [\"description\", \"quantity\", \"unit_price\", \"line_total\"],\n                \"properties\": {\n                    \"description\": {\"type\": \"string\", \"minLength\": 1},\n                    \"quantity\": {\"type\": \"number\"},\n                    \"unit_price\": {\"type\": \"number\"},\n                    \"line_total\": {\"type\": \"number\"},\n                    \"sku\": {\"type\": \"string\"}\n                },\n                \"additionalProperties\": False\n            }\n        }\n    },\n    \"additionalProperties\": False\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Enforcing `additionalProperties: false` prevents hallucinated fields. Patterns ensure dates and currency codes are valid.\n\n---\n\n## Compute Document Hash for Idempotency\n\nHash each file to detect duplicates:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import hashlib\n\ndef compute_document_hash(file_path: str) -> str:\n    \"\"\"Compute SHA-256 hash of a file for idempotency.\"\"\"\n    h = hashlib.sha256()\n    with open(file_path, \"rb\") as f:\n        for chunk in iter(lambda: f.read(8192), b\"\"):\n            h.update(chunk)\n    return h.hexdigest()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Hashing prevents reprocessing the same file and enables ON CONFLICT upserts.\n\n---\n\n## Convert Files to Images\n\nHandle PDFs and common image formats:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\nfrom pdf2image import convert_from_path\n\ndef file_to_images(file_path: str):\n    \"\"\"Convert a file to a list of PIL images.\"\"\"\n    ext = os.path.splitext(file_path)[1].lower()\n    if ext in [\".png\", \".jpg\", \".jpeg\", \".webp\", \".tiff\", \".bmp\"]:\n        return [Image.open(file_path).convert(\"RGB\")]\n    elif ext == \".pdf\":\n        pages = convert_from_path(file_path, dpi=300)\n        return [p.convert(\"RGB\") for p in pages]\n    else:\n        raise ValueError(f\"Unsupported file type: {ext}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** DPI 300 balances quality and token cost. For multi-page PDFs, we process only the first page in this tutorial.\n\n---\n\n## Resize Images to Control Token Usage\n\nLimit image size to reduce API cost:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def resize_image_for_vision(img: Image.Image, max_long_edge: int = 1600) -> Image.Image:\n    \"\"\"Resize image if longest edge exceeds max_long_edge.\"\"\"\n    w, h = img.size\n    if max(w, h) <= max_long_edge:\n        return img\n    scale = max_long_edge / max(w, h)\n    new_w, new_h = int(w * scale), int(h * scale)\n    return img.resize((new_w, new_h), Image.LANCZOS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Trade-off:** Smaller images reduce cost but may hurt OCR accuracy on small fonts. Adjust `max_long_edge` as needed.\n\n---\n\n## Preprocess Images for OCR\n\nEnhance readability with grayscale, thresholding, and deskew:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\nimport numpy as np\n\ndef preprocess_for_ocr(pil_img: Image.Image) -> Image.Image:\n    \"\"\"Preprocess image for OCR by applying grayscale, thresholding, and deskew.\"\"\"\n    img = np.array(pil_img)\n    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    th = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n                               cv2.THRESH_BINARY, 35, 11)\n    \n    # Deskew via moments (guard against empty image)\n    coords = np.column_stack(np.where(th > 0))\n    if len(coords) == 0:\n        return Image.fromarray(th)\n    \n    angle = cv2.minAreaRect(coords)[-1]\n    if angle < -45:\n        angle = -(90 + angle)\n    else:\n        angle = -angle\n    \n    (h, w) = th.shape[:2]\n    M = cv2.getRotationMatrix2D((w // 2, h // 2), angle, 1.0)\n    rotated = cv2.warpAffine(th, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n    return Image.fromarray(rotated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Adaptive thresholding handles uneven lighting; deskew corrects rotation. The guard prevents crashes on blank images.\n\n---\n\n## Run Tesseract OCR\n\nExtract text as a fallback:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pytesseract\n\ndef ocr_extract_text(pil_img: Image.Image) -> str:\n    \"\"\"Extract text from an image using Tesseract OCR.\"\"\"\n    return pytesseract.image_to_string(pil_img, lang=\"eng\", config=\"--psm 6 --oem 1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** `--psm 6` assumes uniform text blocks; `--oem 1` uses LSTM for better accuracy.\n\n---\n\n## Convert Image to Data URL\n\nEncode image for Vision API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import base64\nfrom io import BytesIO\n\ndef pil_to_data_url(img: Image.Image) -> str:\n    \"\"\"Convert a PIL image to a data URL.\"\"\"\n    buf = BytesIO()\n    img.save(buf, format=\"PNG\")\n    b64 = base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n    return f\"data:image/png;base64,{b64}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Define System Prompt and Few-Shot Examples\n\nGuide the model with strict instructions and a concrete example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = (\n    \"You are a careful invoicing parser. Extract fields strictly as JSON. \"\n    \"Do not include any text outside the JSON. If a value is missing, infer cautiously \"\n    \"from context; otherwise omit the field. Use ISO 8601 dates (YYYY-MM-DD) and ISO 4217 currency.\"\n)\n\ndef schema_summary(schema: dict) -> str:\n    \"\"\"Summarize required fields and types for the prompt.\"\"\"\n    req = schema.get(\"required\", [])\n    props = schema.get(\"properties\", {})\n    lines = [\"Required fields and types:\"]\n    for k in req:\n        t = props.get(k, {}).get(\"type\", \"any\")\n        lines.append(f\"- {k}: {t}\")\n    lines.append(\"Line item fields: description (string), quantity (number), unit_price (number), line_total (number).\")\n    return \"\\n\".join(lines)\n\nFEW_SHOT_USER = (\n    \"Example: Extract JSON from this text-only invoice:\\n\"\n    \"ACME Corp\\nInvoice INV-123\\nDate 2024-06-01\\n\"\n    \"1x Widget A @ 10.00\\n2x Widget B @ 5.00\\nSubtotal 20.00\\nTax 2.00\\nTotal 22.00\\n\"\n)\n\nFEW_SHOT_ASSISTANT = \"\"\"{\n  \"vendor\": \"ACME Corp\",\n  \"invoice_number\": \"INV-123\",\n  \"invoice_date\": \"2024-06-01\",\n  \"currency\": \"USD\",\n  \"subtotal\": 20.0,\n  \"tax\": 2.0,\n  \"total\": 22.0,\n  \"line_items\": [\n    {\"description\": \"Widget A\", \"quantity\": 1, \"unit_price\": 10.0, \"line_total\": 10.0},\n    {\"description\": \"Widget B\", \"quantity\": 2, \"unit_price\": 5.0, \"line_total\": 10.0}\n  ]\n}\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Few-shot examples anchor the model's output format and reduce hallucinations.\n\n---\n\n## Call GPT-4o Vision with Retry Logic\n\nExtract invoice data from an image with automatic retries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\nimport time\nfrom openai import OpenAI\nfrom tenacity import retry, stop_after_attempt, wait_exponential\n\nclient = OpenAI()\n\n@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=1, max=8))\ndef call_gpt4o_vision(img: Image.Image, schema: dict):\n    \"\"\"Call GPT-4o Vision API to extract invoice data as JSON.\"\"\"\n    data_url = pil_to_data_url(img)\n    start = time.time()\n    resp = client.chat.completions.create(\n        model=\"gpt-4o\",\n        response_format={\"type\": \"json_object\"},\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": FEW_SHOT_USER},\n            {\"role\": \"assistant\", \"content\": FEW_SHOT_ASSISTANT},\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\"type\": \"text\", \"text\": \"Extract an invoice as JSON. Follow this contract:\\n\" + schema_summary(schema)},\n                    {\"type\": \"image_url\", \"image_url\": {\"url\": data_url}}\n                ]\n            }\n        ],\n        temperature=0.2\n    )\n    latency_ms = int((time.time() - start) * 1000)\n    text = resp.choices[0].message.content\n    usage = resp.usage\n    request_id = resp.id\n    return json.loads(text), latency_ms, usage, request_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** `response_format=json_object` forces JSON output. Retry logic handles transient API errors.\n\n---\n\n## Validate Against JSON Schema\n\nCollect all validation errors for targeted repair:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from jsonschema import Draft202012Validator, ValidationError\n\ndef validate_against_schema(data: dict, schema: dict):\n    \"\"\"Validate data against the JSON schema and return all errors.\"\"\"\n    validator = Draft202012Validator(schema)\n    errors = []\n    for e in validator.iter_errors(data):\n        path = \"/\".join(map(str, e.path)) or \"$\"\n        errors.append(f\"path={path}: {e.message}\")\n    return len(errors) == 0, errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Collecting all errors at once gives the model complete context for repair.\n\n---\n\n## Repair JSON with Targeted Feedback\n\nSend validation errors back to the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=1, max=8))\ndef repair_with_gpt(img: Image.Image, schema: dict, prev: dict, errors: list):\n    \"\"\"Repair JSON data using GPT-4o Vision based on validation errors.\"\"\"\n    data_url = pil_to_data_url(img)\n    prompt = \"The previous JSON failed validation. Fix strictly per errors:\\n\" + \"\\n\".join(f\"- {err}\" for err in errors)\n    resp = client.chat.completions.create(\n        model=\"gpt-4o\",\n        response_format={\"type\": \"json_object\"},\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": FEW_SHOT_USER},\n            {\"role\": \"assistant\", \"content\": FEW_SHOT_ASSISTANT},\n            {\"role\": \"user\", \"content\": [\n                {\"type\": \"text\", \"text\": \"Original image for reference:\"},\n                {\"type\": \"image_url\", \"image_url\": {\"url\": data_url}}\n            ]},\n            {\"role\": \"user\", \"content\": f\"Previous JSON:\\n{json.dumps(prev, ensure_ascii=False)}\"},\n            {\"role\": \"user\", \"content\": prompt},\n        ],\n        temperature=0.1\n    )\n    fixed = json.loads(resp.choices[0].message.content)\n    return fixed, resp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Lower temperature (0.1) reduces creativity during repair. Showing the original image maintains context.\n\n---\n\n## Check Numeric Consistency\n\nVerify line item totals match subtotal and tax:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def numeric_consistency_ok(data: dict, tol: float = 0.05):\n    \"\"\"Check if numeric fields in the data are consistent within a tolerance.\"\"\"\n    try:\n        subtotal = float(data.get(\"subtotal\", 0))\n        tax = float(data.get(\"tax\", 0))\n        total = float(data.get(\"total\", 0))\n        li_sum = sum(float(it.get(\"line_total\", 0)) for it in data.get(\"line_items\", []))\n        return (abs(li_sum - subtotal) <= tol and\n                abs(subtotal + tax - total) <= tol)\n    except Exception:\n        return False\n\ndef build_numeric_errors(data: dict):\n    \"\"\"Build error messages for numeric inconsistencies.\"\"\"\n    subtotal = data.get(\"subtotal\", None)\n    tax = data.get(\"tax\", None)\n    total = data.get(\"total\", None)\n    li_sum = sum(float(it.get(\"line_total\", 0)) for it in data.get(\"line_items\", []))\n    msgs = []\n    msgs.append(f\"Sum(line_items.line_total)={li_sum}, subtotal={subtotal}, tax={tax}, total={total}.\")\n    msgs.append(\"Enforce: sum(line_items) â‰ˆ subtotal; subtotal + tax â‰ˆ total; update fields minimally to satisfy.\")\n    return msgs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Tolerance accounts for rounding. Explicit error messages guide the model to fix arithmetic.\n\n---\n\n## Fallback to OCR and Text-Only Extraction\n\nIf vision fails, preprocess and extract from text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=1, max=8))\ndef call_gpt_text_only(ocr_text: str, schema: dict, extra_instructions: str = \"\"):\n    \"\"\"Call GPT-4o using OCR text to extract invoice data as JSON.\"\"\"\n    resp = client.chat.completions.create(\n        model=\"gpt-4o\",\n        response_format={\"type\": \"json_object\"},\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": FEW_SHOT_USER},\n            {\"role\": \"assistant\", \"content\": FEW_SHOT_ASSISTANT},\n            {\"role\": \"user\", \"content\": \"Extract invoice JSON strictly per schema summary:\\n\" + schema_summary(schema)},\n            {\"role\": \"user\", \"content\": f\"Invoice text:\\n{ocr_text}\"},\n            {\"role\": \"user\", \"content\": extra_instructions} if extra_instructions else {\"role\": \"user\", \"content\": \"\"}\n        ],\n        temperature=0.2\n    )\n    data = json.loads(resp.choices[0].message.content)\n    return data, resp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Passing numeric errors as a separate message keeps the invoice text clean and improves repair signal.\n\n---\n\n## Persist Results to Postgres\n\nUpsert document and replace line items idempotently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def upsert_document(conn, doc_hash: str, filename: str, data: dict):\n    \"\"\"Upsert document data into Postgres and replace line items.\"\"\"\n    with conn.cursor() as cur:\n        cur.execute(\"\"\"\n            INSERT INTO documents (document_hash, filename, vendor, invoice_number, invoice_date, currency,\n                                   subtotal, tax, total, data, created_at, updated_at)\n            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW(), NOW())\n            ON CONFLICT (document_hash) DO UPDATE SET\n                filename = EXCLUDED.filename,\n                vendor = EXCLUDED.vendor,\n                invoice_number = EXCLUDED.invoice_number,\n                invoice_date = EXCLUDED.invoice_date,\n                currency = EXCLUDED.currency,\n                subtotal = EXCLUDED.subtotal,\n                tax = EXCLUDED.tax,\n                total = EXCLUDED.total,\n                data = EXCLUDED.data,\n                updated_at = NOW()\n            RETURNING id\n        \"\"\", (\n            doc_hash, filename,\n            data.get(\"vendor\"),\n            data.get(\"invoice_number\"),\n            data.get(\"invoice_date\"),\n            data.get(\"currency\"),\n            data.get(\"subtotal\"),\n            data.get(\"tax\"),\n            data.get(\"total\"),\n            json.dumps(data),\n        ))\n        doc_id = cur.fetchone()[0]\n        \n        # Replace line items\n        cur.execute(\"DELETE FROM line_items WHERE document_id = %s\", (doc_id,))\n        for idx, it in enumerate(data.get(\"line_items\", []), start=1):\n            cur.execute(\"\"\"\n                INSERT INTO line_items (document_id, line_number, description, quantity, unit_price, line_total)\n                VALUES (%s, %s, %s, %s, %s, %s)\n            \"\"\", (\n                doc_id, idx,\n                it.get(\"description\"),\n                it.get(\"quantity\"),\n                it.get(\"unit_price\"),\n                it.get(\"line_total\")\n            ))\n    conn.commit()\n    return doc_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** `ON CONFLICT` ensures re-runs update existing records. Deleting and reinserting line items keeps them in sync.\n\n---\n\n## Log Processing Metadata\n\nTrack latency, token usage, and errors for observability:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def log_processing(conn, doc_hash: str, request_id: str, status: str, latency_ms: int,\n                   usage=None, error_message: str = None):\n    \"\"\"Log processing details into the database for observability.\"\"\"\n    # Sanitize error message to avoid logging large payloads\n    if error_message and len(error_message) > 500:\n        error_message = error_message[:500] + \"... (truncated)\"\n    \n    with conn.cursor() as cur:\n        cur.execute(\"\"\"\n            INSERT INTO processing_logs (document_hash, request_id, status, latency_ms,\n                                         prompt_tokens, completion_tokens, total_tokens, error_message, created_at)\n            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, NOW())\n        \"\"\", (\n            doc_hash,\n            request_id,\n            status,\n            latency_ms,\n            getattr(usage, \"prompt_tokens\", None) if usage else None,\n            getattr(usage, \"completion_tokens\", None) if usage else None,\n            getattr(usage, \"total_tokens\", None) if usage else None,\n            error_message\n        ))\n    conn.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Truncating error messages prevents PII leakage and keeps logs manageable.\n\n---\n\n## Orchestrate the End-to-End Pipeline\n\nProcess a single invoice file through all steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n\ndef process_invoice_file(file_path: str):\n    \"\"\"Process an invoice file through the full pipeline.\"\"\"\n    doc_hash = compute_document_hash(file_path)\n    images = file_to_images(file_path)\n    first_img = resize_image_for_vision(images[0])\n\n    data = None\n    usage = None\n    request_id = None\n    status = \"ok\"\n    error_message = None\n    start_time = time.time()\n\n    try:\n        # Attempt Vision extraction\n        data, _, usage, request_id = call_gpt4o_vision(first_img, invoice_schema)\n        ok, errs = validate_against_schema(data, invoice_schema)\n        \n        # Repair if validation fails\n        if not ok:\n            data, repair_resp = repair_with_gpt(first_img, invoice_schema, data, errs)\n            usage = repair_resp.usage\n            request_id = repair_resp.id\n            ok, errs = validate_against_schema(data, invoice_schema)\n\n        # Numeric consistency repair\n        if ok and not numeric_consistency_ok(data):\n            numeric_errs = build_numeric_errors(data)\n            data, repair_resp2 = repair_with_gpt(first_img, invoice_schema, data, numeric_errs)\n            usage = repair_resp2.usage\n            request_id = repair_resp2.id\n            ok, errs = validate_against_schema(data, invoice_schema)\n\n        # OCR fallback\n        if not ok:\n            pre = preprocess_for_ocr(first_img)\n            ocr_text = ocr_extract_text(pre)\n            data, text_resp = call_gpt_text_only(ocr_text, invoice_schema)\n            usage = text_resp.usage\n            request_id = text_resp.id\n            ok, errs = validate_against_schema(data, invoice_schema)\n            \n            # Numeric repair for OCR path\n            if ok and not numeric_consistency_ok(data):\n                numeric_errs = build_numeric_errors(data)\n                data, repair_resp3 = call_gpt_text_only(ocr_text, invoice_schema, \"\\n\".join(numeric_errs))\n                usage = repair_resp3.usage\n                request_id = repair_resp3.id\n                ok, errs = validate_against_schema(data, invoice_schema)\n\n        if not ok:\n            status = \"failed\"\n            error_message = \"Validation failed after OCR fallback: \" + \"; \".join(errs)\n\n        # Persist if successful\n        latency_ms = int((time.time() - start_time) * 1000)\n        if status == \"ok\":\n            with psycopg2.connect(os.environ[\"POSTGRES_DSN\"]) as conn:\n                upsert_document(conn, doc_hash, os.path.basename(file_path), data)\n                log_processing(conn, doc_hash, request_id, status, latency_ms, usage, None)\n        else:\n            with psycopg2.connect(os.environ[\"POSTGRES_DSN\"]) as conn:\n                log_processing(conn, doc_hash, request_id, status, latency_ms, usage, error_message)\n\n        return {\"file\": file_path, \"hash\": doc_hash, \"status\": status, \"errors\": None if status == \"ok\" else error_message}\n\n    except Exception as e:\n        status = \"error\"\n        error_message = str(e)\n        latency_ms = int((time.time() - start_time) * 1000)\n        with psycopg2.connect(os.environ[\"POSTGRES_DSN\"]) as conn:\n            log_processing(conn, doc_hash, request_id, status, latency_ms, usage, error_message)\n        return {\"file\": file_path, \"hash\": doc_hash, \"status\": status, \"errors\": error_message}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Tracking `start_time` at the top captures end-to-end latency. Each path (vision, repair, OCR) updates `usage` and `request_id` for accurate logging.\n\n---\n\n## Run the Pipeline on Sample Files\n\nProcess all invoices in the input directory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_dir = \"/content/invoices\"\nfiles = sorted([p for p in glob.glob(os.path.join(input_dir, \"*\")) if os.path.isfile(p)])\n\nresults = []\nfor f in files:\n    res = process_invoice_file(f)\n    print(res)\n    results.append(res)\n\nsummary = {\n    \"processed\": len(results),\n    \"ok\": sum(1 for r in results if r[\"status\"] == \"ok\"),\n    \"failed\": sum(1 for r in results if r[\"status\"] == \"failed\"),\n    \"error\": sum(1 for r in results if r[\"status\"] == \"error\"),\n}\nprint(\"Summary:\", summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Verify Idempotency\n\nRe-run processing and confirm no duplicates are created:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count documents before re-run\nwith psycopg2.connect(os.environ[\"POSTGRES_DSN\"]) as conn:\n    with conn.cursor() as cur:\n        cur.execute(\"SELECT COUNT(*) FROM documents\")\n        count_before = cur.fetchone()[0]\n\n# Re-run processing\nfor f in files:\n    res = process_invoice_file(f)\n    print(\"Re-run:\", res)\n\n# Count documents after re-run\nwith psycopg2.connect(os.environ[\"POSTGRES_DSN\"]) as conn:\n    with conn.cursor() as cur:\n        cur.execute(\"SELECT COUNT(*) FROM documents\")\n        count_after = cur.fetchone()[0]\n\nprint(f\"Documents before: {count_before}, after: {count_after}\")\nassert count_before == count_after, \"Idempotency check failed: duplicate documents created\"\nprint(\"âœ“ Idempotency verified\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design:** Asserting equal counts proves `ON CONFLICT` works. Only `updated_at` should change.\n\n---\n\n## Query and Inspect Results\n\nView extracted documents and line items:\n\n```python\nwith psycopg2.connect(os.environ[\"POSTGRES_DSN\"]) as conn:\n    with conn.cursor() as cur:\n        cur.execute(\"\"\"\n            SELECT id, filename, vendor, invoice_number, invoice_date, currency, subtotal, tax, total\n            FROM documents ORDER BY id DESC LIMIT 5\n        \"\"\")\n        print(\"Documents:\")\n        for row in cur.fetchall():\n            print(row)\n\n        cur.execute(\"\"\"\n            SELECT d.invoice_number, li.line_number, li.description, li.quantity, li.unit_price, li.line_total\n            FROM line_items li\n            JOIN documents d ON li.document_id = d.id\n            ORDER BY d.id DESC, li.line_number ASC\n            LIMIT"
      ]
    }
  ],
  "metadata": {
    "title": "Invoice Data Extraction: How to Get JSON via GPT-4o Vision",
    "description": "Ship a production-ready, template-less invoice data extractor: jsonschema-validated JSON, retryable GPT-4o Vision, OCR fallback, and idempotent Postgres upserts with logs.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}