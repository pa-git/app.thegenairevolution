{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** CrewAI Agent: Build a Production-Ready Planner-Executor with Memory\n\n**Description:** Ship a production-ready CrewAI agent that plans tasks, validates tools, persists memory, and returns deterministic schema-validated JSON with automatic retries.\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thought: I now can give a great answer\n\n---\n\nReal apps fail from hallucinations, context loss, nondeterministic outputs, and tool misuse. We'll fix this with stable planning, strict tool I/O contracts, persistent memory, and schema-enforced outputs with retries. The result is a CrewAI agent that behaves predictably and is safe to ship behind an API. If you want to dive deeper into why LLMs struggle with context loss and how to address it, our article on [Context Rot - Why LLMs \"Forget\" as Their Memory Grows](/article/context-rot-why-llms-forget-as-their-memory-grows-3) provides practical strategies for managing model memory.\n\nYou'll leave with a single Colab notebook you can run end-to-end, demonstrating planning, tool execution, memory persistence, and schema-validated JSON outputs with automatic retries.\n\n---\n\n## Why This Approach Works\n\nCrewAI orchestrates multi-agent workflows, but without constraints, agents hallucinate tool calls, produce malformed JSON, and lose context across steps. This guide enforces:\n\n- **Hierarchical planning**: A planner agent decomposes the query; an executor follows the plan step-by-step, reducing drift.\n- **Strict tool contracts**: Each tool validates inputs with Pydantic, returns structured success/error objects, and applies retries with exponential backoff for external APIs.\n- **Persistent memory**: ChromaDB stores facts across sessions, enabling context reuse and reducing redundant tool calls.\n- **Schema-enforced outputs**: A Pydantic model validates the final JSON. If validation fails, the system injects corrective instructions and retries automatically.\n- **Deterministic model settings**: Explicit model, temperature, and token limits reduce nondeterminism.\n\n---\n\n## How It Works (High-Level Overview)\n\n1. **User submits a query** (e.g., \"What's the current BTC price in USD, and if it rises by 2.5%, what will it be? Include 2 sources.\").\n2. **Planner agent** decomposes the query into numbered steps with tool suggestions.\n3. **Executor agent** runs each step using validated tools (web search, calculator, crypto price API, memory read/write).\n4. **Memory tools** persist useful facts and retrieve prior context.\n5. **Schema validator** checks the final JSON against `FinalAnswer`. If invalid, the system retries with stricter instructions.\n6. **Output** is a structured JSON with query, plan, step results, answer, and citations.\n\n---\n\n## Setup & Installation\n\nRun this cell first to install dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q \"crewai>=0.50.0\" \"pydantic>=2.8.0\" \"chromadb>=0.5.0\" \"httpx>=0.27.0\" \"python-dotenv>=1.0.1\" \"tenacity>=8.5.0\" \"crewai-tools>=0.11.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set your API keys. In Colab, use this cell (replace placeholders with your keys):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n\n# Set API keys directly in Colab (or use .env locally)\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\nos.environ[\"ANTHROPIC_API_KEY\"] = \"sk-ant-...\"\nos.environ[\"TAVILY_API_KEY\"] = \"tvly-...\"\n\n# Verify keys are set\nrequired_keys = [\"OPENAI_API_KEY\", \"ANTHROPIC_API_KEY\", \"TAVILY_API_KEY\"]\nmissing = [k for k in required_keys if not os.getenv(k)]\nif missing:\n    raise EnvironmentError(f\"Missing API keys: {missing}. Set them in the cell above.\")\nprint(\"âœ… All API keys set.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verify installed versions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import crewai\nimport pydantic\nimport chromadb\nprint(f\"CrewAI: {crewai.__version__}\")\nprint(f\"Pydantic: {pydantic.__version__}\")\nprint(f\"ChromaDB: {chromadb.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Step-by-Step Implementation\n\n### Step 1: Define the Output Schema\n\nThis Pydantic model enforces the structure of the final JSON. Each field is required and typed strictly to prevent malformed outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile schemas.py\n# schemas.py\n# Purpose: Define the strict output schema for the agent's final answer.\n\nfrom pydantic import BaseModel, HttpUrl, Field\nfrom typing import List, Optional\n\nclass StepResult(BaseModel):\n    \"\"\"\n    Represents the result of a single execution step.\n    \n    Attributes:\n        step (int): Step number in the plan.\n        tool (str): Tool used (e.g., \"web_search\", \"calculator\").\n        success (bool): Whether the step succeeded.\n        data (Optional[dict]): Tool output data if successful.\n        error (Optional[str]): Error message if failed.\n    \"\"\"\n    step: int\n    tool: str\n    success: bool\n    data: Optional[dict] = None\n    error: Optional[str] = None\n\nclass FinalAnswer(BaseModel):\n    \"\"\"\n    The final validated output from the agent.\n    \n    Attributes:\n        query (str): The original user query.\n        plan (List[str]): Numbered steps executed.\n        results (List[StepResult]): Detailed results for each step.\n        answer (str): Natural language answer to the query.\n        citations (List[HttpUrl]): Valid URLs cited as sources.\n    \"\"\"\n    query: str\n    plan: List[str]\n    results: List[StepResult]\n    answer: str\n    citations: List[HttpUrl] = Field(default_factory=list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why this design**: `HttpUrl` ensures citations are valid URLs. `StepResult` captures success/failure per step, enabling debugging and retry logic. `plan` is included so the executor must explicitly copy the planner's steps, reducing drift.\n\n---\n\n### Step 2: Build Production-Grade Tools\n\nEach tool validates inputs, handles errors gracefully, and returns structured outputs. We apply retries with exponential backoff for external APIs.\n\n#### Web Search Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile tools/search.py\n# tools/search.py\n# Purpose: Web search tool with strict input validation, retry logic, and structured error handling.\n\nimport httpx\nfrom crewai_tools import BaseTool\nfrom pydantic import BaseModel, Field, ValidationError\nfrom tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\nfrom typing import List, Optional\nimport os\nimport logging\n\nlogger = logging.getLogger(\"tools.search\")\n\nclass SearchInput(BaseModel):\n    \"\"\"Input schema for web search.\"\"\"\n    query: str = Field(..., min_length=1, max_length=500, description=\"Search query string\")\n    max_results: int = Field(default=3, ge=1, le=10, description=\"Max number of results to return\")\n\nclass TavilySearchTool(BaseTool):\n    name: str = \"web_search\"\n    description: str = (\n        \"Search the web using Tavily API. Returns a list of results with title, URL, and snippet. \"\n        \"Input must be JSON: {\\\"query\\\": \\\"your search\\\", \\\"max_results\\\": 3}. \"\n        \"Example: {\\\"query\\\": \\\"Bitcoin price news\\\", \\\"max_results\\\": 3}\"\n    )\n\n    @retry(\n        reraise=True,\n        stop=stop_after_attempt(3),\n        wait=wait_exponential(multiplier=0.5, min=0.5, max=4),\n        retry=retry_if_exception_type(httpx.HTTPStatusError)\n    )\n    def _run(self, query: str, max_results: int = 3) -> dict:\n        \"\"\"\n        Execute web search with retry logic.\n        \n        Args:\n            query (str): Search query.\n            max_results (int): Number of results to return.\n        \n        Returns:\n            dict: {\"success\": bool, \"data\": list or None, \"error\": str or None}\n        \"\"\"\n        try:\n            # Validate inputs\n            validated = SearchInput(query=query, max_results=max_results)\n        except ValidationError as e:\n            logger.error(f\"Search input validation failed: {e}\")\n            return {\"success\": False, \"data\": None, \"error\": f\"Invalid input: {e}\"}\n\n        api_key = os.getenv(\"TAVILY_API_KEY\")\n        if not api_key:\n            return {\"success\": False, \"data\": None, \"error\": \"TAVILY_API_KEY not set\"}\n\n        try:\n            with httpx.Client(timeout=10.0) as client:\n                resp = client.post(\n                    \"https://api.tavily.com/search\",\n                    json={\"query\": validated.query, \"max_results\": validated.max_results, \"api_key\": api_key}\n                )\n                resp.raise_for_status()\n                data = resp.json()\n                # Filter out placeholder URLs and invalid results\n                results = [\n                    {\"title\": r.get(\"title\", \"\"), \"url\": r.get(\"url\", \"\"), \"snippet\": r.get(\"content\", \"\")}\n                    for r in data.get(\"results\", [])\n                    if r.get(\"url\") and not r[\"url\"].startswith(\"https://example.com\")\n                ]\n                logger.info(f\"Search returned {len(results)} results for query: {validated.query}\")\n                return {\"success\": True, \"data\": results, \"error\": None}\n        except httpx.HTTPStatusError as e:\n            logger.error(f\"Tavily API error: {e.response.status_code}\")\n            return {\"success\": False, \"data\": None, \"error\": f\"API error: {e.response.status_code}\"}\n        except Exception as e:\n            logger.error(f\"Search failed: {e}\")\n            return {\"success\": False, \"data\": None, \"error\": str(e)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why retries**: External APIs can fail transiently. Exponential backoff reduces load and increases success rate. **Why structured errors**: The executor can parse `{\"success\": false, \"error\": \"...\"}` and include it in `FinalAnswer.results` without crashing.\n\n---\n\n#### Calculator Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile tools/calculator.py\n# tools/calculator.py\n# Purpose: Safe arithmetic evaluator with strict input validation and operator whitelisting.\n\nimport ast\nimport operator\nfrom crewai_tools import BaseTool\nfrom pydantic import BaseModel, Field, ValidationError\nimport logging\n\nlogger = logging.getLogger(\"tools.calculator\")\n\nclass CalculatorInput(BaseModel):\n    \"\"\"Input schema for calculator.\"\"\"\n    expression: str = Field(..., min_length=1, max_length=200, description=\"Arithmetic expression to evaluate\")\n\nclass CalculatorTool(BaseTool):\n    name: str = \"calculator\"\n    description: str = (\n        \"Evaluate arithmetic expressions safely. Supports +, -, *, /, %, //, **. \"\n        \"Input must be JSON: {\\\"expression\\\": \\\"2 + 2\\\"}. \"\n        \"Example: {\\\"expression\\\": \\\"100 * 1.025\\\"}\"\n    )\n\n    # Whitelist of allowed operators (excludes pow to prevent abuse)\n    ALLOWED_OPS = {\n        ast.Add: operator.add,\n        ast.Sub: operator.sub,\n        ast.Mult: operator.mul,\n        ast.Div: operator.truediv,\n        ast.Mod: operator.mod,\n        ast.FloorDiv: operator.floordiv,\n        ast.USub: operator.neg,\n    }\n\n    def _eval_node(self, node):\n        \"\"\"Recursively evaluate AST node with operator whitelist.\"\"\"\n        if isinstance(node, ast.Constant):  # Python 3.8+\n            return node.value\n        elif isinstance(node, ast.Num):  # Python 3.7 compatibility\n            return node.n\n        elif isinstance(node, ast.BinOp):\n            if type(node.op) not in self.ALLOWED_OPS:\n                raise ValueError(f\"Operator {type(node.op).__name__} not allowed\")\n            left = self._eval_node(node.left)\n            right = self._eval_node(node.right)\n            return self.ALLOWED_OPS[type(node.op)](left, right)\n        elif isinstance(node, ast.UnaryOp):\n            if type(node.op) not in self.ALLOWED_OPS:\n                raise ValueError(f\"Operator {type(node.op).__name__} not allowed\")\n            operand = self._eval_node(node.operand)\n            return self.ALLOWED_OPS[type(node.op)](operand)\n        else:\n            raise ValueError(f\"Unsupported node type: {type(node).__name__}\")\n\n    def _run(self, expression: str) -> dict:\n        \"\"\"\n        Evaluate arithmetic expression safely.\n        \n        Args:\n            expression (str): Arithmetic expression.\n        \n        Returns:\n            dict: {\"success\": bool, \"data\": {\"result\": float} or None, \"error\": str or None}\n        \"\"\"\n        try:\n            validated = CalculatorInput(expression=expression)\n        except ValidationError as e:\n            logger.error(f\"Calculator input validation failed: {e}\")\n            return {\"success\": False, \"data\": None, \"error\": f\"Invalid input: {e}\"}\n\n        try:\n            tree = ast.parse(validated.expression, mode=\"eval\")\n            result = self._eval_node(tree.body)\n            logger.info(f\"Calculated: {validated.expression} = {result}\")\n            return {\"success\": True, \"data\": {\"result\": float(result)}, \"error\": None}\n        except Exception as e:\n            logger.error(f\"Calculation failed: {e}\")\n            return {\"success\": False, \"data\": None, \"error\": str(e)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why operator whitelist**: Prevents abuse (e.g., `2**9999999` causing hangs). **Why length cap**: Limits complexity and prevents prompt injection via long expressions.\n\n---\n\n#### Crypto Price Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile tools/prices.py\n# tools/prices.py\n# Purpose: Fetch cryptocurrency prices from CoinGecko with retry logic and strict validation.\n\nimport httpx\nfrom crewai_tools import BaseTool\nfrom pydantic import BaseModel, Field, ValidationError\nfrom tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\nimport logging\n\nlogger = logging.getLogger(\"tools.prices\")\n\nclass PriceInput(BaseModel):\n    \"\"\"Input schema for crypto price lookup.\"\"\"\n    coin_id: str = Field(..., min_length=1, max_length=50, description=\"CoinGecko coin ID (e.g., 'bitcoin')\")\n    currency: str = Field(default=\"usd\", min_length=3, max_length=3, description=\"Currency code (e.g., 'usd')\")\n\nclass CoinGeckoPriceTool(BaseTool):\n    name: str = \"crypto_price\"\n    description: str = (\n        \"Fetch current cryptocurrency price from CoinGecko. \"\n        \"Input must be JSON: {\\\"coin_id\\\": \\\"bitcoin\\\", \\\"currency\\\": \\\"usd\\\"}. \"\n        \"Example: {\\\"coin_id\\\": \\\"ethereum\\\", \\\"currency\\\": \\\"usd\\\"}\"\n    )\n\n    @retry(\n        reraise=True,\n        stop=stop_after_attempt(3),\n        wait=wait_exponential(multiplier=0.5, min=0.5, max=4),\n        retry=retry_if_exception_type(httpx.HTTPStatusError)\n    )\n    def _run(self, coin_id: str, currency: str = \"usd\") -> dict:\n        \"\"\"\n        Fetch crypto price with retry logic.\n        \n        Args:\n            coin_id (str): CoinGecko coin ID.\n            currency (str): Currency code.\n        \n        Returns:\n            dict: {\"success\": bool, \"data\": {\"coin_id\": str, \"currency\": str, \"price\": float} or None, \"error\": str or None}\n        \"\"\"\n        try:\n            validated = PriceInput(coin_id=coin_id, currency=currency)\n        except ValidationError as e:\n            logger.error(f\"Price input validation failed: {e}\")\n            return {\"success\": False, \"data\": None, \"error\": f\"Invalid input: {e}\"}\n\n        try:\n            with httpx.Client(timeout=10.0) as client:\n                resp = client.get(\n                    \"https://api.coingecko.com/api/v3/simple/price\",\n                    params={\"ids\": validated.coin_id, \"vs_currencies\": validated.currency}\n                )\n                resp.raise_for_status()\n                data = resp.json()\n                # Handle missing coin_id or currency gracefully\n                if validated.coin_id not in data or validated.currency not in data[validated.coin_id]:\n                    return {\"success\": False, \"data\": None, \"error\": f\"Price not found for {validated.coin_id}/{validated.currency}\"}\n                price = float(data[validated.coin_id][validated.currency])\n                logger.info(f\"Fetched price: {validated.coin_id}/{validated.currency} = {price}\")\n                return {\"success\": True, \"data\": {\"coin_id\": validated.coin_id, \"currency\": validated.currency, \"price\": price}, \"error\": None}\n        except httpx.HTTPStatusError as e:\n            logger.error(f\"CoinGecko API error: {e.response.status_code}\")\n            return {\"success\": False, \"data\": None, \"error\": f\"API error: {e.response.status_code}\"}\n        except Exception as e:\n            logger.error(f\"Price fetch failed: {e}\")\n            return {\"success\": False, \"data\": None, \"error\": str(e)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why coin_id validation**: Prevents injection of arbitrary strings. **Why graceful key path handling**: Avoids KeyError crashes if the API response structure changes.\n\n---\n\n#### Memory Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile tools/memory.py\n# tools/memory.py\n# Purpose: Persistent memory tools using ChromaDB for context retention across sessions.\n\nimport chromadb\nfrom crewai_tools import BaseTool\nfrom pydantic import BaseModel, Field, ValidationError\nimport os\nimport logging\n\nlogger = logging.getLogger(\"tools.memory\")\n\n# Ensure ChromaDB persists to a writable directory (Colab-compatible)\nCHROMA_DIR = os.getenv(\"CHROMA_DIR\", \"./chroma_data\")\nos.makedirs(CHROMA_DIR, exist_ok=True)\nchroma_client = chromadb.PersistentClient(path=CHROMA_DIR)\ncollection = chroma_client.get_or_create_collection(\"agent_memory\")\n\nclass MemoryWriteInput(BaseModel):\n    \"\"\"Input schema for memory write.\"\"\"\n    user_id: str = Field(..., min_length=1, max_length=100, description=\"User identifier\")\n    fact: str = Field(..., min_length=1, max_length=1000, description=\"Fact to store\")\n\nclass MemorySearchInput(BaseModel):\n    \"\"\"Input schema for memory search.\"\"\"\n    user_id: str = Field(..., min_length=1, max_length=100, description=\"User identifier\")\n    query: str = Field(..., min_length=1, max_length=500, description=\"Search query\")\n    top_k: int = Field(default=3, ge=1, le=10, description=\"Number of results to return\")\n\nclass MemoryWriteTool(BaseTool):\n    name: str = \"memory_write\"\n    description: str = (\n        \"Store a fact in persistent memory for a user. \"\n        \"Input must be JSON: {\\\"user_id\\\": \\\"user123\\\", \\\"fact\\\": \\\"User prefers BTC over ETH\\\"}. \"\n        \"Example: {\\\"user_id\\\": \\\"alice\\\", \\\"fact\\\": \\\"Alice's favorite coin is bitcoin\\\"}\"\n    )\n\n    def _run(self, user_id: str, fact: str) -> dict:\n        \"\"\"\n        Store a fact in ChromaDB.\n        \n        Args:\n            user_id (str): User identifier.\n            fact (str): Fact to store.\n        \n        Returns:\n            dict: {\"success\": bool, \"data\": {\"stored\": str} or None, \"error\": str or None}\n        \"\"\"\n        try:\n            validated = MemoryWriteInput(user_id=user_id, fact=fact)\n        except ValidationError as e:\n            logger.error(f\"Memory write input validation failed: {e}\")\n            return {\"success\": False, \"data\": None, \"error\": f\"Invalid input: {e}\"}\n\n        try:\n            doc_id = f\"{validated.user_id}_{hash(validated.fact)}\"\n            collection.add(\n                documents=[validated.fact],\n                metadatas=[{\"user_id\": validated.user_id}],\n                ids=[doc_id]\n            )\n            logger.info(f\"Stored fact for {validated.user_id}: {validated.fact}\")\n            return {\"success\": True, \"data\": {\"stored\": validated.fact}, \"error\": None}\n        except Exception as e:\n            logger.error(f\"Memory write failed: {e}\")\n            return {\"success\": False, \"data\": None, \"error\": str(e)}\n\nclass MemorySearchTool(BaseTool):\n    name: str = \"memory_search\"\n    description: str = (\n        \"Search stored facts for a user. \"\n        \"Input must be JSON: {\\\"user_id\\\": \\\"user123\\\", \\\"query\\\": \\\"favorite coin\\\", \\\"top_k\\\": 3}. \"\n        \"Example: {\\\"user_id\\\": \\\"alice\\\", \\\"query\\\": \\\"bitcoin\\\", \\\"top_k\\\": 2}\"\n    )\n\n    def _run(self, user_id: str, query: str, top_k: int = 3) -> dict:\n        \"\"\"\n        Search ChromaDB for relevant facts.\n        \n        Args:\n            user_id (str): User identifier.\n            query (str): Search query.\n            top_k (int): Number of results to return.\n        \n        Returns:\n            dict: {\"success\": bool, \"data\": {\"facts\": list} or None, \"error\": str or None}\n        \"\"\"\n        try:\n            validated = MemorySearchInput(user_id=user_id, query=query, top_k=top_k)\n        except ValidationError as e:\n            logger.error(f\"Memory search input validation failed: {e}\")\n            return {\"success\": False, \"data\": None, \"error\": f\"Invalid input: {e}\"}\n\n        try:\n            results = collection.query(\n                query_texts=[validated.query],\n                n_results=validated.top_k,\n                where={\"user_id\": validated.user_id}\n            )\n            facts = results[\"documents\"][0] if results[\"documents\"] else []\n            logger.info(f\"Retrieved {len(facts)} facts for {validated.user_id}\")\n            return {\"success\": True, \"data\": {\"facts\": facts}, \"error\": None}\n        except Exception as e:\n            logger.error(f\"Memory search failed: {e}\")\n            return {\"success\": False, \"data\": None, \"error\": str(e)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why user_id scoping**: Prevents cross-user data leakage. **Why persistent client**: Retains memory across notebook restarts (if CHROMA_DIR is mounted or persistent).\n\n---\n\n### Step 3: Assemble the Agent System\n\nDefine planner and executor agents with explicit model settings for determinism, then wire them into a hierarchical crew."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile main.py\n# main.py\n# Purpose: Entrypoint for a production-grade CrewAI agent with validated tools, persistent memory, and deterministic schema-validated outputs.\n\nimport os\nimport json\nimport logging\nfrom dotenv import load_dotenv\n\n# Load environment variables\ntry:\n    from google.colab import userdata\n    load_dotenv()\n    for key in [\"OPENAI_API_KEY\", \"ANTHROPIC_API_KEY\", \"TAVILY_API_KEY\"]:\n        if key not in os.environ and userdata.get(key):\n            os.environ[key] = userdata.get(key)\nexcept ImportError:\n    load_dotenv()\n\nlogging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(name)s %(message)s\")\nlogger = logging.getLogger(\"main\")\n\nfrom crewai import Agent, Task, Crew, Process\nfrom pydantic import ValidationError\nfrom tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n\nfrom tools.search import TavilySearchTool\nfrom tools.calculator import CalculatorTool\nfrom tools.prices import CoinGeckoPriceTool\nfrom tools.memory import MemoryWriteTool, MemorySearchTool\nfrom schemas import FinalAnswer\n\n# Instantiate tools\nweb_search = TavilySearchTool()\ncalculator = CalculatorTool()\ncrypto_price = CoinGeckoPriceTool()\nmemory_write = MemoryWriteTool()\nmemory_search = MemorySearchTool()\n\n# Define agents with explicit model settings for determinism\nplanner = Agent(\n    role=\"Planner\",\n    goal=\"Decompose the user request into a minimal set of executable steps with proper tool usage.\",\n    backstory=\"You are a precise project planner. You only produce plans; you do not execute.\",\n    allow_delegation=True,\n    verbose=True,\n    llm=\"gpt-4o-mini\",  # Explicit model\n    temperature=0.2,  # Low temperature for determinism\n    max_tokens=1000\n)\n\nexecutor = Agent(\n    role=\"Executor\",\n    goal=(\n        \"Execute the plan step-by-step using the available tools, validate tool outputs, \"\n        \"persist useful facts with memory_write, and construct the final JSON strictly matching the given schema. \"\n        \"Use user_id='{user_id}' in all memory_* tool calls.\"\n    ),\n    backstory=\"You are a reliable operator who follows instructions exactly and validates everything.\",\n    tools=[web_search, calculator, crypto_price, memory_write, memory_search],\n    allow_delegation=False,\n    verbose=True,\n    llm=\"gpt-4o-mini\",\n    temperature=0.2,\n    max_tokens=2000\n)\n\n# Schema instruction for strict output validation\nSCHEMA_INSTRUCTION = (\n    \"You must output a single JSON object that matches this schema exactly:\\n\"\n    \"{\\n\"\n    '  \"query\": string,\\n'\n    '  \"plan\": array of strings (copy the numbered steps you executed),\\n'\n    '  \"results\": array of { \"step\": int, \"tool\": string, \"success\": boolean, \"data\": object|null, \"error\": string|null },\\n'\n    '  \"answer\": string,\\n'\n    '  \"citations\": array of valid URLs\\n'\n    \"}\\n\"\n    \"No extra keys. No markdown. No commentary. JSON only.\"\n)\n\n# Define tasks\nplanning_task = Task(\n    description=(\n        \"Analyze the user request: '{query}'. \"\n        \"Produce a concise, numbered plan of steps. For each step, specify: objective, suggested tool (if any), and expected output.\"\n    ),\n    expected_output=\"A numbered list of 2-6 concrete steps with tool suggestions.\",\n    agent=planner\n)\n\nexecution_task = Task(\n    description=(\n        \"Follow the plan precisely. For each step: select the appropriate tool, run it with validated inputs, \"\n        \"and record success or error in the results array. Use memory_search when relevant; write useful facts via memory_write. \"\n        f\"Finally, produce a strictly valid JSON that matches the provided schema.\\n\\n{SCHEMA_INSTRUCTION}\"\n    ),\n    expected_output=\"A single JSON object matching the FinalAnswer schema exactly.\",\n    agent=executor\n)\n\n# Assemble crew\ncrew = Crew(\n    agents=[planner, executor],\n    tasks=[planning_task, execution_task],\n    process=Process.hierarchical,\n    manager_agent=planner,\n    verbose=True\n)\n\nclass SchemaError(Exception):\n    \"\"\"Custom exception for schema validation errors.\"\"\"\n    pass\n\ndef validate_output(text: str) -> FinalAnswer:\n    \"\"\"\n    Validate the output text against the FinalAnswer schema.\n    \n    Args:\n        text (str): The raw output text from the agent.\n    \n    Returns:\n        FinalAnswer: Parsed and validated FinalAnswer object.\n    \n    Raises:\n        SchemaError: If the output does not match the schema.\n    \"\"\"\n    try:\n        s = text.strip()\n        # Handle code fences\n        if s.startswith(\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\"):\n            s = s.strip(\"`\")\n            if \"json\" in s[:10].lower():\n                s = s[s.find(\"\\n\")+1:]\n            s = s[s.find(\"{\"): s.rfind(\"}\") + 1]\n        data = json.loads(s)\n        return FinalAnswer.model_validate(data)\n    except Exception as e:\n        logger.error(f\"Schema validation failed: {e}\")\n        raise SchemaError(str(e))\n\ndef run_crew_once(user_query: str, user_id: str) -> str:\n    \"\"\"\n    Run the CrewAI process once for the given user query.\n    \n    Args:\n        user_query (str): The user's input query.\n        user_id (str): User identifier for memory scoping.\n    \n    Returns:\n        str: The raw output from the CrewAI process.\n    \"\"\"\n    logger.info(f\"Running CrewAI for query: {user_query}, user_id: {user_id}\")\n    result = crew.kickoff(inputs={\"query\": user_query, \"user_id\": user_id})\n    return result\n\n@retry(\n    reraise=True,\n    stop=stop_after_attempt(3),\n    wait=wait_exponential(multiplier=0.5, min=0.5, max=4),\n    retry=retry_if_exception_type(SchemaError),\n)\ndef run_with_validation(user_query: str, user_id: str = \"default_user\") -> FinalAnswer:\n    \"\"\"\n    Run the CrewAI process with schema validation and automatic retries.\n    \n    Args:\n        user_query (str): The user's input query.\n        user_id (str): User identifier for memory scoping.\n    \n    Returns:\n        FinalAnswer: The validated output matching the FinalAnswer schema.\n    \n    Raises:\n        SchemaError: If all retries fail to produce valid output.\n    \"\"\"\n    raw = run_crew_once(user_query, user_id)\n    try:\n        return validate_output(raw)\n    except SchemaError as err:\n        logger.warning(f\"Output failed schema validation: {err}. Retrying with stricter instructions.\")\n        # Inject corrective instruction (idempotent: only add if not present)\n        if \"STRICT OUTPUT INSTRUCTION\" not in execution_task.description:\n            execution_task.description += f\"\\n\\nSTRICT OUTPUT INSTRUCTION:\\n{SCHEMA_INSTRUCTION}\\n\\n\"\n        execution_task.expected_output = \"Strictly valid JSON per schema.\"\n        raw2 = run_crew_once(user_query, user_id)\n        return validate_output(raw2)\n\nif __name__ == \"__main__\":\n    q = \"What's the current BTC price in USD, and if it rises by 2.5%, what will it be? Include 2 sources.\"\n    try:\n        answer = run_with_validation(q, user_id=\"alice\")\n        print(answer.model_dump_json(indent=2))\n    except Exception as e:\n        logger.error(f\"Failed to produce valid output: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "**Why hierarchical process**: The planner manages the executor, reducing drift. **Why explicit model/temperature**: Ensures deterministic outputs. **Why user_id in inputs**: Enables memory scoping per user. **Why idempotent retry instruction**: Prevents prompt bloat on repeated retries.\n\n---\n\n## Run and Validate\n\n### Test 1: Valid End-to-End Query\n\nRun the main script to execute a full query with planning, tool calls, and schema validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "python\nfrom main import run_with_validation\n\nquery = \"What's the current BTC price in USD, and if it rises by 2.5%, what will it be? Include 2 sources.\"\nresult = run_with_validation(query, user_id=\"alice\")\nprint(result.model_dump_json(indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "**Expected output**: A JSON object with `query`, `plan`, `results` (showing successful tool calls), `answer`, and `citations`.\n\n---\n\n### Test 2: Tool Failure Handling\n\nTrigger a tool failure by passing an invalid coin ID."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "python\nquery_invalid = \"What's the current price of invalid_coin_xyz in USD?\"\nresult_invalid = run_with_validation(query_invalid, user_id=\"alice\")\nprint(result_invalid.model_dump_json(indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "**Expected output**: `FinalAnswer.results` includes a step with `\"success\": false` and a descriptive error message. The agent should still produce valid JSON.\n\n---\n\n### Test 3: Schema Violation and Retry\n\nManually inject a malformed output to test retry logic (for demonstration, you can modify `validate_output` temporarily to always raise `SchemaError` on first attempt)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "python\n# Simulate schema violation by forcing a retry\n# (In practice, this happens when the LLM produces invalid JSON)\n# The retry mechanism will inject stricter instructions and rerun."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "**Expected behavior**: The system logs a validation error, injects corrective instructions, and retries. The second attempt should produce valid JSON.\n\n---\n\n### Test 4: Memory Persistence\n\nRun a query that writes a fact, then run a second query that retrieves it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "python\n# First query: store a fact\nquery1 = \"Remember that Alice's favorite cryptocurrency is Bitcoin.\"\nresult1 = run_with_validation(query1, user_id=\"alice\")\nprint(\"First run:\", result1.answer)\n\n# Second query: retrieve the fact\nquery2 = \"What is Alice's favorite cryptocurrency?\"\nresult2 = run_with_validation(query2, user_id=\"alice\")\nprint(\"Second run:\", result2.answer)\n```\n\n**Expected output**: The second query should retrieve \"Bitcoin\" from memory without calling external APIs.\n\n---\n\n## Conclusion\n\nYou've built a production-grade CrewAI agent with:\n\n- **Hierarchical planning** to reduce drift\n- **Strict tool contracts** with Pydantic validation and retry logic\n- **Persistent memory** using ChromaDB for context retention\n- **Schema-enforced outputs** with automatic retries\n- **Deterministic model settings** for predictable behavior\n\nThis system is ready to deploy behind an API. Key decisions:\n\n- **Why hierarchical process**: Separates planning from execution, reducing hallucinations.\n- **Why Pydantic schemas**: Enforces strict input/output contracts, preventing malformed data.\n- **Why retries with exponential backoff**: Handles transient API failures gracefully.\n- **Why memory scoping by user_id**: Prevents cross-user data leakage.\n- **Why explicit model/temperature**: Reduces nondeterminism in outputs.\n\n### Next Steps\n\n- **Add domain allowlists** for web_search to restrict outbound requests.\n- **Implement rate limiting** per user to prevent abuse.\n- **Extend memory** with semantic search or time-based expiration.\n- **Deploy** via FastAPI or Flask with request_id logging for observability.\n- **Monitor** tool success rates and schema validation failures in production.\n\nFor more on model selection and trade-offs, see our guide on [How do you pick an LLM?](/article/how-to-choose-an-ai-model-for-your-app-speed-cost-reliability). To understand prompt structure and information placement, check out [Lost in the Middle: Placing Critical Info in Long Prompts](/article/lost-in-the-middle-placing-critical-info-in-long-prompts)."
      ]
    }
  ],
  "metadata": {
    "title": "CrewAI Agent: Build a Production-Ready Planner-Executor with Memory",
    "description": "Ship a production-ready CrewAI agent that plans tasks, validates tools, persists memory, and returns deterministic schema-validated JSON with automatic retries.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}