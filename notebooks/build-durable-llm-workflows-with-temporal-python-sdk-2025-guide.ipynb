{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** Build Durable LLM Workflows with temporal-python-sdk [2025 Guide]\n\n**Description:** Ship production-grade document workflows using Temporal Python SDK signals for human approvals, safe retries, and idempotent activities that survive restarts.\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why This Approach Works\n\nBuilding a durable, human-in-the-loop document approval workflow requires more than just async tasks and retry loops. Traditional approaches fail when processes crash mid-execution, duplicate expensive LLM calls on retries, or lose track of approval state across restarts.\n\nTemporal solves these problems by treating your workflow as durable code that survives failures, retries activities idempotently, and waits indefinitely for human signals without polling. You get automatic retries with exponential backoff, deterministic execution that replays from history, and built-in observabilityâ€”all without building your own orchestration layer.\n\nIn this tutorial, you'll build a production-grade document approval workflow using the Temporal Python SDK. The system will generate drafts via OpenAI, wait for human edits or approval via signals, apply revisions idempotently, and persist the final documentâ€”all while handling transient failures and maintaining full auditability.\n\n## How It Works\n\nHere's the end-to-end flow:\n\n1. **Client starts workflow** with a document ID and prompt\n2. **Workflow executes draft activity** (idempotent LLM call via OpenAI)\n3. **Workflow waits for signals**: human submits edits or approves\n4. **On edits**: workflow increments version, executes revision activity (idempotent), loops back to wait\n5. **On approval**: workflow executes persist activity (idempotent) and completes\n6. **Retries on transient failures**: exponential backoff with configurable max attempts\n7. **Durability across restarts**: workflow resumes from last checkpoint if worker crashes\n\nActivities encapsulate side effects (LLM calls, storage) and use atomic file writes keyed by `(doc_id, version)` to ensure at-most-once execution. Workflows orchestrate activities and signals deterministically, never calling external APIs directly. Signals enable human-in-the-loop without polling or timeouts.\n\n## Setup & Installation\n\nThis tutorial runs locally and requires a Temporal dev server. You'll need Python 3.8+, an OpenAI API key, and the Temporal CLI.\n\n**Install dependencies:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install temporalio openai python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Install Temporal CLI** (choose your platform):\n\n- **macOS**: `brew install temporal`\n- **Linux**: `curl -sSf https://temporal.download/cli.sh | sh`\n- **Windows**: Download from [temporal.io/cli](https://temporal.io/cli)\n\n**Set your OpenAI API key** as an environment variable:\n\n- **macOS/Linux**: `export OPENAI_API_KEY=\"sk-...\"`\n- **Windows (PowerShell)**: `$env:OPENAI_API_KEY=\"sk-...\"`\n- **Windows (CMD)**: `setx OPENAI_API_KEY \"sk-...\"`\n\nAlternatively, create a `.env` file with `OPENAI_API_KEY=sk-...` in your project directory.\n\n## Step-by-Step Implementation\n\n### Step 1: Define Shared Models\n\nCreate a custom exception for non-retryable validation errors. This tells Temporal to fail fast on bad inputs instead of retrying indefinitely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile models.py\n# models.py\n# Purpose: Define shared exceptions and models for workflow activities.\n\nclass ValidationError(Exception):\n    \"\"\"\n    Raised when input is invalid and should not be retried by Temporal activities.\n\n    Args:\n        message (str): Description of the validation error.\n    \"\"\"\n    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Build Idempotent Storage Helpers\n\nActivities must be idempotent to prevent duplicate side effects on retries. These helpers use atomic file writes keyed by `(doc_id, version)` to ensure each LLM call happens at most once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile storage_utils.py\n# storage_utils.py\n# Purpose: Provide atomic, idempotent JSON storage helpers for activities.\n\nimport os\nimport json\nimport tempfile\nfrom pathlib import Path\nfrom typing import Any, Dict, Optional\n\nBASE = Path(\"storage\")\nBASE.mkdir(exist_ok=True)\n\ndef key_path(*parts: str) -> Path:\n    \"\"\"\n    Generate a safe, unique file path for a given key.\n\n    Args:\n        *parts (str): Components to build the key.\n\n    Returns:\n        Path: Path to the JSON file for this key.\n    \"\"\"\n    safe = \"_\".join(parts)\n    return BASE / f\"{safe}.json\"\n\ndef atomic_write_json(path: Path, data: Dict[str, Any]) -> None:\n    \"\"\"\n    Atomically write JSON data to disk to ensure at-most-once side effects.\n\n    Args:\n        path (Path): Target file path.\n        data (Dict[str, Any]): Data to write.\n\n    Raises:\n        OSError: If writing fails.\n    \"\"\"\n    path.parent.mkdir(parents=True, exist_ok=True)\n    with tempfile.NamedTemporaryFile(\"w\", delete=False, dir=str(path.parent)) as tmp:\n        json.dump(data, tmp, ensure_ascii=False, indent=2)\n        tmp.flush()\n        os.fsync(tmp.fileno())\n        tmp_name = tmp.name\n    os.replace(tmp_name, path)\n\ndef read_json_if_exists(path: Path) -> Optional[Dict[str, Any]]:\n    \"\"\"\n    Read JSON data from a file if it exists.\n\n    Args:\n        path (Path): File path.\n\n    Returns:\n        Optional[Dict[str, Any]]: Parsed JSON data or None if file does not exist.\n    \"\"\"\n    if path.exists():\n        with open(path, \"r\") as f:\n            return json.load(f)\n    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Implement Idempotent Activities\n\nActivities encapsulate side effects (LLM calls, storage) to keep workflows deterministic. Each activity checks for existing output before calling OpenAI, ensuring idempotency across retries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile activities.py\n# activities.py\n# Purpose: Define idempotent LLM and storage activities for the workflow.\n\nimport os\nfrom typing import Dict, Optional\nfrom temporalio import activity\nfrom models import ValidationError\nfrom storage_utils import key_path, read_json_if_exists, atomic_write_json\nfrom openai import OpenAI\n\n_openai_client = None\n\ndef get_openai():\n    \"\"\"\n    Lazily initialize and return a singleton OpenAI client.\n\n    Returns:\n        OpenAI: OpenAI client instance.\n    \"\"\"\n    global _openai_client\n    if _openai_client is None:\n        _openai_client = OpenAI()\n    return _openai_client\n\ndef _idempotent_get(path_key: str):\n    \"\"\"\n    Helper to check for existing output by key.\n\n    Args:\n        path_key (str): Unique key for the output.\n\n    Returns:\n        Tuple[Path, Optional[Dict]]: Path and existing data if present.\n    \"\"\"\n    path = key_path(path_key)\n    return path, read_json_if_exists(path)\n\n@activity.defn\nasync def generate_draft(doc_id: str, prompt: str, version: int, model: Optional[str] = None) -> Dict:\n    \"\"\"\n    Idempotently generate a draft for (doc_id, version).\n    If a draft already exists, return it instead of re-calling the LLM.\n\n    Args:\n        doc_id (str): Document identifier.\n        prompt (str): Prompt for the LLM.\n        version (int): Version number.\n        model (Optional[str]): OpenAI model name.\n\n    Returns:\n        Dict: Draft data.\n\n    Raises:\n        ValidationError: If prompt is invalid.\n        RuntimeError: For transient failures (for retry testing).\n    \"\"\"\n    if os.getenv(\"FAIL_FIRST\", \"0\") == \"1\":\n        os.environ[\"FAIL_FIRST\"] = \"0\"\n        raise RuntimeError(\"Injected transient failure\")\n\n    model = model or os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n    path, existing = _idempotent_get(f\"draft_{doc_id}_{version}\")\n    if existing:\n        return existing\n\n    if not prompt or len(prompt) < 10:\n        raise ValidationError(\"Prompt too short for drafting\")\n\n    client = get_openai()\n    resp = client.chat.completions.create(\n        model=model,\n        messages=[{\"role\": \"user\", \"content\": f\"Draft a clear, concise document based on:\\n{prompt}\\nTone: professional.\"}],\n    )\n    text = resp.choices[0].message.content\n\n    result = {\n        \"doc_id\": doc_id,\n        \"version\": version,\n        \"draft\": text,\n        \"source\": \"llm\",\n    }\n    atomic_write_json(path, result)\n    return result\n\n@activity.defn\nasync def revise_draft(doc_id: str, base_text: str, edits: str, version: int, model: Optional[str] = None) -> Dict:\n    \"\"\"\n    Idempotently create a revision for (doc_id, version) from base_text + edits.\n\n    Args:\n        doc_id (str): Document identifier.\n        base_text (str): Current draft text.\n        edits (str): Human edits to apply.\n        version (int): New version number.\n        model (Optional[str]): OpenAI model name.\n\n    Returns:\n        Dict: Revised draft data.\n\n    Raises:\n        ValidationError: If edits are empty.\n    \"\"\"\n    model = model or os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n    path, existing = _idempotent_get(f\"revision_{doc_id}_{version}\")\n    if existing:\n        return existing\n\n    if not edits or len(edits.strip()) == 0:\n        raise ValidationError(\"No edits provided\")\n\n    client = get_openai()\n    instructions = (\n        \"Apply the user's edits faithfully. Keep structure, improve clarity, and \"\n        \"do not invent facts. Return the full revised document.\"\n    )\n    resp = client.chat.completions.create(\n        model=model,\n        messages=[{\"role\": \"user\", \"content\": f\"{instructions}\\n\\n--- Current Draft ---\\n{base_text}\\n\\n--- Edits ---\\n{edits}\"}],\n    )\n    text = resp.choices[0].message.content\n\n    result = {\n        \"doc_id\": doc_id,\n        \"version\": version,\n        \"draft\": text,\n        \"source\": \"llm_revision\",\n    }\n    atomic_write_json(path, result)\n    return result\n\n@activity.defn\nasync def persist_final(doc_id: str, content: str, version: int) -> Dict:\n    \"\"\"\n    Idempotently persist the final approved document.\n\n    Args:\n        doc_id (str): Document identifier.\n        content (str): Final document content.\n        version (int): Version number.\n\n    Returns:\n        Dict: Final persisted document data.\n    \"\"\"\n    path, existing = _idempotent_get(f\"final_{doc_id}_{version}\")\n    if existing:\n        return existing\n\n    result = {\"doc_id\": doc_id, \"version\": version, \"content\": content, \"status\": \"final\"}\n    atomic_write_json(path, result)\n    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Define the Workflow with Signals and Queries\n\nWorkflows orchestrate activities and wait for signals without calling external APIs directly. This keeps execution deterministic and replayable. Signals enable human-in-the-loop without polling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile workflow.py\n# workflow.py\n# Purpose: Define the deterministic document approval workflow with signals and queries.\n\nfrom datetime import timedelta\nfrom typing import Optional, Dict\nfrom temporalio import workflow\nfrom temporalio.common import RetryPolicy\nfrom models import ValidationError\n\nwith workflow.unsafe.imports_passed_through():\n    from activities import generate_draft, revise_draft, persist_final\n\n@workflow.defn\nclass DocumentWorkflow:\n    \"\"\"\n    Durable, human-in-the-loop document approval workflow.\n\n    Signals:\n        submit_edit(content): Submit human edits for revision.\n        approve(): Approve the current draft.\n\n    Queries:\n        status(): Get current workflow status.\n    \"\"\"\n\n    def __init__(self) -> None:\n        self.doc_id: Optional[str] = None\n        self.prompt: Optional[str] = None\n        self.current: Optional[Dict] = None\n        self.version: int = 0\n        self._approved: bool = False\n        self._pending_edits: Optional[str] = None\n\n    @workflow.signal\n    def submit_edit(self, content: str) -> None:\n        \"\"\"\n        Signal: Submit human edits for the current draft.\n\n        Args:\n            content (str): Edits to apply.\n        \"\"\"\n        self._pending_edits = content\n\n    @workflow.signal\n    def approve(self) -> None:\n        \"\"\"\n        Signal: Approve the current draft.\n        \"\"\"\n        self._approved = True\n\n    @workflow.query\n    def status(self) -> Dict:\n        \"\"\"\n        Query: Get current workflow status.\n\n        Returns:\n            Dict: Status fields for observability.\n        \"\"\"\n        return {\n            \"doc_id\": self.doc_id,\n            \"version\": self.version,\n            \"approved\": self._approved,\n            \"has_pending_edits\": self._pending_edits is not None,\n            \"current_excerpt\": (self.current[\"draft\"][:120] + \"...\") if self.current else None,\n        }\n\n    @workflow.run\n    async def run(self, doc_id: str, prompt: str, model: Optional[str] = None) -> Dict:\n        \"\"\"\n        Main workflow logic: orchestrates draft, revision, and approval.\n\n        Args:\n            doc_id (str): Document identifier.\n            prompt (str): Initial prompt for LLM.\n            model (Optional[str]): OpenAI model name.\n\n        Returns:\n            Dict: Final persisted document data.\n        \"\"\"\n        self.doc_id = doc_id\n        self.prompt = prompt\n        self.version = 1\n\n        ao = workflow.ActivityOptions(\n            start_to_close_timeout=timedelta(seconds=60),\n            schedule_to_close_timeout=timedelta(minutes=5),\n            retry_policy=RetryPolicy(\n                initial_interval=timedelta(seconds=2),\n                backoff_coefficient=2.0,\n                maximum_interval=timedelta(seconds=30),\n                maximum_attempts=6,\n                non_retryable_error_types=[ValidationError.__name__],\n            ),\n        )\n\n        self.current = await workflow.execute_activity(\n            generate_draft, self.doc_id, self.prompt, self.version, model,\n            **ao.as_dict()\n        )\n\n        while True:\n            await workflow.wait_condition(\n                lambda: self._approved or self._pending_edits is not None\n            )\n            if self._approved:\n                break\n\n            edits = self._pending_edits\n            self._pending_edits = None\n            self.version += 1\n            self.current = await workflow.execute_activity(\n                revise_draft,\n                self.doc_id,\n                self.current[\"draft\"],\n                edits,\n                self.version,\n                model,\n                **ao.as_dict()\n            )\n\n        final = await workflow.execute_activity(\n            persist_final, self.doc_id, self.current[\"draft\"], self.version,\n            **ao.as_dict()\n        )\n        return final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5: Create the Worker\n\nThe worker polls the task queue to execute workflows and activities reliably. It connects to the Temporal server and registers your workflow and activities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile worker.py\n# worker.py\n# Purpose: Register and run the Temporal worker for workflows and activities.\n\nimport asyncio\nimport os\nfrom temporalio.client import Client\nfrom temporalio.worker import Worker\nfrom workflow import DocumentWorkflow\nfrom activities import generate_draft, revise_draft, persist_final\n\nTASK_QUEUE = \"doc-approval-q\"\n\nasync def main():\n    \"\"\"\n    Start the Temporal worker to process workflow and activity tasks.\n\n    Raises:\n        Exception: If connection or worker startup fails.\n    \"\"\"\n    address = os.getenv(\"TEMPORAL_ADDRESS\", \"localhost:7233\")\n    client = await Client.connect(address)\n    worker = Worker(\n        client,\n        task_queue=TASK_QUEUE,\n        workflows=[DocumentWorkflow],\n        activities=[generate_draft, revise_draft, persist_final],\n    )\n    print(\"Worker started on task queue:\", TASK_QUEUE)\n    await worker.run()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 6: Build the Client\n\nThe client starts workflows, sends signals (for edits and approval), queries status, and waits for results. This emulates human interaction with the workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile client.py\n# client.py\n# Purpose: Start, signal, and query the document approval workflow.\n\nimport asyncio\nimport os\nimport time\nfrom temporalio.client import Client\nfrom workflow import DocumentWorkflow\n\nTASK_QUEUE = \"doc-approval-q\"\n\nasync def main():\n    \"\"\"\n    Start a new workflow, submit edits, approve, and print results.\n\n    Raises:\n        Exception: If workflow or client operations fail.\n    \"\"\"\n    address = os.getenv(\"TEMPORAL_ADDRESS\", \"localhost:7233\")\n    client = await Client.connect(address)\n\n    workflow_id = f\"doc-approval-{int(time.time())}\"\n    handle = await client.start_workflow(\n        DocumentWorkflow.run,\n        id=workflow_id,\n        task_queue=TASK_QUEUE,\n        args=[\"doc-123\", \"Draft a two-paragraph product summary for ACME TurboWidget.\"],\n    )\n    print(\"Started workflow:\", workflow_id)\n\n    status = await handle.query(DocumentWorkflow.status)\n    print(\"Initial status:\", status)\n\n    await handle.signal(DocumentWorkflow.submit_edit, \"Please emphasize safety and warranty; remove pricing details.\")\n\n    status = await handle.query(DocumentWorkflow.status)\n    print(\"After edits:\", status)\n\n    await handle.signal(DocumentWorkflow.approve)\n\n    result = await handle.result()\n    print(\"Final result:\", result)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run and Validate\n\n**Start the Temporal dev server** in a terminal:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temporal server start-dev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Start the worker** in a second terminal:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "python worker.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Run the client** in a third terminal:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "python client.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You'll see output showing the workflow ID, initial status, status after edits, and the final persisted document. Check the `storage/` directory for JSON files keyed by `(doc_id, version)` to verify idempotency.\n\n**Test retry behavior** by setting `FAIL_FIRST=1` before running the client:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "export FAIL_FIRST=1\npython client.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first `generate_draft` call will fail with a transient error, then Temporal will retry automatically with exponential backoff. The workflow completes successfully on the second attempt, demonstrating durable retries.\n\n**Test non-retryable errors** by modifying the prompt in `client.py` to be too short (e.g., `\"Hi\"`). The workflow will fail immediately with a `ValidationError` and not retry, showing how to short-circuit bad inputs.\n\n**Inspect workflow history** in the Temporal Web UI at `http://localhost:8233`. Search for your workflow ID to see the full event log, including activity executions, signals, and retries.\n\n## Conclusion\n\nYou've built a production-grade, human-in-the-loop document approval workflow using Temporal and OpenAI. The system generates drafts, waits for human signals (edits or approval), applies revisions idempotently, and persists the final documentâ€”all while handling transient failures and maintaining full auditability.\n\n**Key takeaways:**\n\n- **Activities encapsulate side effects** (LLM calls, storage) to keep workflows deterministic\n- **Idempotency via storage keys** prevents duplicate LLM calls on retries\n- **Signals enable human-in-the-loop** without polling or timeouts\n- **RetryPolicy uses exponential backoff** to tame transient failures and bounds attempts with `maximum_attempts`\n- **ValidationError short-circuits bad inputs** to avoid wasting retries\n\n**Next steps:**\n\n- **Add multi-stage approvals**: Extend the workflow to require multiple approvers (e.g., editor, legal, exec) with separate signals and state tracking\n- **Integrate Temporal Cloud**: Deploy to Temporal Cloud for managed infrastructure, encryption at rest, and global namespaces\n- **Add metrics and alerts**: Instrument activities with custom metrics (e.g., LLM latency, token usage) and set up alerts for retry exhaustion or validation failures\n- **Implement versioning**: Use Temporal's versioning API to safely deploy workflow changes without breaking in-flight executions\n- **Chunk large documents**: Split long documents into paragraphs, process in parallel activities, and merge results deterministically\n- **Enhance visibility**: Add custom search attributes (e.g., `doc_id`, `status`) to enable filtering and dashboards in the Temporal Web UI\n- **Secure API keys**: Use Temporal's data converter API to encrypt sensitive payloads (e.g., prompts, drafts) in workflow history"
      ]
    }
  ],
  "metadata": {
    "title": "Build Durable LLM Workflows with temporal-python-sdk [2025 Guide]",
    "description": "Ship production-grade document workflows using Temporal Python SDK signals for human approvals, safe retries, and idempotent activities that survive restarts.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}