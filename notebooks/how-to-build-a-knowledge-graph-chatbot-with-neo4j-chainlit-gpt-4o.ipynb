{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pMT6K5l3dqU"
      },
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n",
        "\n",
        "**Title:** How to Build a Knowledge Graph Chatbot with Neo4j, Chainlit, GPT-4o\n",
        "\n",
        "**Description:** Ship a Python knowledge graph chatbot using Neo4j, Chainlit, and GPT-4oâ€”auto-generate Cypher, visualize results, and answer complex data questions accurately.\n",
        "\n",
        "---\n",
        "\n",
        "*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR1jM0MP3dqX"
      },
      "source": [
        "Knowledge graphs excel at modeling complex relationships. But querying them usually requires Cypher. That creates a barrier for non\\-technical users. This tutorial shows you how to build a production\\-ready chatbot that translates natural language questions into Cypher queries. It executes them against Neo4j and returns both tabular results and interactive visualizations. Youâ€™ll wire together GPT\\-4\\.1 for query generation, Neo4j for graph storage, CrewAI for agent orchestration, and Chainlit for a conversational UI. By the end, youâ€™ll have a working system that handles multi\\-hop reasoning, enforces read\\-only safety, and gracefully manages errors. This solves the common pain points of LLM hallucinations, brittle SQL generation, and UI plumbing. This build is fully runnable in a Colab notebook, with incremental validation at each step.\n",
        "\n",
        "We will use the same graph that you built in a previous article. If you need a refresher on constructing the initial knowledge graph and embedding pipeline, you can revisit our [step\\-by\\-step guide to building a Knowledge Graph RAG system with Neo4j and embeddings](/article/how-to-build-a-knowledge-graph-rag-pipeline-with-neo4j-embeddings-2).\n",
        "\n",
        "---\n",
        "\n",
        "## Why This Approach Works\n",
        "\n",
        "**Graphs over tables.** Relational databases struggle with multi\\-hop queries like friends\\-of\\-friends or recommendation paths. Neo4jâ€™s native graph traversal makes those queries fast and expressive.\n",
        "\n",
        "**GPT\\-4\\.1 for Cypher generation.** GPT\\-4\\.1 has strong language understanding and produces reliable structured output when given schema context and examples. This removes the need for hand\\-coded query templates. It adapts well if your schema evolves.\n",
        "\n",
        "**CrewAI for orchestration.** CrewAI offers a lightweight agent framework. It manages tool invocation and conversation flow without forcing you to build a custom orchestration layer. For a deeper dive into orchestrating multi\\-agent systems, see our [tutorial on building multi\\-agent AI systems with CrewAI and YAML](/article/how-to-build-multi-agent-ai-systems-with-crewai-and-yaml-2).\n",
        "\n",
        "**Chainlit for UI.** Chainlit gives you a chat interface with minimal boilerplate. It supports streaming, tables, and charts out of the box. You focus on backend logic, not frontend plumbing.\n",
        "\n",
        "**Read\\-only enforcement.** By restricting Cypher to MATCH, RETURN, and CALL, and using a read\\-only Neo4j role, you prevent accidental or malicious writes. That makes the system safe for production use.\n",
        "\n",
        "---\n",
        "\n",
        "## Setup \\& Installation\n",
        "\n",
        "Run this cell to install all dependencies with pinned versions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gfyWC9Yw3dqY"
      },
      "outputs": [],
      "source": [
        "%pip install -q neomodel crewai[tools] openai chainlit python-dotenv plotly pandas requests==2.32.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSBOoQFm3dqZ"
      },
      "source": [
        "Next, make sure you've got all required environment variables set before moving forward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SolfflJA3dqZ",
        "outputId": "1809d4ab-7ade-4d76-a8a3-5b1edcab5324"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating/updating .env with values from Colab User Secrets.\n",
            "All required environment variables found and loaded from .env.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from google.colab import userdata # Import userdata\n",
        "\n",
        "required_keys = [\"NEO4J_URI\", \"NEO4J_USERNAME\", \"NEO4J_PASSWORD\", \"OPENAI_API_KEY\", \"OPENAI_MODEL\"]\n",
        "\n",
        "env_file_path = '.env'\n",
        "\n",
        "# Check for missing keys in userdata first\n",
        "missing_in_userdata = [k for k in required_keys if not userdata.get(k)]\n",
        "if missing_in_userdata:\n",
        "    raise EnvironmentError(\n",
        "        f\"Missing required environment variables in Colab User Secrets (userdata): {', '.join(missing_in_userdata)}\\n\"\n",
        "        \"Please add them to Colab's 'Secrets' tab and re-run this cell.\"\n",
        "    )\n",
        "\n",
        "# Create or update .env file with values from userdata\n",
        "print(f\"Creating/updating {env_file_path} with values from Colab User Secrets.\")\n",
        "with open(env_file_path, 'w') as f:\n",
        "    for key in required_keys:\n",
        "        value = userdata.get(key)\n",
        "        f.write(f\"{key}={value}\\n\")\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv(dotenv_path=env_file_path)\n",
        "\n",
        "# Final check to ensure all required variables are loaded into the environment\n",
        "missing_after_load = [k for k in required_keys if not os.getenv(k)]\n",
        "if missing_after_load:\n",
        "    raise EnvironmentError(f\"Failed to load required environment variables from {env_file_path}: {', '.join(missing_after_load)}\")\n",
        "\n",
        "print(f\"All required environment variables found and loaded from {env_file_path}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNVBtY043dqZ"
      },
      "source": [
        "---\n",
        "\n",
        "## Step\\-by\\-Step Implementation\n",
        "\n",
        "### Step 1: Connect to Neo4j and Validate\n",
        "\n",
        "Create the directory structure and write the Neo4j connection module. This module normalizes the URI, initializes the connection, and provides a test function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HI2DFVvI3dqa"
      },
      "outputs": [],
      "source": [
        "!mkdir -p tools utils config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnjuiZKh3dqa",
        "outputId": "25654cf5-9484-4bb7-cc42-15ae95f0428b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tools/query_knowledge_graph.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile tools/query_knowledge_graph.py\n",
        "import os\n",
        "from typing import Any, Dict, List, Tuple, Optional\n",
        "from neomodel import db, config as neo_config\n",
        "from dotenv import load_dotenv\n",
        "from urllib.parse import unquote, urlparse # Import unquote and urlparse for URL decoding and parsing\n",
        "from neo4j import GraphDatabase # Import GraphDatabase driver\n",
        "\n",
        "# Load environment variables from .env\n",
        "load_dotenv()\n",
        "\n",
        "required_keys = [\"NEO4J_URI\", \"NEO4J_USERNAME\", \"NEO4J_PASSWORD\"]\n",
        "missing = [k for k in required_keys if not os.getenv(k)]\n",
        "if missing:\n",
        "    raise EnvironmentError(\n",
        "        f\"Missing required environment variables: {', '.join(missing)}\\n\"\n",
        "        \"Please set them before running the application.\" # Now refers to .env\n",
        "    )\n",
        "\n",
        "print(\"All required Neo4j environment variables found.\")\n",
        "\n",
        "def _normalize_neo4j_uri(uri: str) -> str:\n",
        "    print(f\"DEBUG: _normalize_neo4j_uri - Original URI: {uri}\")\n",
        "    # First, URL-decode the URI to handle any encoded characters like '%3A'\n",
        "    decoded_uri = unquote(uri)\n",
        "    print(f\"DEBUG: _normalize_neo4j_uri - Decoded URI: {decoded_uri}\")\n",
        "\n",
        "    # Parse the URI components\n",
        "    parsed_uri = urlparse(decoded_uri)\n",
        "    hostname = parsed_uri.hostname\n",
        "    # Ensure port is always present, default to 7687 if not specified\n",
        "    port = parsed_uri.port if parsed_uri.port else 7687\n",
        "\n",
        "    # Construct the final bolt URI without credentials in the URL, as per new neo4j driver requirements\n",
        "    final_bolt_uri = f\"bolt://{hostname}:{port}\"\n",
        "    print(f\"DEBUG: _normalize_neo4j_uri - Final canonical Bolt URI without credentials: {final_bolt_uri}\")\n",
        "    return final_bolt_uri\n",
        "\n",
        "\n",
        "def init_neo4j_connection() -> None:\n",
        "    uri = os.getenv(\"NEO4J_URI\")\n",
        "    user = os.getenv(\"NEO4J_USERNAME\")\n",
        "    pwd = os.getenv(\"NEO4J_PASSWORD\")\n",
        "\n",
        "    print(f\"DEBUG: init_neo4j_connection - NEO4J_URI (from env): {uri}\")\n",
        "    print(f\"DEBUG: init_neo4j_connection - NEO4J_USERNAME (from env): {user}\")\n",
        "    # print(f\"DEBUG: init_neo4j_connection - NEO4J_PASSWORD (from env): {pwd[0]}... (hidden)\") # Don't print full password\n",
        "\n",
        "    if not uri or not user or not pwd:\n",
        "        raise RuntimeError(\"Missing Neo4j credentials.\")\n",
        "\n",
        "    # Determine if SSL is needed from the original URI\n",
        "    is_encrypted = uri.startswith(\"neo4j+s://\") # Use original URI to check for +s\n",
        "    print(f\"DEBUG: init_neo4j_connection - Is encrypted connection: {is_encrypted}\")\n",
        "\n",
        "    # Normalize URI to bolt://host:port format (without credentials)\n",
        "    clean_bolt_uri = _normalize_neo4j_uri(uri)\n",
        "    print(f\"DEBUG: init_neo4j_connection - Clean Bolt URI for neomodel and driver: {clean_bolt_uri}\")\n",
        "\n",
        "    # Set DATABASE_URL with clean URI for neomodel's internal parsing\n",
        "    neo_config.DATABASE_URL = clean_bolt_uri\n",
        "    neo_config.MAX_POOL_SIZE = 20\n",
        "    # These are not strictly necessary if driver is passed, but keeping for clarity\n",
        "    neo_config.NEO4J_USERNAME = user\n",
        "    neo_config.NEO4J_PASSWORD = pwd\n",
        "    neo_config.ENCRYPTED = is_encrypted\n",
        "\n",
        "    # Explicitly create the neo4j driver, passing auth separately\n",
        "    driver = GraphDatabase.driver(clean_bolt_uri, auth=(user, pwd), encrypted=is_encrypted)\n",
        "\n",
        "    # Pass the instantiated driver to neomodel's set_connection\n",
        "    db.set_connection(driver=driver)\n",
        "    print(\"Neo4j connection initialized.\")\n",
        "\n",
        "\n",
        "def test_connection() -> Tuple[List[Tuple[Any]], List[Dict[str, Any]]]:\n",
        "    return db.cypher_query(\"RETURN 'Connection successful' AS message\")\n",
        "\n",
        "\n",
        "def safe_init() -> None:\n",
        "    try:\n",
        "        init_neo4j_connection()\n",
        "        res, _ = test_connection()\n",
        "        print(f\"Neo4j: {res[0][0]}\")\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Neo4j connection failed: {e}\")\n",
        "\n",
        "\n",
        "def run_cypher(cypher: str, params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
        "    cypher_lower = cypher.strip().lower()\n",
        "    unsafe_keywords = [\"create\", \"merge\", \"delete\", \"set\", \"remove\", \"detach\"]\n",
        "    if any(kw in cypher_lower for kw in unsafe_keywords):\n",
        "        return {\"error\": \"Unsafe Cypher detected. Only read-only queries allowed.\", \"columns\": [], \"rows\": [], \"data\": []}\n",
        "\n",
        "    try:\n",
        "        results, columns = db.cypher_query(cypher, params or {}) # Corrected: meta is now columns\n",
        "        rows = [list(r) for r in results]\n",
        "        data = [dict(zip(columns, row)) for row in rows]\n",
        "        return {\"columns\": columns, \"rows\": rows, \"data\": data}\n",
        "    except Exception as e:\n",
        "        print(f\"Cypher execution error: {e}\")\n",
        "        return {\"error\": str(e), \"columns\": [], \"rows\": [], \"data\": []}\n",
        "\n",
        "\n",
        "def query_knowledge_graph(nl_query: str, cypher: str, params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
        "    result = run_cypher(cypher, params)\n",
        "    result[\"nl_query\"] = nl_query\n",
        "    result[\"cypher\"] = cypher\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAkOFace3dqa"
      },
      "source": [
        "Test the connection:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD32fNA73dqb",
        "outputId": "e60f83b7-f453-45f8-f218-8de0f25b40cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All required Neo4j environment variables found.\n",
            "DEBUG: init_neo4j_connection - NEO4J_URI (from env): neo4j+s://02fd3f4e.databases.neo4j.io\n",
            "DEBUG: init_neo4j_connection - NEO4J_USERNAME (from env): neo4j\n",
            "DEBUG: init_neo4j_connection - Is encrypted connection: True\n",
            "DEBUG: _normalize_neo4j_uri - Original URI: neo4j+s://02fd3f4e.databases.neo4j.io\n",
            "DEBUG: _normalize_neo4j_uri - Decoded URI: neo4j+s://02fd3f4e.databases.neo4j.io\n",
            "DEBUG: _normalize_neo4j_uri - Final canonical Bolt URI without credentials: bolt://02fd3f4e.databases.neo4j.io:7687\n",
            "DEBUG: init_neo4j_connection - Clean Bolt URI for neomodel and driver: bolt://02fd3f4e.databases.neo4j.io:7687\n",
            "Neo4j connection initialized.\n",
            "Neo4j: Connection successful\n",
            "{'columns': ['one'], 'rows': [[1]], 'data': [{'one': 1}]}\n",
            "{'columns': ['nodes'], 'rows': [[86]], 'data': [{'nodes': 86}]}\n"
          ]
        }
      ],
      "source": [
        "from tools.query_knowledge_graph import safe_init, run_cypher\n",
        "\n",
        "safe_init()\n",
        "print(run_cypher(\"RETURN 1 AS one\"))\n",
        "print(run_cypher(\"MATCH (n) RETURN count(n) AS nodes LIMIT 1\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3vWXiEG3dqb"
      },
      "source": [
        "Expected output: `{'columns': ['one'], 'rows': [[1]], 'data': [{'one': 1}]}` and a node count.\n",
        "\n",
        "---\n",
        "\n",
        "### Step 2: Define Agent and Task Configuration\n",
        "\n",
        "Write the agent and task YAML files. The agent uses GPT\\-4\\.1 and the knowledge graph tool to generate and execute Cypher queries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uhGq8Gj3dqb",
        "outputId": "dacb3f91-9256-4421-fa40-85b9047b1d31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing config/agents.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile config/agents.yaml\n",
        "cypher_agent:\n",
        "  role: \"Knowledge Graph Query Specialist\"\n",
        "  goal: \"Generate accurate Cypher queries from natural language and return results.\"\n",
        "  backstory: |\n",
        "    You are an expert in Neo4j and Cypher. Given a schema and a question, you produce a valid Cypher query.\n",
        "    You always return the query in a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9bqmWpX3dqb"
      },
      "source": [
        "cypher code block, followed by any chart configuration in a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgB6qS9D3dqb"
      },
      "source": [
        "```json\n",
        "block if visualization is requested.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_fKSnVS3dqc",
        "outputId": "7f41914e-c502-4e0d-ec8e-f00730725f17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting config/tasks.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile config/tasks.yaml\n",
        "generate_and_execute_query:\n",
        "  description: |\n",
        "    Given the question: {question}\n",
        "    And the schema: {schema}\n",
        "    Generate a Cypher query to answer it. Return the query in a block with chart config (type, x, y, title).\n",
        "  expected_output: |\n",
        "    A block with chart config.\n",
        "  agent: cypher_agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk0H2jZi3dqc"
      },
      "source": [
        "---\n",
        "\n",
        "### Step 3: Build the CrewAI Agent and Tool\n",
        "\n",
        "Create a utility to load YAML configuration:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEmnPWaq3dqc",
        "outputId": "f31bc92d-053b-4207-c697-817d39b81824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing utils/yaml_loader.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile utils/yaml_loader.py\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "def load_yaml(file_path: str):\n",
        "    with open(Path(file_path), \"r\") as f:\n",
        "        return yaml.safe_load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqA06zIB3dqc"
      },
      "source": [
        "Define the CrewAI tool wrapper for the knowledge graph query function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05AMbRNk3dqc",
        "outputId": "6c42ac53-c1aa-43d4-db66-c1b96184c8de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tools/__init__.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile tools/__init__.py\n",
        "from crewai_tools import tool\n",
        "from .query_knowledge_graph import query_knowledge_graph\n",
        "\n",
        "@tool(\"Query Knowledge Graph\")\n",
        "def query_knowledge_graph_tool(nl_query: str, cypher: str) -> dict:\n",
        "    \"\"\"\n",
        "    Execute a Cypher query against the Neo4j knowledge graph.\n",
        "    Args:\n",
        "        nl_query (str): The natural language question.\n",
        "        cypher (str): The Cypher query to execute.\n",
        "    Returns:\n",
        "        dict: Query results with columns, rows, and data.\n",
        "    \"\"\"\n",
        "    return query_knowledge_graph(nl_query, cypher)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1V3vFzDo3dqd"
      },
      "source": [
        "Assemble the agent and task. This cell creates the agent, attaches the tool, and defines the task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfChv4TK3dqd",
        "outputId": "3e65c89f-c9c0-40ca-e511-4e20be7ef591"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing agent_setup.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile agent_setup.py\n",
        "import os\n",
        "from crewai import Agent, Task, Crew\n",
        "from langchain_openai import ChatOpenAI\n",
        "from tools import query_knowledge_graph_tool\n",
        "from utils.yaml_loader import load_yaml\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env\n",
        "load_dotenv()\n",
        "\n",
        "agents_config = load_yaml(\"config/agents.yaml\")\n",
        "tasks_config = load_yaml(\"config/tasks.yaml\")\n",
        "\n",
        "llm = ChatOpenAI(model=os.getenv(\"OPENAI_MODEL\"), temperature=0, openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "cypher_agent = Agent(\n",
        "    config=agents_config[\"cypher_agent\"],\n",
        "    tools=[query_knowledge_graph_tool],\n",
        "    llm=llm,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "def create_query_task(question: str, schema: str) -> Task:\n",
        "    return Task(\n",
        "        config=tasks_config[\"generate_and_execute_query\"],\n",
        "        agent=cypher_agent,\n",
        "        context={\"question\": question, \"schema\": schema}\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k33i34Qb3dqd"
      },
      "source": [
        "---\n",
        "\n",
        "### Step 4: Parse Agent Output and Execute Tool\n",
        "\n",
        "Write a parser to extract Cypher and chart JSON from the agentâ€™s response:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3nUhxrI3dqd",
        "outputId": "895cde0a-f2fc-4d63-e034-1a2ced0c5ecc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing utils/parser.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile utils/parser.py\n",
        "import re\n",
        "import json\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "def extract_cypher(text: str) -> Optional[str]:\n",
        "    match = re.search(r\"\", text, re.DOTALL | re.IGNORECASE)\n",
        "    return match.group(1).strip() if match else None\n",
        "\n",
        "def extract_chart_config(text: str) -> Optional[dict]:\n",
        "    match = re.search(r\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP6RXvla3dqd"
      },
      "source": [
        "cypher\\s+(.*?)\\s+"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZd9GsbD3dqd"
      },
      "outputs": [],
      "source": [
        "\", text, re.DOTALL | re.IGNORECASE)\n",
        "    return match.group(1).strip() if match else None\n",
        "\n",
        "def extract_chart_config(text: str) -> Optional[dict]:\n",
        "    match = re.search(r\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9V7NOu13dqd"
      },
      "source": [
        "json\\s+(.*?)\\s+"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21bqZbyS3dqd"
      },
      "outputs": [],
      "source": [
        "\", text, re.DOTALL | re.IGNORECASE)\n",
        "    if match:\n",
        "        try:\n",
        "            return json.loads(match.group(1).strip())\n",
        "        except json.JSONDecodeError:\n",
        "            return None\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlbL_esB3dqd"
      },
      "source": [
        "Test the agent and parser with a sample question:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RimRc-A3dqd"
      },
      "outputs": [],
      "source": [
        "from agent_setup import cypher_agent, create_query_task\n",
        "from crewai import Crew\n",
        "from utils.parser import extract_cypher, extract_chart_config\n",
        "\n",
        "schema = \"\"\"\n",
        "Nodes: Person(name, age), Movie(title, year)\n",
        "Relationships: (Person)-[:ACTED_IN]->(Movie), (Person)-[:DIRECTED]->(Movie)\n",
        "\"\"\"\n",
        "\n",
        "question = \"Who acted in movies released after 2010?\"\n",
        "task = create_query_task(question, schema)\n",
        "crew = Crew(agents=[cypher_agent], tasks=[task], verbose=True)\n",
        "\n",
        "result = crew.kickoff()\n",
        "print(\"Agent output:\", result)\n",
        "\n",
        "cypher = extract_cypher(str(result))\n",
        "chart_config = extract_chart_config(str(result))\n",
        "print(\"Extracted Cypher:\", cypher)\n",
        "print(\"Chart config:\", chart_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7iq56sb3dqe"
      },
      "source": [
        "Expected output: A Cypher query like `MATCH (p:Person)-[:ACTED_IN]->(m:Movie) WHERE m.year > 2010 RETURN p.name, m.title` and optionally a chart config JSON.\n",
        "\n",
        "---\n",
        "\n",
        "### Step 5: Wire the Chainlit UI\n",
        "\n",
        "Create the Chainlit app. This app maintains conversation history, sends questions to the agent, extracts and executes Cypher, and renders results as tables and charts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enF3r5h93dqe"
      },
      "outputs": [],
      "source": [
        "%%writefile chat.py\n",
        "import os\n",
        "import chainlit as cl\n",
        "from crewai import Crew\n",
        "from agent_setup import cypher_agent, create_query_task\n",
        "from tools.query_knowledge_graph import query_knowledge_graph, safe_init\n",
        "from utils.parser import extract_cypher, extract_chart_config\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "\n",
        "safe_init()\n",
        "\n",
        "SCHEMA = \"\"\"\n",
        "Nodes: Person(name, age), Movie(title, year)\n",
        "Relationships: (Person)-[:ACTED_IN]->(Movie), (Person)-[:DIRECTED]->(Movie)\n",
        "\"\"\"\n",
        "\n",
        "@cl.on_chat_start\n",
        "async def start():\n",
        "    cl.user_session.set(\"history\", [])\n",
        "    await cl.Message(content=\"Ask me anything about the knowledge graph!\").send()\n",
        "\n",
        "@cl.on_message\n",
        "async def main(message: cl.Message):\n",
        "    question = message.content\n",
        "    history = cl.user_session.get(\"history\")\n",
        "    history.append({\"role\": \"user\", \"content\": question})\n",
        "\n",
        "    task = create_query_task(question, SCHEMA)\n",
        "    crew = Crew(agents=[cypher_agent], tasks=[task], verbose=False)\n",
        "\n",
        "    try:\n",
        "        result = crew.kickoff()\n",
        "        agent_output = str(result)\n",
        "        history.append({\"role\": \"assistant\", \"content\": agent_output})\n",
        "        cl.user_session.set(\"history\", history[-10:])\n",
        "\n",
        "        cypher = extract_cypher(agent_output)\n",
        "        chart_config = extract_chart_config(agent_output)\n",
        "\n",
        "        if not cypher:\n",
        "            await cl.Message(content=\"Could not extract a valid Cypher query.\").send()\n",
        "            return\n",
        "\n",
        "        query_result = query_knowledge_graph(question, cypher)\n",
        "\n",
        "        if \"error\" in query_result:\n",
        "            await cl.Message(content=f\"Query error: {query_result['error']}\").send()\n",
        "            return\n",
        "\n",
        "        df = pd.DataFrame(query_result[\"data\"])\n",
        "        table_md = df.to_markdown(index=False)\n",
        "        await cl.Message(content=f\"**Results:**\\n\\n{table_md}\").send()\n",
        "\n",
        "        if chart_config and not df.empty:\n",
        "            chart_type = chart_config.get(\"type\", \"bar\")\n",
        "            x_col = chart_config.get(\"x\")\n",
        "            y_col = chart_config.get(\"y\")\n",
        "            title = chart_config.get(\"title\", \"Chart\")\n",
        "\n",
        "            if x_col in df.columns and y_col in df.columns:\n",
        "                if chart_type == \"bar\":\n",
        "                    fig = go.Figure(data=[go.Bar(x=df[x_col], y=df[y_col])])\n",
        "                elif chart_type == \"line\":\n",
        "                    fig = go.Figure(data=[go.Scatter(x=df[x_col], y=df[y_col], mode='lines+markers')])\n",
        "                else:\n",
        "                    fig = go.Figure(data=[go.Bar(x=df[x_col], y=df[y_col])])\n",
        "\n",
        "                fig.update_layout(title=title, xaxis_title=x_col, yaxis_title=y_col)\n",
        "                await cl.Message(content=\"\", elements=[cl.Plotly(name=\"chart\", figure=fig)]).send()\n",
        "\n",
        "    except Exception as e:\n",
        "        await cl.Message(content=f\"Error: {str(e)}\").send()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C5VHR3r3dqe"
      },
      "source": [
        "Run the Chainlit app. In Colab, you can use a tunnel service like ngrok to expose the app publicly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwkSP76C3dqe"
      },
      "outputs": [],
      "source": [
        "!chainlit run chat.py --host 0.0.0.0 --port 8000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbKmIScF3dqe"
      },
      "source": [
        "For local development, simply run `chainlit run chat.py` and open the provided URL.\n",
        "\n",
        "---\n",
        "\n",
        "### Step 6: Validate End\\-to\\-End\n",
        "\n",
        "Test the system with a sample question. This cell simulates the agent workflow without the UI:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmdGKETR3dqe"
      },
      "outputs": [],
      "source": [
        "from agent_setup import cypher_agent, create_query_task\n",
        "from crewai import Crew\n",
        "from tools.query_knowledge_graph import query_knowledge_graph\n",
        "from utils.parser import extract_cypher\n",
        "\n",
        "schema = \"\"\"\n",
        "Nodes: Person(name, age), Movie(title, year)\n",
        "Relationships: (Person)-[:ACTED_IN]->(Movie)\n",
        "\"\"\"\n",
        "\n",
        "question = \"List all actors and their movies\"\n",
        "task = create_query_task(question, schema)\n",
        "crew = Crew(agents=[cypher_agent], tasks=[task], verbose=False)\n",
        "\n",
        "result = crew.kickoff()\n",
        "cypher = extract_cypher(str(result))\n",
        "print(\"Generated Cypher:\", cypher)\n",
        "\n",
        "if cypher:\n",
        "    query_result = query_knowledge_graph(question, cypher)\n",
        "    print(\"Query result:\", query_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLKh05EE3dqp"
      },
      "source": [
        "Expected output: A Cypher query and a result dictionary with `columns`, `rows`, and `data`.\n",
        "\n",
        "---\n",
        "\n",
        "## Production Considerations\n",
        "\n",
        "**Read\\-only enforcement.** Use a Neo4j role with read\\-only permissions. The `run_cypher` function already rejects unsafe keywords. Check your Neo4j user setup to enforce this.\n",
        "\n",
        "**Error handling and retries.** Wrap OpenAI and Neo4j calls in retry logic with exponential backoff. Use libraries like `tenacity` to handle transient 429 or network errors.\n",
        "\n",
        "**Token and cost control.** Limit conversation history to the last 10 messages. Prune or summarize older context. Monitor token usage per request. Set budget alerts in your OpenAI dashboard.\n",
        "\n",
        "**Logging and observability.** Add correlation IDs to each request. Log Cypher queries, parameters, execution time, and errors. Use structured logging (JSON) for easy parsing and alerting.\n",
        "\n",
        "**Schema versioning.** Store schema definitions in version control. Update prompts when the schema changes. Test queries against a staging graph before you deploy to production.\n",
        "\n",
        "**Caching.** Cache normalized Cypher queries with a hash key. Return saved results for repeated questions. Use an LRU cache with TTL. For deeper optimization, consider adding semantic caching with Redis Vector to reuse similar queries using embeddings.\n",
        "\n",
        "**Testing.** Write unit tests for `run_cypher`, `extract_cypher`, and `extract_chart_config`. Create integration tests that validate end\\-to\\-end flows with seed data. Assert expected column names, row counts, and chart configs.\n",
        "\n",
        "For more guidance on prompt reliability and deterministic outputsâ€”especially when using LLMs for structured tasksâ€”see our [guide to prompt engineering with LLM APIs](/article/prompt-engineering-with-llm-apis-how-to-get-reliable-outputs-3). If your use case involves extracting structured data or building pipelines that require zero hallucinations, our [structured data extraction with LLMs pipeline tutorial](/article/structured-data-extraction-with-llms-how-to-build-a-pipeline-3) provides practical patterns and code.\n",
        "\n",
        "---\n",
        "\n",
        "## Conclusion and Next Steps\n",
        "\n",
        "Youâ€™ve built a knowledge graph chatbot that translates natural language into Cypher, executes queries safely, and visualizes results. The system uses GPT\\-4\\.1 for query generation, CrewAI for orchestration, and Chainlit for a conversational UI. Youâ€™ve implemented read\\-only enforcement, error handling, and incremental validation at each step.\n",
        "\n",
        "**Next steps:**\n",
        "\n",
        "* **Swap LLMs.** You can replace GPT\\-4\\.1 with another model such as Claude or Llama by changing the `llm` parameter in `agent_setup.py`. Test prompt compatibility and adjust schema examples if needed. For a hands\\-on walkthrough of building LLM agents from scratch, including reasoning and action patterns, check out our [tutorial on building an LLM agent with GPT\\-4 ReAct](/article/how-to-build-an-llm-agent-from-scratch-with-gpt-4-react-5).\n",
        "* **Add RAG for schema context.** If your schema is large or dynamic, embed schema documentation and retrieve relevant subsets before query generation. See the [guide to structured data extraction with LLMs](/article/structured-data-extraction-with-llms-how-to-build-a-pipeline-3) for best practices on deterministic outputs.\n",
        "* **Integrate with external APIs.** Extend the agent with additional tools (for example REST API calls or database lookups) to enrich query results or trigger actions based on graph insights.\n",
        "* **Deploy to production.** Containerize the app with Docker. Set up environment\\-specific configs. Deploy to a cloud platform like AWS, GCP, or Azure. Use a reverse proxy such as nginx and enable HTTPS.\n",
        "* **Build stateful workflows.** For more complex agent behaviors, explore [building a stateful AI agent with LangGraph](/article/how-to-build-a-stateful-ai-agent-with-langgraph-step-by-step-5) to manage multi\\-turn conversations and conditional logic.\n",
        "\n",
        "Begin!"
      ]
    }
  ],
  "metadata": {
    "title": "How to Build a Knowledge Graph Chatbot with Neo4j, Chainlit, GPT-4o",
    "description": "Ship a Python knowledge graph chatbot using Neo4j, Chainlit, and GPT-4oâ€”auto-generate Cypher, visualize results, and answer complex data questions accurately.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}