{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** How to Build a Knowledge Graph Chatbot with Neo4j, Chainlit, GPT-4o\n\n**Description:** Ship a Python knowledge graph chatbot using Neo4j, Chainlit, and GPT-4oâ€”auto-generate Cypher, visualize results, and answer complex data questions accurately.\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Knowledge graph chatbots combine the precision of structured data with the flexibility of natural language. This guide walks you through building a production-ready Python chatbot that queries a Neo4j graph database using GPT-4o, CrewAI for agent orchestration, and Chainlit for the UI. By the end, you'll have a working app that answers questions, generates Cypher queries, and renders interactive chartsâ€”all runnable locally with minimal setup.\n\n## What You're Building\n\nA conversational interface that:\n\n- Accepts natural language questions about your graph\n- Generates and executes Cypher queries via GPT-4o\n- Returns structured results as text, tables, and Plotly charts\n- Maintains conversation context across multiple turns\n\nYou'll integrate Neo4j for graph storage, CrewAI for agent orchestration (providing built-in memory and standardized tool calling), and Chainlit for a chat UI. This architecture is extensible: add more agents, tools, or data sources as your use case grows.\n\n## Prerequisites\n\n- Python 3.10+\n- Neo4j Aura account (free tier) or local Neo4j instance\n- OpenAI API key with GPT-4o access\n- Basic familiarity with Python, environment variables, and command-line tools\n\n## Setup & Installation\n\nCreate a project directory and virtual environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mkdir kg-chatbot && cd kg-chatbot\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install dependencies with pinned versions to ensure compatibility:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install chainlit==1.0.200 neomodel==5.2.1 plotly==5.18.0 crewai==0.28.0 pyyaml==6.0.1 python-dotenv==1.0.0 openai==1.12.0 neo4j==5.16.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a `.env` file in the project root with your credentials:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "OPENAI_API_KEY=sk-...\nNEO4J_URI=neo4j+s://your-instance.databases.neo4j.io\nNEO4J_USER=neo4j\nNEO4J_PASSWORD=your-password\nNEO4J_DATABASE=neo4j"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Project Structure\n\nOrganize your code into the following files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "kg-chatbot/\nâ”œâ”€â”€ .env\nâ”œâ”€â”€ tools/\nâ”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”œâ”€â”€ db.py\nâ”‚   â”œâ”€â”€ query_knowledge_graph.py\nâ”‚   â””â”€â”€ _demo.py\nâ”œâ”€â”€ agents.yaml\nâ”œâ”€â”€ tasks.yaml\nâ”œâ”€â”€ agents.py\nâ””â”€â”€ chat.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the `tools/` directory and an empty `__init__.py`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mkdir tools\ntouch tools/__init__.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Initialize the Neo4j Connection\n\nThis module loads environment variables, converts the Neo4j URI to a Bolt-compatible format for neomodel, and tests connectivity. Using neomodel simplifies Cypher execution and provides a consistent interface for future ODM features if needed.\n\nCreate `tools/db.py`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\nimport re\nfrom dotenv import load_dotenv\nfrom neomodel import config, db\n\nload_dotenv()\n\ndef _to_bolt_uri(uri: str) -> str:\n    return re.sub(r\"^neo4j\\+s\", \"bolt+s\", uri)\n\ndef init_db():\n    uri = os.getenv(\"NEO4J_URI\")\n    user = os.getenv(\"NEO4J_USER\")\n    password = os.getenv(\"NEO4J_PASSWORD\")\n    database = os.getenv(\"NEO4J_DATABASE\", \"neo4j\")\n\n    if not uri or not user or not password:\n        raise RuntimeError(\"Missing Neo4j env vars: NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD\")\n\n    bolt_uri = _to_bolt_uri(uri)\n    config.DATABASE_URL = f\"{bolt_uri}/{database}\"\n    config.AUTH = (user, password)\n\ndef test_connection() -> bool:\n    try:\n        res, meta = db.cypher_query(\"RETURN 'Connection successful' AS msg\")\n        return res[0][0] == \"Connection successful\"\n    except Exception as e:\n        print(f\"Neo4j connection failed: {e}\")\n        return False\n\nif __name__ == \"__main__\":\n    init_db()\n    print(\"OK\" if test_connection() else \"FAIL\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test the connection:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "python tools/db.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You should see `OK` if credentials are correct.\n\n## Step 2: Seed Sample Data\n\nTo validate the chatbot end-to-end, seed a small synthetic dataset. This creates Person, Company, and Product nodes with relationships.\n\nRun the following Cypher in the Neo4j Browser or via a Python script:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```cypher\nCREATE (alice:Person {name: 'Alice', age: 30})\nCREATE (bob:Person {name: 'Bob', age: 35})\nCREATE (acme:Company {name: 'Acme Corp', industry: 'Tech'})\nCREATE (widget:Product {name: 'Widget', category: 'Hardware'})\nCREATE (alice)-[:WORKS_AT]->(acme)\nCREATE (bob)-[:WORKS_AT]->(acme)\nCREATE (alice)-[:PURCHASED]->(widget)\nCREATE (acme)-[:MAKES]->(widget)\n```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verify with:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```cypher\nMATCH (n) RETURN count(n) AS node_count\n```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You should see at least 4 nodes.\n\n## Step 3: Build the Query Tool\n\nThis tool encapsulates LLM-powered Cypher generation and execution. It accepts a natural language question, generates Cypher with GPT-4o, executes it via neomodel, and returns structured data. This keeps query logic reusable for any agent. If you're interested in building robust pipelines for extracting structured data from language models, our guide on [structured data extraction with LLMs](/article/structured-data-extraction-with-llms-how-to-build-a-pipeline) offers a deep dive into best practices for production-ready systems.\n\nCreate `tools/query_knowledge_graph.py`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\nimport json\nimport textwrap\nimport re\nfrom typing import Any, Dict, List, Optional, Tuple\n\nfrom openai import OpenAI\nfrom neomodel import db\n\nDEFAULT_SCHEMA = \"\"\"\nNode labels:\n- Person(name, age)\n- Company(name, industry)\n- Product(name, category)\nRelationships:\n- (Person)-[:WORKS_AT]->(Company)\n- (Person)-[:PURCHASED]->(Product)\n- (Company)-[:MAKES]->(Product)\n\"\"\"\n\nclass KnowledgeGraphQueryTool:\n    def __init__(self, schema: Optional[str] = None, model: str = \"gpt-4o\"):\n        api_key = os.getenv(\"OPENAI_API_KEY\")\n        if not api_key:\n            raise RuntimeError(\"OPENAI_API_KEY not set\")\n        self.client = OpenAI(api_key=api_key)\n        self.model = model\n        self.schema = schema or DEFAULT_SCHEMA\n\n    def generate_cypher(self, question: str) -> str:\n        system = \"You are a Cypher expert. Generate a single Cypher query. Do not include explanations.\"\n        prompt = f\"\"\"\n        Given this Neo4j schema:\n        {self.schema}\n\n        User question:\n        {question}\n\n        Constraints:\n        - Return concise columns with clear names.\n        - Prefer COUNT(), LIMIT, and WHERE for performance.\n        - Only output Cypher, no prose.\n        \"\"\"\n        resp = self.client.chat.completions.create(\n            model=self.model,\n            messages=[\n                {\"role\": \"system\", \"content\": system},\n                {\"role\": \"user\", \"content\": textwrap.dedent(prompt).strip()}\n            ],\n            temperature=0.1,\n        )\n        raw = resp.choices[0].message.content.strip()\n        cypher = re.sub(r\"^"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "cypher\\s*\", \"\", raw, flags=re.IGNORECASE)\n        cypher = re.sub(r\"\\s*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "$\", \"\", cypher)\n        return cypher.strip()\n\n    def execute_cypher(self, cypher: str) -> Tuple[List[Dict[str, Any]], List[str]]:\n        results, meta = db.cypher_query(cypher)\n        headers = [m['name'] for m in meta]\n        rows = [dict(zip(headers, row)) for row in results]\n        return rows, headers\n\n    def run(self, question: str) -> Dict[str, Any]:\n        try:\n            cypher = self.generate_cypher(question)\n            rows, headers = self.execute_cypher(cypher)\n            return {\n                \"ok\": True,\n                \"cypher\": cypher,\n                \"headers\": headers,\n                \"rows\": rows\n            }\n        except Exception as e:\n            print(f\"Error in KnowledgeGraphQueryTool.run: {e}\")\n            return {\n                \"ok\": False,\n                \"error\": str(e)\n            }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test the tool with a demo script. Create `tools/_demo.py`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tools.db import init_db\nfrom tools.query_knowledge_graph import KnowledgeGraphQueryTool\n\nif __name__ == \"__main__\":\n    init_db()\n    tool = KnowledgeGraphQueryTool()\n    print(tool.run(\"How many Person nodes are there?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "python tools/_demo.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You should see a result with `ok: True` and a count of 2.\n\n## Step 4: Define the Agent and Task\n\nCrewAI provides built-in memory, standardized tool calling, and a clear separation between agent configuration and task logic. This makes it easier to extend with multiple agents or tools later. We'll define the agent and task in YAML for clarity and maintainability.\n\nCreate `agents.yaml`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```yaml\ngraph_analyst:\n  role: \"Graph Data Analyst\"\n  goal: \"Answer user questions by querying the Neo4j knowledge graph accurately and concisely.\"\n  backstory: \"You are an expert in graph databases and Cypher. You translate natural language into precise queries and present results clearly.\"\n  tone: \"Professional, concise, and helpful.\"\n  instructions: |\n    - Use the query_knowledge_graph tool to answer questions.\n    - If the tool returns an error, explain it to the user and suggest rephrasing.\n    - If results are empty, state that clearly.\n    - When appropriate, suggest a chart to visualize the data.\n  schema: |\n    Node labels:\n    - Person(name, age)\n    - Company(name, industry)\n    - Product(name, category)\n    Relationships:\n    - (Person)-[:WORKS_AT]->(Company)\n    - (Person)-[:PURCHASED]->(Product)\n    - (Company)-[:MAKES]->(Product)\n```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create `tasks.yaml`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```yaml\nanswer_question:\n  description: |\n    Answer the user's question using the knowledge graph.\n    User question: {question}\n    Conversation history:\n    {history}\n  expected_output: |\n    A clear, concise answer with supporting data.\n    If a chart is appropriate, include a JSON block with chart spec:\n```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "json\n    {\n      \"chart\": {\n        \"type\": \"bar\",\n        \"title\": \"Chart Title\",\n        \"x\": [\"label1\", \"label2\"],\n        \"y\": [10, 20]\n      }\n    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create `agents.py` to load these configs and build CrewAI components:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\nfrom pathlib import Path\nfrom typing import Any, Dict\n\nfrom crewai import Agent, Task, Crew, Process\nfrom crewai.tools import BaseTool\n\ndef load_yaml(path: str) -> Dict[str, Any]:\n    return yaml.safe_load(Path(path).read_text())\n\ndef build_graph_analyst() -> Agent:\n    data = load_yaml(\"agents.yaml\")[\"graph_analyst\"]\n    return Agent(\n        role=data[\"role\"],\n        goal=data[\"goal\"],\n        backstory=data[\"backstory\"],\n        allow_delegation=False,\n        verbose=True,\n        memory=True,\n        tools=[],\n    )\n\ndef build_answer_task() -> Task:\n    data = load_yaml(\"tasks.yaml\")[\"answer_question\"]\n    return Task(\n        description=data[\"description\"],\n        expected_output=data[\"expected_output\"],\n        agent=None,\n    )\n\ndef build_crew(agent: Agent, task: Task, tools: list) -> Crew:\n    agent.tools = tools\n    task.agent = agent\n    return Crew(\n        agents=[agent],\n        tasks=[task],\n        process=Process.sequential,\n        verbose=True\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Wrap the Tool for CrewAI\n\nCrewAI requires tools to inherit from `BaseTool`. This wrapper exposes the `KnowledgeGraphQueryTool` to the agent.\n\nAdd this class to `agents.py`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\nfrom tools.query_knowledge_graph import KnowledgeGraphQueryTool\n\nclass ToolWrapper(BaseTool):\n    name: str = \"query_knowledge_graph\"\n    description: str = \"Generate and execute Cypher to answer questions about the Neo4j graph.\"\n\n    def __init__(self, tool: KnowledgeGraphQueryTool):\n        super().__init__()\n        self.tool = tool\n\n    def _run(self, input: str) -> str:\n        result = self.tool.run(input)\n        return json.dumps(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Build the Chainlit Chat Interface\n\nThis module integrates CrewAI, Neo4j, and Plotly into a conversational UI. It maintains conversation history in the user session, passes it to the agent for context-aware responses, and renders charts and tables.\n\nCreate `chat.py`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n\nrequired_keys = [\"OPENAI_API_KEY\", \"NEO4J_URI\", \"NEO4J_USER\", \"NEO4J_PASSWORD\"]\nmissing = [k for k in required_keys if not os.getenv(k)]\nif missing:\n    raise EnvironmentError(\n        f\"Missing required environment variables: {', '.join(missing)}\\n\"\n        \"Please set them before running the app.\"\n    )\n\nimport re\nimport json\nfrom typing import Any, Dict, Optional\n\nimport chainlit as cl\nimport plotly.express as px\n\nfrom tools.db import init_db\nfrom tools.query_knowledge_graph import KnowledgeGraphQueryTool\nfrom agents import build_graph_analyst, build_answer_task, build_crew, ToolWrapper\n\ndef extract_chart_json(text: str) -> Optional[Dict[str, Any]]:\n    code_blocks = re.findall(r\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "json(.*?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\", text, re.DOTALL | re.IGNORECASE)\n    for block in code_blocks:\n        try:\n            data = json.loads(block.strip())\n            if isinstance(data, dict) and \"chart\" in data:\n                chart = data[\"chart\"]\n                if \"type\" in chart and (\"x\" in chart or \"labels\" in chart):\n                    return chart\n        except Exception:\n            continue\n    return None\n\ndef extract_cypher(text: str) -> Optional[str]:\n    blocks = re.findall(r\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "cypher(.*?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\", text, re.DOTALL | re.IGNORECASE)\n    return blocks[0].strip() if blocks else None\n\ndef render_chart(chart_spec: Dict[str, Any]):\n    ctype = chart_spec.get(\"type\", \"bar\")\n    title = chart_spec.get(\"title\", \"\")\n    if ctype == \"bar\":\n        fig = px.bar(x=chart_spec.get(\"x\", []), y=chart_spec.get(\"y\", []), title=title)\n    elif ctype == \"line\":\n        fig = px.line(x=chart_spec.get(\"x\", []), y=chart_spec.get(\"y\", []), title=title)\n    elif ctype == \"pie\":\n        fig = px.pie(names=chart_spec.get(\"labels\", []), values=chart_spec.get(\"values\", []), title=title)\n    else:\n        fig = px.bar(x=[], y=[], title=f\"Unsupported chart type: {ctype}\")\n    return fig\n\n@cl.on_chat_start\nasync def on_start():\n    init_db()\n    tool = KnowledgeGraphQueryTool()\n    agent = build_graph_analyst()\n    task = build_answer_task()\n    crew = build_crew(agent, task, tools=[ToolWrapper(tool)])\n    cl.user_session.set(\"crew\", crew)\n    cl.user_session.set(\"history\", [])\n    await cl.Message(content=\"Knowledge Graph Chatbot ready. Ask a question about your graph.\").send()\n\n@cl.on_message\nasync def on_message(message: cl.Message):\n    crew = cl.user_session.get(\"crew\")\n    history = cl.user_session.get(\"history\", [])\n    user_input = message.content\n\n    history.append(f\"User: {user_input}\")\n    history_blob = \"\\n\".join(history[-10:])\n\n    try:\n        result = crew.kickoff(\n            inputs={\n                \"question\": user_input,\n                \"history\": history_blob\n            }\n        )\n        text = result.raw if hasattr(result, \"raw\") else str(result)\n    except Exception as e:\n        await cl.Message(content=f\"Agent error: {e}\").send()\n        return\n\n    history.append(f\"Assistant: {text}\")\n    cl.user_session.set(\"history\", history)\n\n    elements = []\n\n    chart = extract_chart_json(text)\n    if chart:\n        fig = render_chart(chart)\n        elements.append(cl.Plotly(name=\"chart\", figure=fig))\n\n    cypher = extract_cypher(text)\n    if cypher:\n        text += \"\\n\\nExecuted Cypher:\\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "cypher\\n\" + cypher + \"\\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\n\n    await cl.Message(content=text, elements=elements).send()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run and Validate\n\nStart the Chainlit app:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chainlit run chat.py -w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Open the URL shown in your terminal (usually `http://localhost:8000`). Try these test queries:\n\n- \"How many Person nodes are there?\"\n- \"Who works at Acme Corp?\"\n- \"Show me a chart of people by age.\"\n\nYou should see:\n\n- Natural language answers\n- Generated Cypher queries (appended to responses)\n- Interactive Plotly charts when appropriate\n\nIf the tool returns an error, the agent will surface it with a suggestion to rephrase.\n\n## Conversation Memory Strategy\n\nUse short sliding windows and summaries to keep token counts low and context relevant. Store state server-side and avoid sending entire histories unnecessarily. For more on how LLMs handle and sometimes lose context as conversations grow, see our article on [context rot and LLM memory limitations](/article/context-rot-why-llms-forget-as-their-memory-grows).\n\nThe current implementation maintains the last 10 messages in `cl.user_session`. For longer conversations, consider:\n\n- Summarizing older messages with GPT-4o\n- Storing only the last N turns plus a summary\n- Using a vector store to retrieve relevant past exchanges\n\n## Query Caching\n\nCache frequent Cypher results keyed by normalized queries and parameters. For time-varying data, set short TTLs. This reduces cost and latency for repeated questions. To learn how semantic caching can further optimize your LLM-powered apps, check out our tutorial on [semantic caching with Redis Vector](/article/semantic-cache-llm-how-to-implement-with-redis-vector-to-cut-costs).\n\nAdd a simple in-memory cache to `KnowledgeGraphQueryTool`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from functools import lru_cache\n\n@lru_cache(maxsize=128)\ndef _cached_execute(self, cypher: str):\n    return self.execute_cypher(cypher)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For production, use Redis or Memcached with TTLs.\n\n## Security Considerations\n\nExecuting generated Cypher directly poses risks. Add safeguards:\n\n- Allowlist node labels and relationship types\n- Use read-only database credentials\n- Parameterize user-supplied literals\n- Validate generated queries against a schema\n\nExample allowlist check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ALLOWED_LABELS = {\"Person\", \"Company\", \"Product\"}\nALLOWED_RELS = {\"WORKS_AT\", \"PURCHASED\", \"MAKES\"}\n\ndef validate_cypher(cypher: str) -> bool:\n    labels = re.findall(r\":(\\w+)\", cypher)\n    rels = re.findall(r\"\\[:(\\w+)\\]\", cypher)\n    return all(l in ALLOWED_LABELS for l in labels) and all(r in ALLOWED_RELS for r in rels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Call this before executing queries and reject invalid ones.\n\n## Next Steps\n\n- Add multi-agent workflows for complex queries\n- Integrate vector search for hybrid retrieval\n- Deploy to production with authentication and rate limiting\n- Extend the schema and seed larger datasets\n\nYou now have a working knowledge graph chatbot that combines LLM reasoning with structured data precision. Use this foundation to build domain-specific assistants for customer support, analytics, or internal tooling."
      ]
    }
  ],
  "metadata": {
    "title": "How to Build a Knowledge Graph Chatbot with Neo4j, Chainlit, GPT-4o",
    "description": "Ship a Python knowledge graph chatbot using Neo4j, Chainlit, and GPT-4oâ€”auto-generate Cypher, visualize results, and answer complex data questions accurately.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}