{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìì The GenAI Revolution Cookbook\n\n**Title:** How to Build Multi-Agent AI Systems with CrewAI, Step by Step\n\n**Description:** Design scalable multi-agent AI systems with CrewAI using YAML configs, task delegation, tools, and training‚Äîthen build a Customer Feedback Analyst.\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here‚Äôs a revised version of your draft content. I‚Äôve aligned the code and config structure much more closely with *‚ÄúBuilding Multi\\-Agent AI Systems: A Practical Guide with CrewAI‚Äù* from The GenAI Revolution, while preserving your existing narrative, humanizing for clearer flow, and obeying your instruction rules.\n\n---\n\nGenerative AI gets useful when it ships. In this guide you'll build a Customer Feedback Analyst using CrewAI. You‚Äôll define agents in YAML, wire tasks and tools, run the system end\\-to\\-end, and produce a real report with sentiment tables and a pie chart. You‚Äôll learn the exact architecture and code so you can reuse it with your own data. If you like extracting structured data with LLMs, our [structured data extraction pipeline guide](/article/structured-data-extraction-with-llms-how-to-build-a-pipeline-3) walks you through best practices.\n\n## Why This Approach Works\n\nMulti\\-agent systems shine when you need specialized roles working together. A single LLM call can classify sentiment, but it struggles to read files, compute aggregates, generate charts, and assemble reports all in one go. By splitting those responsibilities across focused agents, you get modularity, clarity, and you can swap models or tools per task.\n\nCrewAI gives you a clean model for agents, tasks, tools, and crews. You define roles and workflows in YAML. You reduce boilerplate. You run sequential, hierarchical, or parallel processes with built\\-in context passing, delegation, and memory. To help your agents interoperate and audit more effectively, take a look at the [Model Context Protocol (MCP)](/article/model-context-protocol-mcp-explained-2025-guide-for-builders).\n\nIn this tutorial you‚Äôll use a sequential pipeline. Each task receives context from previous steps. That keeps logic simple and traceable.\n\n## How It Works\n\nThe pipeline has five stages:\n\n1. **Read feedback**: A file reader tool loads the CSV.\n2. **Classify sentiment**: An agent labels each row as positive, neutral, or negative, outputting JSONL.\n3. **Aggregate counts**: A Python tool parses the JSONL and computes sentiment totals deterministically.\n4. **Generate chart**: A tool creates a pie chart PNG from the aggregated counts.\n5. **Assemble report**: A writer agent combines the table and chart into a Markdown document.\n\nEach agent has a role, goal, backstory, and assigned tools. Tasks declare dependencies via context. The crew orchestrates execution. You‚Äôll get a final report with real artifacts.\n\n## What You‚Äôll Build\n\nBy the end, you‚Äôll have:\n\n* A `customer_feedback_report.md` with sentiment breakdown and insights.\n* A `sentiment_pie.png` chart visualizing the distribution.\n* A reusable pipeline you can adapt to other CSV datasets or feedback sources.\n\nYou‚Äôll run everything in a notebook or script. You‚Äôll validate outputs. You‚Äôll understand the design decisions behind each component.\n\n## Setup \\& Installation\n\nStart by installing dependencies and pinning versions to stay stable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install crewai[tools]==0.28.0 python-dotenv==1.0.0 pyyaml==6.0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set your API keys. If you‚Äôre in a notebook without a `.env` file, set them in session:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\nfrom dotenv import load_dotenv, find_dotenv\n\n<p>_ = load_dotenv(find_dotenv())</p>\n<p>os.environ[\"OPENAI_API_KEY\"] = \"your-openai-key-here\"\nos.environ[\"ANTHROPIC_API_KEY\"] = \"your-anthropic-key-here\"  # optional, if using Claude"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check the keys:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "required_keys = [\"OPENAI_API_KEY\"]\nmissing = [k for k in required_keys if not os.getenv(k)]\nif missing:\n    raise EnvironmentError(\n        f\"Missing required environment variables: {', '.join(missing)}\"\n        \" Please set them before running the notebook.\"\n    )\nprint(\"All required API keys found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step\\-by\\-Step Implementation\n\n### Define Tools\n\nTools are functions that agents call to carry out actions. You‚Äôll create a file reader, a sentiment aggregator, and a chart generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tools/__init__.py\nfrom crewai_tools import FileReadTool, tool\nimport json\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n<p>def make_file_reader(csv_path: str):\n    return FileReadTool(file_path=csv_path, description=\"Read customer_feedback.csv\")</p>\n<p>@tool(\"aggregate_sentiment\")\ndef aggregate_sentiment(jsonl_str: str) -> str:\n    lines = [ln.strip() for ln in jsonl_str.strip().split(\"\\n\") if ln.strip()]\n    records = [json.loads(ln) for ln in lines]\n    df = pd.DataFrame(records)\n    counts = df[\"sentiment\"].value_counts().to_dict()\n    result = {\n        \"positive\": counts.get(\"positive\", 0),\n        \"neutral\": counts.get(\"neutral\", 0),\n        \"negative\": counts.get(\"negative\", 0),\n    }\n    return json.dumps(result)</p>\n<p>@tool(\"make_sentiment_pie\")\ndef make_sentiment_pie(summary_json: str) -> str:\n    data = json.loads(summary_json)\n    counts = [data.get(\"positive\", 0), data.get(\"neutral\", 0), data.get(\"negative\", 0)]\n    labels = [\"Positive\", \"Neutral\", \"Negative\"]\n    colors = [\"#2ecc71\", \"#95a5a6\", \"#e74c3c\"]</p>\n<pre><code>reports_dir = Path(\"reports\")\nreports_dir.mkdir(parents=True, exist_ok=True)\nout_path = reports_dir / \"sentiment_pie.png\"\n\nfig, ax = plt.subplots(figsize=(5, 5), dpi=160)\nax.pie(counts, labels=labels, autopct=\"%1.1f%%\", startangle=140, colors=colors)\nax.axis(\"equal\")\nplt.title(\"Sentiment Distribution\")\nplt.tight_layout()\nfig.savefig(out_path)\nplt.close(fig)\nreturn str(out_path.resolve())</code></pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Configure Agents via YAML\n\nAgents are defined in YAML. Each has a role, goal, backstory, and tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# configs/agents.yaml\nsentiment_classifier:\n  role: Sentiment Classifier\n  goal: Label each feedback entry as positive, neutral, or negative\n  backstory: You are an expert in customer tone and sentiment. You read feedback text and assign accurate sentiment labels.\n  llm: gpt-4o-mini\n  tools:\n    - file_reader\n  verbose: true\n  allow_delegation: false\n\n<p>aggregator:\n  role: Data Aggregator\n  goal: Compute sentiment counts from classified feedback\n  backstory: You process structured data and produce accurate numeric summaries.\n  llm: gpt-4o-mini\n  tools:\n    - aggregate_sentiment\n  verbose: true\n  allow_delegation: false</p>\n<p>chart_maker:\n  role: Chart Generator\n  goal: Create a pie chart image showing sentiment distribution\n  backstory: You turn numbers into professional visuals.\n  llm: gpt-4o-mini\n  tools:\n    - make_sentiment_pie\n  verbose: true\n  allow_delegation: false</p>\n<p>report_writer:\n  role: Report Writer\n  goal: Assemble a Markdown report with table and chart\n  backstory: You synthesize insights and visuals into clear reports for stakeholders.\n  llm: gpt-4o-mini\n  tools: []\n  verbose: true\n  allow_delegation: false"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Configure Tasks via YAML\n\nTasks define what each agent does. You wire outputs between them using \\`context\\` to enforce order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# configs/tasks.yaml\nclassify_feedback:\n  description: |\n    Read the customer_feedback.csv file using the file_reader tool.\n    For each row, classify sentiment of the feedback_text field as Positive, Neutral, or Negative.\n    Output JSONL with id, feedback_text, sentiment per feedback entry.\n  agent: sentiment_classifier\n  expected_output: JSONL with id, feedback_text, and sentiment\n\n<p>aggregate_counts:\n  description: |\n    Take the JSONL output from classify_feedback.\n    Use the aggregate_sentiment tool to compute total counts for positive, neutral, and negative.\n    Return a JSON object with keys: positive, neutral, negative.\n  agent: aggregator\n  expected_output: JSON object with sentiment counts.\n  context:\n    - classify_feedback</p>\n<p>generate_chart:\n  description: |\n    Take the summary JSON from aggregate_counts.\n    Use make_sentiment_pie tool to generate a pie chart PNG.\n    Return the absolute file path to the generated chart image.\n  agent: chart_maker\n  expected_output: Absolute path to sentiment_pie.png.\n  context:\n    - aggregate_counts</p>\n<p>write_report:\n  description: |\n    Using sentiment counts (from aggregate_counts) and chart path (from generate_chart),\n    write a Markdown report that includes:\n    - Summary of total feedback entries and sentiment breakdown.\n    - Table of positive, neutral, negative counts.\n    - Embedded image: <img src=\"reports/sentiment_pie.png\" alt=\"Sentiment Distribution\">\n    - Brief insights and recommendations based on sentiment distribution.\n    Return the complete Markdown content.\n  agent: report_writer\n  expected_output: Complete Markdown report with table, chart, and insights.\n  context:\n    - aggregate_counts\n    - generate_chart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Instantiate Agents, Tasks \\& Crew"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\nfrom pathlib import Path\nimport yaml\nfrom dotenv import load_dotenv, find_dotenv\nfrom crewai import Agent, Task, Crew\nfrom tools import make_file_reader, aggregate_sentiment, make_sentiment_pie\n\n_ = load_dotenv(find_dotenv())\n\n# Paths\nROOT = Path.cwd()\nDATA_DIR = ROOT / \"data\"\nCONFIGS_DIR = ROOT / \"configs\"\nREPORTS_DIR = ROOT / \"reports\"\n\ncsv_path = DATA_DIR / \"customer_feedback.csv\"\n\n# Build tools\ntools_registry = {\n    \"file_reader\": make_file_reader(str(csv_path)),\n    \"aggregate_sentiment\": aggregate_sentiment,\n    \"make_sentiment_pie\": make_sentiment_pie,\n}\n\n# Load YAML configs\ndef load_yaml(path: Path):\n    if not path.exists():\n        raise FileNotFoundError(f\"Missing config: {path}\")\n    import yaml\n    return yaml.safe_load(path.read_text())\n\nagents_cfg = load_yaml(CONFIGS_DIR / \"agents.yaml\")\ntasks_cfg = load_yaml(CONFIGS_DIR / \"tasks.yaml\")\n\n# Instantiate agents\nagents = {}\nfor name, spec in agents_cfg.items():\n    agent = Agent(\n        role=spec[\"role\"],\n        goal=spec[\"goal\"],\n        backstory=spec.get(\"backstory\", \"\"),\n        llm=spec.get(\"llm\"),\n        tools=[tools_registry[t] for t in spec.get(\"tools\", [])],\n        verbose=spec.get(\"verbose\", False),\n        allow_delegation=spec.get(\"allow_delegation\", False),\n    )\n    agents[name] = agent\n\n# Instantiate tasks\ntasks = {}\nfor name, spec in tasks_cfg.items():\n    task = Task(\n        description=spec[\"description\"],\n        expected_output=spec[\"expected_output\"],\n        agent=agents[spec[\"agent\"]],\n    )\n    # assign context if provided\n    if \"context\" in spec:\n        task.context = [tasks[c] for c in spec[\"context\"]]\n    tasks[name] = task\n\n# Assemble Crew\ncrew = Crew(\n    agents=list(agents.values()),\n    tasks=list(tasks.values()),\n    process=Crew.Process.sequential,\n    verbose=True,\n)\n\nprint(\"Starting pipeline...\")\nfinal_report = crew.kickoff()\n\n# Save outputs\nREPORTS_DIR.mkdir(parents=True, exist_ok=True)\n(report_path := REPORTS_DIR / \"customer_feedback_report.md\").write_text(final_report, encoding=\"utf-8\")\nprint(f\"Report saved at {report_path.resolve()}\")\n\nchart_path = REPORTS_DIR / \"sentiment_pie.png\"\nif chart_path.exists():\n    print(f\"Chart saved at {chart_path.resolve()}\")\nelse:\n    print(\"Warning: Chart not found. Check tool execution logs.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Design Decisions\n\n**Deterministic aggregation:** Asking an LLM to compute counts risks hallucination or errors. The Python tool using pandas produces accurate totals every time.\n\n**Sequential execution:** You depend on prior outputs: classify before aggregating, chart before reporting. Sequential tasks keep the process simple and easy to debug.\n\n**YAML for configuration:** Defining agents and tasks in YAML makes the system maintainable. You can swap models, adjust prompts, or add agents without touching orchestration code.\n\n**Single\\-responsibility tools:** Each tool does one thing. That lets you test, reuse, or replace parts independently.\n\n## Conclusion\n\nYou‚Äôve built a complete Customer Feedback Analyst using CrewAI. You defined agents in YAML. You wired tasks with clear context dependencies. You attached tools for reading files, aggregating data, and charting. You ran the system end to end to produce a Markdown report and PNG visualization.\n\nThis architecture is reusable. Swap in a different CSV. Adjust the classifier prompt. Add agents for deeper analysis. You now have a template for multi\\-agent pipelines that coordinate specialized roles to deliver structured, validated outputs.\n\n**Next steps:**\n\n* Add schema validation for JSONL outputs using Pydantic. That helps catch malformed data early.\n* Implement chunking for large CSVs to avoid context length limits.\n* Add observability: log token usage, task timings, and tool calls for performance and cost tracking.\n* Explore parallel task execution for independent steps to reduce latency.\n* Consider deploying the pipeline as an API or scheduled job for continuous feedback analysis.\n\n---\n\n### References\n\n* Building Multi\\-Agent AI Systems: A Practical Guide with CrewAI. The GenAI Revolution. ([thegenairevolution.com](https://thegenairevolution.com/building-multi-agent-ai-systems-a-practical-guide-with-crewai/))"
      ]
    }
  ],
  "metadata": {
    "title": "How to Build Multi-Agent AI Systems with CrewAI, Step by Step",
    "description": "Design scalable multi-agent AI systems with CrewAI using YAML configs, task delegation, tools, and training‚Äîthen build a Customer Feedback Analyst.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}