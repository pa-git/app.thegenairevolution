{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** How to Build CrewAI Tools with Decorators, BaseTool, and Payloads\n\n**Description:** Choose the right CrewAI toolsâ€”decorators, BaseTool, or payloadâ€”validate structured inputs with Pydantic, and ship reliable agent integrations faster with confidence.\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CrewAI agents need tools to interact with external systems, validate data, and execute business logic. Without tools, agents can only generate text. With tools, they can log events, call APIs, enforce schemas, and integrate with your production stack.\n\nThis guide shows you three patterns for building custom CrewAI tools: a simple function decorator for quick prototyping, a BaseTool subclass with Pydantic validation for production-grade type safety, and a payload-based tool for flexible, dynamic schemas. You'll finish with a fully runnable Colab notebook that demonstrates all three patterns end-to-end, ready to copy, paste, and execute.\n\n## Why Use CrewAI for This Problem\n\nCrewAI's tool system is designed for agent-driven workflows where you need automatic tool discovery, schema enforcement, and iterative development. Compared to alternatives:\n\n- **OpenAI function calling**: Requires manual JSON Schema definitions and separate validation logic. CrewAI integrates Pydantic schemas directly into tools, reducing boilerplate.\n- **LangChain Tools**: Similar decorator pattern, but CrewAI's BaseTool subclass offers tighter integration with agent state and crew orchestration, making it easier to manage multi-agent workflows.\n- **Direct JSON Schema interfaces**: More flexible but error-prone. CrewAI enforces schemas at the tool level, catching errors before they reach your business logic.\n\nFor builders who want to move fast, validate inputs automatically, and scale to multi-agent systems, CrewAI's tool patterns offer a practical balance of simplicity and robustness.\n\n## Core Concepts for This Use Case\n\n**Tool**: A function or class that an agent can call. Tools are registered with agents and discovered automatically during task execution.\n\n**@tool decorator**: Wraps a Python function into a CrewAI tool. Best for simple, stateless operations with basic type hints.\n\n**BaseTool subclass**: A class-based tool with Pydantic schema validation via `args_schema`. Use this for production workflows where you need strict input validation, internal state, or business rule enforcement.\n\n**Payload tool**: A tool that accepts a JSON string payload. Useful when input schemas vary across contexts or when you need to pass complex, nested data structures.\n\n**args_schema**: A Pydantic `BaseModel` that defines the expected input structure for a BaseTool. CrewAI validates inputs against this schema before calling the tool's `_run` method.\n\n## Setup\n\nInstall the required dependencies. We use `crewai` for the agent framework, `crewai-tools` for stable tool imports, and `pydantic` for schema validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q crewai crewai-tools pydantic~=2.8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import the core classes and set up your API key. If running in Colab, use the userdata API to load secrets securely. Otherwise, use a runtime prompt fallback."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\nimport json\nfrom typing import Type\nfrom getpass import getpass\nfrom crewai import Agent, Task, Crew\nfrom crewai_tools import tool, BaseTool\nfrom pydantic import BaseModel, Field, ValidationError\n\n# Load API key from environment or prompt at runtime\nif not os.getenv(\"OPENAI_API_KEY\"):\n    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OPENAI_API_KEY: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you're running in Google Colab and have stored your API key in Colab Secrets, use this block instead to load it automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import userdata\nfrom google.colab.userdata import SecretNotFoundError\n\nkeys = [\"OPENAI_API_KEY\"]\nmissing = []\nfor k in keys:\n    value = None\n    try:\n        value = userdata.get(k)\n    except SecretNotFoundError:\n        pass\n    os.environ[k] = value if value is not None else \"\"\n    if not os.environ[k]:\n        missing.append(k)\n\nif missing:\n    raise EnvironmentError(f\"Missing keys: {', '.join(missing)}. Add them in Colab Settings, Secrets.\")\n\nprint(\"All keys loaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using the Tool in Practice\n\n### Approach 1: Simple Function Tool with @tool Decorator\n\nThe `@tool` decorator is the fastest way to turn a Python function into a CrewAI tool. Use it for quick prototypes or stateless operations where you don't need complex validation.\n\nDefine a function that logs a user intent. The function signature becomes the tool's input schema, and the docstring becomes the tool's description."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool(\"user_intent_logger\")\ndef user_intent_logger(user_name: str, intent: str, is_premium_user: bool) -> str:\n    \"\"\"\n    Log a user intent with basic parameters.\n    \n    Args:\n        user_name (str): The display name of the user.\n        intent (str): The action the user wants to perform.\n        is_premium_user (bool): Whether the user is on a premium plan.\n    \n    Returns:\n        str: JSON string with status and a synthetic log_id.\n    \"\"\"\n    log_event = {\n        \"user_name\": user_name,\n        \"intent\": intent,\n        \"is_premium_user\": is_premium_user,\n    }\n    print(f\"[user_intent_logger] Logged event: {log_event}\")\n    response = {\"status\": \"ok\", \"log_id\": f\"{user_name.lower()}-{intent}-001\"}\n    return json.dumps(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create an agent that uses the tool. The agent will automatically discover the tool and call it when the task requires logging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "simple_agent = Agent(\n    role=\"Support Analyst\",\n    goal=\"Understand user intent and log it using provided tools\",\n    backstory=\"You review user requests and ensure their intent is captured for analytics\",\n    tools=[user_intent_logger],\n    model=\"gpt-4o-mini\",\n    verbose=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a task that instructs the agent to call the logger tool with explicit parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "simple_task = Task(\n    description=(\n        \"A user named Alice wants to cancel her plan. \"\n        \"Call the user_intent_logger tool with user_name='Alice', intent='cancel', is_premium_user=True. \"\n        \"Return only the JSON from the tool output.\"\n    ),\n    expected_output=\"A JSON string with status and log_id fields.\",\n    agent=simple_agent,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the crew to execute the task. The agent will call the tool and return the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "simple_crew = Crew(\n    agents=[simple_agent],\n    tasks=[simple_task],\n    verbose=True,\n)\n\nprint(\"=== Running Approach 1: Decorator tool ===\")\nresult_1 = simple_crew.kickoff()\nprint(\"Crew result:\", result_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Approach 2: BaseTool Subclass with Pydantic Validation\n\nFor production workflows, use a `BaseTool` subclass with a Pydantic schema. This enforces strict input validation, supports internal state, and lets you add business rules.\n\nDefine a Pydantic schema for the tool's inputs. This schema will be validated automatically before the tool runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class IntentInput(BaseModel):\n    \"\"\"\n    Pydantic schema for user intent logging.\n    \n    Args:\n        user_name (str): End user display name (min 1 character).\n        intent (str): Action the user wants to perform (min 2 characters).\n        is_premium_user (bool): True if the user is on a premium plan.\n    \"\"\"\n    user_name: str = Field(..., min_length=1, description=\"End user display name\")\n    intent: str = Field(..., min_length=2, description=\"Action the user wants to perform\")\n    is_premium_user: bool = Field(..., description=\"True if the user is on a premium plan\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implement a `BaseTool` subclass that uses the schema. The `_run` method contains your business logic and is called only after validation succeeds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class UserIntentLoggerTool(BaseTool):\n    \"\"\"\n    CrewAI BaseTool for validated user intent logging.\n    \n    Attributes:\n        name (str): Tool name for agent discovery.\n        description (str): Tool description for agent context.\n        args_schema (Type[BaseModel]): Pydantic schema for input validation.\n    \"\"\"\n    name: str = \"user_intent_logger_validated\"\n    description: str = (\n        \"Logs validated user intents to the analytics pipeline. \"\n        \"Requires user_name, intent, and is_premium_user.\"\n    )\n    args_schema: Type[BaseModel] = IntentInput\n\n    def __init__(self):\n        super().__init__()\n        self._log_counter = 0\n\n    def _run(self, user_name: str, intent: str, is_premium_user: bool) -> str:\n        \"\"\"\n        Log a validated user intent with business rule enforcement.\n        \n        Args:\n            user_name (str): The display name of the user.\n            intent (str): The action the user wants to perform.\n            is_premium_user (bool): Whether the user is on a premium plan.\n        \n        Returns:\n            str: JSON string with status and log_id.\n        \n        Raises:\n            ValueError: If intent is not in the allowed set.\n        \"\"\"\n        if intent.lower() not in {\"cancel\", \"upgrade\", \"downgrade\", \"support\"}:\n            raise ValueError(\"intent must be one of cancel, upgrade, downgrade, support\")\n        self._log_counter += 1\n        log_id = f\"{user_name.lower()}-{intent}-{self._log_counter:03d}\"\n        event = {\n            \"user_name\": user_name,\n            \"intent\": intent.lower(),\n            \"is_premium_user\": is_premium_user,\n            \"log_id\": log_id,\n        }\n        print(f\"[user_intent_logger_validated] Logged event: {event}\")\n        return json.dumps({\"status\": \"ok\", \"log_id\": log_id})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instantiate the tool and wire it into an agent. The agent will use the validated tool for all logging tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "validated_tool = UserIntentLoggerTool()\n\nvalidated_agent = Agent(\n    role=\"Support Analyst\",\n    goal=\"Log validated user intents with strict schema and business rules\",\n    backstory=\"You ensure data quality by using validated tools\",\n    tools=[validated_tool],\n    model=\"gpt-4o-mini\",\n    verbose=True,\n)\n\nvalidated_task = Task(\n    description=(\n        \"A user named Bob wants to upgrade his plan. \"\n        \"Call the user_intent_logger_validated tool with user_name='Bob', intent='upgrade', is_premium_user=False. \"\n        \"Return only the JSON from the tool output.\"\n    ),\n    expected_output=\"A JSON string with status and log_id fields.\",\n    agent=validated_agent,\n)\n\nvalidated_crew = Crew(\n    agents=[validated_agent],\n    tasks=[validated_task],\n    verbose=True,\n)\n\nprint(\"=== Running Approach 2: BaseTool with Pydantic ===\")\nresult_2 = validated_crew.kickoff()\nprint(\"Crew result:\", result_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test validation failure by passing an invalid intent. The tool will raise a `ValueError` before executing any business logic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "invalid_task = Task(\n    description=(\n        \"A user named Carol wants a refund immediately. \"\n        \"Call the user_intent_logger_validated tool with user_name='Carol', intent='refund', is_premium_user=True. \"\n        \"Return only the JSON from the tool output.\"\n    ),\n    expected_output=\"A JSON string with status and log_id fields.\",\n    agent=validated_agent,\n)\n\ninvalid_crew = Crew(\n    agents=[validated_agent],\n    tasks=[invalid_task],\n    verbose=True,\n)\n\nprint(\"=== Running Approach 2b: Expect validation failure ===\")\ntry:\n    invalid_crew.kickoff()\nexcept Exception as e:\n    print(\"Caught error as expected:\", repr(e))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Approach 3: Payload-Based Tool for Flexible Schemas\n\nWhen input schemas vary across contexts or you need to pass complex, nested data, use a payload-based tool that accepts a JSON string.\n\nDefine a tool that parses and validates a JSON payload. This tool checks for required keys and types, then logs the event."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool(\"payload_intent_logger\")\ndef payload_intent_logger(payload: str) -> str:\n    \"\"\"\n    Log a user intent from a JSON string payload.\n    \n    Args:\n        payload (str): JSON string with required keys user_name (str), intent (str).\n            Optional keys: is_premium_user (bool), timestamp (str ISO), context (dict).\n    \n    Returns:\n        str: JSON string with status and log_id.\n    \n    Raises:\n        ValueError: If payload is not valid JSON or required keys are missing/invalid.\n    \"\"\"\n    try:\n        data = json.loads(payload)\n    except json.JSONDecodeError as e:\n        raise ValueError(f\"Invalid JSON payload. Error: {e}\")\n\n    for key in [\"user_name\", \"intent\"]:\n        if key not in data or not isinstance(data[key], str) or not data[key]:\n            raise ValueError(f\"Missing or invalid required key: {key}\")\n\n    if \"is_premium_user\" in data and not isinstance(data[\"is_premium_user\"], bool):\n        raise ValueError(\"is_premium_user must be a boolean\")\n\n    user_name = data[\"user_name\"]\n    intent = data[\"intent\"].lower()\n    is_premium_user = data.get(\"is_premium_user\", False)\n    log_id = f\"{user_name.lower()}-{intent}-p1\"\n\n    print(f\"[payload_intent_logger] Logged payload: {data}\")\n    return json.dumps({\"status\": \"ok\", \"log_id\": log_id})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create an agent and task for the payload-based tool. The agent will construct a JSON string and pass it to the tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "payload_agent = Agent(\n    role=\"Support Analyst\",\n    goal=\"Construct valid JSON payloads and log them via payload_intent_logger\",\n    backstory=\"You prefer flexible payloads when fields vary across contexts\",\n    tools=[payload_intent_logger],\n    model=\"gpt-4o-mini\",\n    verbose=True,\n)\n\npayload_task = Task(\n    description=(\n        \"Construct a strict JSON string with required keys user_name and intent. \"\n        \"Optional key is_premium_user may be included as a boolean. \"\n        \"Then call payload_intent_logger(payload=<the JSON string>) for user_name='Dana', intent='downgrade', is_premium_user=false. \"\n        \"Return only the JSON from the tool output.\"\n    ),\n    expected_output=\"A JSON string with status and log_id fields.\",\n    agent=payload_agent,\n)\n\npayload_crew = Crew(\n    agents=[payload_agent],\n    tasks=[payload_task],\n    verbose=True,\n)\n\nprint(\"=== Running Approach 3: Payload tool ===\")\nresult_3 = payload_crew.kickoff()\nprint(\"Crew result:\", result_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run and Evaluate\n\nValidate that all three approaches produce the expected JSON output with `status` and `log_id` fields."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ensure_json_ok(output: str) -> bool:\n    \"\"\"\n    Assert that the output is valid JSON with required fields.\n    \n    Args:\n        output (str): Output string from a tool.\n    \n    Returns:\n        bool: True if output is valid and contains required fields.\n    \n    Raises:\n        AssertionError: If output is not valid JSON or missing required fields.\n    \"\"\"\n    try:\n        data = json.loads(output)\n    except Exception as e:\n        raise AssertionError(f\"Output is not valid JSON. Error: {e}\")\n    assert \"status\" in data and data[\"status\"] == \"ok\", \"Missing or bad status\"\n    assert \"log_id\" in data, \"Missing log_id\"\n    return True\n\nprint(\"=== Validating Approach 1 output ===\")\nassert ensure_json_ok(result_1), \"Approach 1 output invalid\"\n\nprint(\"=== Validating Approach 2 output ===\")\nassert ensure_json_ok(result_2), \"Approach 2 output invalid\"\n\nprint(\"=== Validating Approach 3 output ===\")\nassert ensure_json_ok(result_3), \"Approach 3 output invalid\"\n\nprint(\"All validations passed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test edge cases to confirm validation behavior. For the BaseTool, pass an empty `user_name` to trigger a Pydantic validation error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "edge_task = Task(\n    description=(\n        \"Call the user_intent_logger_validated tool with user_name='', intent='support', is_premium_user=True. \"\n        \"Return the tool output.\"\n    ),\n    expected_output=\"A JSON string with status and log_id fields.\",\n    agent=validated_agent,\n)\nedge_crew = Crew(agents=[validated_agent], tasks=[edge_task], verbose=True)\n\nprint(\"=== BaseTool invalid input: Expect Pydantic error ===\")\ntry:\n    edge_crew.kickoff()\nexcept Exception as e:\n    print(\"Caught error as expected:\", repr(e))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test the payload tool with malformed JSON to confirm error handling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bad_payload_task = Task(\n    description=(\n        \"Call payload_intent_logger with payload set to this invalid JSON string exactly: \"\n        \"{user_name: Dana, intent: downgrade} \"\n        \"Return the tool output.\"\n    ),\n    expected_output=\"Tool raises ValueError due to invalid JSON.\",\n    agent=payload_agent,\n)\n\nbad_payload_crew = Crew(\n    agents=[payload_agent],\n    tasks=[bad_payload_task],\n    verbose=True,\n)\n\nprint(\"=== Payload tool invalid JSON: Expect failure ===\")\ntry:\n    bad_payload_crew.kickoff()\nexcept Exception as e:\n    print(\"Caught error as expected:\", repr(e))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n\nYou now have three production-ready patterns for building custom CrewAI tools. Use the `@tool` decorator for quick prototypes, `BaseTool` with Pydantic for strict validation and business rules, and payload-based tools for flexible, dynamic schemas. All three patterns are runnable in Colab and ready to integrate into your agent workflows.\n\nNext steps: Extend the BaseTool pattern to call external APIs, add structured logging with timestamps and trace IDs, or combine multiple tools in a single crew to build multi-step workflows. For advanced validation, explore Pydantic's custom validators and field constraints to enforce domain-specific rules at the schema level."
      ]
    }
  ],
  "metadata": {
    "title": "How to Build CrewAI Tools with Decorators, BaseTool, and Payloads",
    "description": "Choose the right CrewAI toolsâ€”decorators, BaseTool, or payloadâ€”validate structured inputs with Pydantic, and ship reliable agent integrations faster with confidence.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}