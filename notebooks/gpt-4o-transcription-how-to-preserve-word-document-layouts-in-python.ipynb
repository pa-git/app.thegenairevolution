{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** GPT-4o transcription: How to Preserve Word Document Layouts in Python\n\n**Description:** Preserve Word layouts, tables, and media with Python GPT-4o hybrid workflow; combine text extraction and page images for accurate transcription.\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why This Approach Works\n\nMost DOCX-to-Markdown converters rely on embedded XML or heuristics that fail when documents use complex layouts, tables, or custom styles. This pipeline combines three complementary tools to preserve structure:\n\n- **LibreOffice** converts DOCX to PDF, freezing the layout into a stable format.\n- **Poppler and PyMuPDF** extract both rendered images and embedded text from the PDF.\n- **GPT-4o** uses both the text and the image to reconstruct Markdown that respects visual hierarchy, tables, and formatting.\n\nBy the end of this guide, you'll have a Colab-ready notebook that takes any DOCX file and outputs per-page Markdown files plus a merged document.\n\n## How It Works (High-Level Overview)\n\nThe pipeline runs in four stages:\n\n1. **DOCX â†’ PDF**: LibreOffice converts the DOCX to PDF in headless mode, preserving layout.\n2. **PDF â†’ Images**: Poppler renders each page as a high-DPI image.\n3. **PDF â†’ Text**: PyMuPDF extracts embedded text per page.\n4. **Multimodal Transcription**: GPT-4o receives both the text and the image for each page and outputs structured Markdown.\n\nThis hybrid approach ensures that even when text extraction is incomplete or out of order, the model can infer structure from the visual layout.\n\n## Setup & Installation\n\nRun this cell first to install system dependencies and Python packages in Colab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!apt-get update -qq\n!apt-get install -y libreoffice poppler-utils\n!pip install pdf2image PyMuPDF pillow openai python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, verify that LibreOffice and Poppler are available:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!soffice --headless --version\n!pdftoppm -v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If both commands return version information, you're ready to proceed.\n\nNow, securely load your OpenAI API key from Colab userdata:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\nfrom google.colab import userdata\nfrom google.colab.userdata import SecretNotFoundError\n\nkeys = [\"OPENAI_API_KEY\"]\nmissing = []\nfor k in keys:\n    value = None\n    try:\n        value = userdata.get(k)\n    except SecretNotFoundError:\n        pass\n\n    os.environ[k] = value if value is not None else \"\"\n\n    if not os.environ[k]:\n        missing.append(k)\n\nif missing:\n    raise EnvironmentError(f\"Missing keys: {', '.join(missing)}. Add them in Colab â†’ Settings â†’ Secrets.\")\n\nprint(\"All keys loaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, initialize libraries and constants:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\nimport io\nimport base64\nimport subprocess\nimport logging\nfrom pathlib import Path\nfrom typing import List, Optional\n\nfrom openai import OpenAI\nfrom pdf2image import convert_from_path\nimport fitz\nfrom PIL import Image\n\nlogging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\n\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nif not OPENAI_API_KEY:\n    logging.error(\"OPENAI_API_KEY is not set.\")\n    sys.exit(1)\n\nclient = OpenAI()\n\nLIBREOFFICE_BIN = os.getenv(\"LIBREOFFICE_BIN\", \"soffice\")\nPOPPLER_PATH = os.getenv(\"POPPLER_PATH\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step-by-Step Implementation\n\n### Step 1: Convert DOCX to PDF\n\nThis function calls LibreOffice in headless mode to convert the DOCX file to PDF. It validates that the input exists, runs the conversion, and checks that the output PDF was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def docx_to_pdf(docx_path: Path, out_dir: Optional[Path] = None) -> Path:\n    docx_path = Path(docx_path).resolve()\n    if not docx_path.exists():\n        raise FileNotFoundError(f\"Input DOCX not found: {docx_path}\")\n\n    out_dir = Path(out_dir or docx_path.parent).resolve()\n    out_dir.mkdir(parents=True, exist_ok=True)\n\n    cmd = [\n        LIBREOFFICE_BIN,\n        \"--headless\",\n        \"--convert-to\", \"pdf\",\n        \"--outdir\", str(out_dir),\n        str(docx_path),\n    ]\n    try:\n        result = subprocess.run(\n            cmd, capture_output=True, text=True, check=False\n        )\n    except FileNotFoundError as e:\n        raise RuntimeError(\n            \"LibreOffice not found. Install LibreOffice and ensure 'soffice' is on PATH.\"\n        ) from e\n\n    if result.returncode != 0:\n        logging.error(f\"LibreOffice stderr: {result.stderr.strip()}\")\n        raise RuntimeError(\n            f\"LibreOffice conversion failed. Code {result.returncode}. \"\n            f\"stderr: {result.stderr.strip()}\"\n        )\n\n    pdf_name = docx_path.with_suffix(\".pdf\").name\n    pdf_path = out_dir / pdf_name\n    if not pdf_path.exists():\n        raise RuntimeError(\"Expected PDF not created. Check LibreOffice logs and file permissions.\")\n    logging.info(f\"Converted DOCX to PDF: {pdf_path}\")\n    return pdf_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test the conversion with a sample DOCX file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_docx = Path(\"sample.docx\")\npdf_path = docx_to_pdf(sample_docx)\nprint(f\"PDF created at: {pdf_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Render PDF Pages as Images\n\nThis function uses Poppler to render each page of the PDF as a high-resolution image. Higher DPI improves OCR accuracy but increases memory usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pdf_to_images(pdf_path: Path, dpi: int = 300) -> List[Image.Image]:\n    pdf_path = Path(pdf_path).resolve()\n    if not pdf_path.exists():\n        raise FileNotFoundError(f\"PDF not found: {pdf_path}\")\n\n    images = convert_from_path(\n        str(pdf_path),\n        dpi=dpi,\n        poppler_path=POPPLER_PATH if POPPLER_PATH else None\n    )\n    logging.info(f\"Rendered {len(images)} pages from PDF at {dpi} DPI.\")\n    return images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Render the PDF and preview the first page:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "images = pdf_to_images(pdf_path, dpi=300)\nprint(f\"Rendered {len(images)} pages.\")\nimages[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Extract Embedded Text Per Page\n\nThis function uses PyMuPDF to extract text from each page. The text is in reading order but may be incomplete or out of sequence for complex layouts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_text_per_page(pdf_path: Path) -> List[str]:\n    pdf_path = Path(pdf_path).resolve()\n    if not pdf_path.exists():\n        raise FileNotFoundError(f\"PDF not found: {pdf_path}\")\n\n    texts: List[str] = []\n    with fitz.open(str(pdf_path)) as doc:\n        for page in doc:\n            t = page.get_text(\"text\")\n            texts.append(t.strip())\n    logging.info(f\"Extracted text from {len(texts)} PDF pages.\")\n    return texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract text and print the first 20 lines:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "texts = extract_text_per_page(pdf_path)\nprint(\"\\n\".join(texts[0].split(\"\\n\")[:20]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Convert Images to Data URLs\n\nThis helper function converts a PIL Image to a PNG data URL for use in GPT-4o multimodal prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pil_image_to_data_url(img: Image.Image, png_compress_level: int = 6) -> str:\n    buf = io.BytesIO()\n    img.save(buf, format=\"PNG\", compress_level=png_compress_level)\n    b64 = base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n    return f\"data:image/png;base64,{b64}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5: Define the System Prompt\n\nThis prompt instructs GPT-4o to produce clean Markdown that preserves structure, including headings, lists, tables, and figure placeholders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = \"\"\"You are a meticulous document transcriber. Produce clean Markdown that preserves structure.\nRules:\n- Keep the original reading order.\n- Use #, ##, ### for headings that reflect visual hierarchy.\n- Preserve lists, bold, italics, and footnotes.\n- Reconstruct tables as Markdown tables with headers when present.\n- For images or figures, insert a placeholder like [Figure N: short caption] with concise alt text.\n- Include headers and footers only if they contain meaningful information.\n- Do not hallucinate content. If text is illegible or absent, write [Unclear].\n- Output only Markdown for the page, no extra commentary.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 6: Transcribe a Single Page with GPT-4o\n\nThis function sends both the extracted text and the rendered image to GPT-4o and returns structured Markdown for the page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def transcribe_page_with_gpt4o(page_text: str, page_image: Image.Image, temperature: float = 0.0) -> str:\n    image_url = pil_image_to_data_url(page_image)\n\n    user_content = [\n        {\"type\": \"text\", \"text\": \"Here is the exact text extracted from this page:\"},\n        {\"type\": \"text\", \"text\": page_text or \"[No embedded text extracted]\"},\n        {\"type\": \"text\", \"text\": \"Here is the rendered image of the same page to infer layout:\"},\n        {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n        {\"type\": \"text\", \"text\": \"Return structured Markdown for this single page only.\"},\n    ]\n\n    resp = client.chat.completions.create(\n        model=\"gpt-4o\",\n        temperature=temperature,\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": user_content},\n        ],\n    )\n    return resp.choices[0].message.content.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test transcription on the first page:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "md_page_1 = transcribe_page_with_gpt4o(texts[0], images[0])\nprint(md_page_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 7: Add Retry Logic for Rate Limits\n\nThis wrapper function retries the transcription call with exponential backoff if rate limits or transient errors occur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\nimport random\nfrom openai import APIError, RateLimitError\n\ndef safe_transcribe_page(page_text: str, page_image: Image.Image, max_retries: int = 5) -> str:\n    delay = 1.0\n    for attempt in range(1, max_retries + 1):\n        try:\n            return transcribe_page_with_gpt4o(page_text, page_image)\n        except RateLimitError as e:\n            logging.warning(f\"Rate limit error on attempt {attempt}: {e}\")\n            if attempt == max_retries:\n                raise\n            time.sleep(delay + random.random())\n            delay *= 2\n        except APIError as e:\n            status = getattr(e, \"status_code\", 500)\n            if 500 <= status < 600 and attempt < max_retries:\n                logging.warning(f\"API error (status {status}) on attempt {attempt}: {e}\")\n                time.sleep(delay + random.random())\n                delay *= 2\n                continue\n            raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 8: Orchestrate the Full Pipeline\n\nThis function coordinates all stages: convert DOCX to PDF, render images, extract text, and transcribe each page with GPT-4o."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def transcribe_docx(docx_path: Path, dpi: int = 300) -> List[str]:\n    pdf_path = docx_to_pdf(docx_path)\n    images = pdf_to_images(pdf_path, dpi=dpi)\n    texts = extract_text_per_page(pdf_path)\n\n    if len(images) != len(texts):\n        raise RuntimeError(\n            f\"Page count mismatch. images={len(images)} texts={len(texts)}\"\n        )\n\n    outputs: List[str] = []\n    for idx, (img, txt) in enumerate(zip(images, texts), start=1):\n        logging.info(f\"Transcribing page {idx}/{len(images)} ...\")\n        md = safe_transcribe_page(txt, img)\n        outputs.append(md)\n    return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the full pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "outputs = transcribe_docx(sample_docx, dpi=300)\nprint(f\"Transcribed {len(outputs)} pages.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 9: Write Outputs to Disk\n\nThis function writes each page's Markdown to a separate file and creates a merged document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def write_outputs(docx_path: Path, outputs: List[str], out_dir: Optional[Path] = None) -> Path:\n    base = Path(out_dir or docx_path.parent) / (docx_path.stem + \"_transcription\")\n    base.mkdir(parents=True, exist_ok=True)\n    merged = []\n    for i, md in enumerate(outputs, start=1):\n        p = base / f\"page_{i:04d}.md\"\n        p.write_text(md, encoding=\"utf-8\")\n        merged.append(f\"<!-- Page {i} -->\\n\\n{md}\\n\")\n    merged_path = base / \"full_document.md\"\n    merged_path.write_text(\"\\n\\n\".join(merged), encoding=\"utf-8\")\n    logging.info(f\"Wrote {len(outputs)} page files and merged Markdown to {base}\")\n    return base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Write the outputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "out_dir = write_outputs(sample_docx, outputs)\nprint(f\"Wrote transcription to {out_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run and Validate\n\nDisplay the first page image alongside its generated Markdown:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown\n\nprint(\"Original Page Image:\")\ndisplay(images[0])\nprint(\"\\nGenerated Markdown:\")\ndisplay(Markdown(outputs[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verify that page counts match and detect empty pages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert len(images) == len(texts) == len(outputs), \"Page count mismatch detected.\"\nempty_pages = [i+1 for i, txt in enumerate(texts) if not txt.strip()]\nif empty_pages:\n    print(f\"Warning: Empty text on pages {empty_pages}\")\nelse:\n    print(\"All pages contain text.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check for tables in the Markdown output:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "table_pages = [i+1 for i, md in enumerate(outputs) if \"|\" in md]\nif table_pages:\n    print(f\"Tables detected on pages: {table_pages}\")\nelse:\n    print(\"No tables detected. Verify if tables were expected.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n\nYou now have a working DOCX-to-Markdown pipeline that preserves layout, tables, and formatting. The hybrid approach combines LibreOffice for stable conversion, Poppler and PyMuPDF for dual extraction, and GPT-4o for intelligent reconstruction.\n\nTo extend this pipeline, consider adding hash-based caching to skip re-transcription of unchanged pages, or switch to `gpt-4o-mini` for faster, cheaper tests. You can also add image resizing to keep data URL payloads below API limits, or integrate a worker pool with bounded concurrency to parallelize transcription while respecting rate limits."
      ]
    }
  ],
  "metadata": {
    "title": "GPT-4o transcription: How to Preserve Word Document Layouts in Python",
    "description": "Preserve Word layouts, tables, and media with Python GPT-4o hybrid workflow; combine text extraction and page images for accurate transcription.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}