{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n\n**Title:** Prompt Library: How to Build a System That 10x Your Productivity\n\n**Description:** Build a prompt library to reuse winning ChatGPT prompts, cut time by 80%, strengthen AI workflows, and impress hiring managers.\n\n---\n\n*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What Problem Are We Solving?\n\nYou've written a prompt that works once, then fails on edge cases. You tweak it, test again, and lose track of what changed. A teammate asks for the \"latest version,\" and you paste from Slack. Three weeks later, outputs drift and no one knows why.\n\nThis happens because prompts are treated as disposable strings, leading to instruction drift and inconsistent output contracts.\n\nYou'll implement a minimal prompt schema with format contracts, variables, and delimiters, plus a lightweight eval loop to measure improvement.\n\n## What's Actually Happening Under the Hood\n\nWhen prompts lack structure, several failure modes emerge:\n\n- **Instruction dilution.** System rules and user input mix in a single block, causing the model to treat constraints as suggestions rather than hard boundaries.\n- **Context interference.** Without delimiters, the model cannot reliably distinguish between instructions, examples, and live input, leading to hallucinated or off-spec outputs.\n- **Unconstrained output shape.** No format contract means the model chooses its own structure, breaking downstream parsers and automation.\n- **No negative examples.** The model sees only success cases, so it doesn't learn what to avoid or how to handle malformed input.\n\nThe diagram below shows where ambiguity enters and how structure mitigates it:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\ngraph LR\n    A[System Instructions] --> B[Delimiters]\n    B --> C[User Input]\n    C --> D[Model Processing]\n    D --> E[Format Contract]\n    E --> F[Structured Output]\n    F --> G[Validation]\n    G -->|Pass| H[Downstream Use]\n    G -->|Fail| I[Reject & Log]\n```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to Fix It\n\n### Design a Minimal Prompt Schema\n\nA prompt schema defines the structure and contract for every prompt in your library. Each prompt should include:\n\n- **Role.** A single-sentence description of the model's task (e.g., \"You are a code reviewer\").\n- **Format contract.** The exact output shape (e.g., JSON with specific keys, markdown with headers, or plain text with line breaks).\n- **Variables.** Placeholders for dynamic input (e.g., `{code_snippet}`, `{user_query}`).\n- **Delimiters.** Clear markers separating system instructions from user input (e.g., triple backticks, XML tags, or `---`).\n\nStore each prompt as a versioned file with metadata (name, version, model, last updated).\n\n### Isolate System Instructions From User Input\n\nPlace system-level rules in a dedicated section, separate from user-provided content. This prevents the model from treating user input as additional instructions.\n\n**Before:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Write a product spec for {feature_name}. Include goals, user stories, and success metrics. {user_notes}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**After:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Role: You are a product manager writing a PRD.\nFormat: Return JSON with keys: goals, user_stories, success_metrics.\n---\nFeature: {feature_name}\nNotes: {user_notes}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Use Variables and Delimiters\n\nVariables make prompts reusable across inputs. Delimiters protect against injection and context bleed.\n\nWrap user input in triple backticks or XML tags:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Analyze the following code:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "{code_snippet}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Return a JSON object with keys: issues, suggestions, severity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This ensures the model treats `{code_snippet}` as data, not instructions.\n\n### Enforce Structured Outputs\n\nSpecify the exact output format in the system section. For JSON, list required keys and types. For markdown, define headers and sections.\n\nExample format contract:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Return JSON:\n{\n  \"summary\": \"string\",\n  \"action_items\": [\"string\"],\n  \"priority\": \"high | medium | low\"\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Validate the output with a JSON Schema validator. If validation fails, log the prompt version, input, and output for debugging.\n\n### Add Success Criteria and Constraints\n\nInclude 2â€“3 concrete success criteria and 1â€“2 constraints to anchor the model's behavior.\n\nSuccess criteria:\n- Summary must be under 100 words.\n- Action items must be specific and assignable.\n\nConstraints:\n- Do not fabricate data not present in the input.\n- If a required field is missing, return `{\"error\": \"missing_field\"}`.\n\n### Provide Positive and Negative Examples\n\nShow the model both correct and incorrect outputs. Negative examples teach boundary conditions.\n\nPositive example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Input: \"Add user authentication\"\nOutput: {\"goals\": [\"Secure user data\"], \"user_stories\": [\"As a user, I want to log in securely\"], \"success_metrics\": [\"Zero unauthorized access incidents\"]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Negative example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Input: \"Add user authentication\"\nBad Output: {\"goals\": \"Secure user data\"}\nWhy: goals must be an array, not a string."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Measure Impact With Baselines\n\nBefore adopting structure, capture a baseline. Run your current prompt on 10â€“20 representative inputs and record:\n\n- Output adherence (does it match the expected format?).\n- Factuality (does it fabricate information?).\n- Latency (how long does it take?).\n\nAfter applying structure, re-run the same inputs and compare. Track the delta in a simple spreadsheet or JSON log.\n\nMinimal eval set guidelines:\n- Include 3â€“5 typical cases.\n- Add 2â€“3 edge cases (e.g., missing fields, ambiguous input).\n- Map each case to a metric (adherence, factuality, latency).\n- Re-run evals after every prompt version change.\n\n## Key Takeaways\n\n- **Separate system and user sections.** Prevents instruction dilution.\n- **Use variables and delimiters.** Protects against injection and context bleed.\n- **Specify a format contract.** Ensures consistent, parseable outputs.\n- **Add success criteria and constraints.** Anchors model behavior.\n- **Provide negative examples.** Teaches boundary conditions.\n- **Measure with baselines.** Quantifies improvement and catches regressions.\n\n### When to Use This Pattern\n\n- Outputs drift across runs or users.\n- Downstream automation requires a consistent shape.\n- Reviewers need to audit prompt logic.\n- You're scaling prompts across a team or product.\n\n### Token Cost and Latency Considerations\n\nStructured prompts add tokens (delimiters, format contracts, examples). Keep scaffolds concise:\n- Limit examples to 1â€“2 per type (positive/negative).\n- Compress success criteria to essential bullets.\n- Use short delimiters (e.g., `---` instead of verbose XML).\n\nTrack token counts and latency in your eval logs. If costs spike, trim examples or move format contracts to function calling schemas.\n\n### Reproducibility in CI/CD\n\nPin prompt version and model version in automated tests. Artifact prompts and outputs for each test run. Store them in version control or an object store.\n\nChecklist:\n- Tag each prompt file with a semantic version (e.g., `v1.2.0`).\n- Log prompt name, version, model, input, and output in CI.\n- Compare outputs against expected results using JSON diff or string match.\n- Fail the build if adherence drops below a threshold.\n\n### Multi-Model Strategy\n\nIf you support multiple models, maintain a shared core prompt and model-specific overrides. Branch only when:\n- Token window differences require truncation.\n- Function calling or tool use differs.\n- Output formatting quirks emerge (e.g., one model ignores JSON instructions).\n\nStore overrides in separate files (e.g., `prompt_v1_gpt4.txt`, `prompt_v1_claude.txt`) and reference the shared core.\n\n### Logging for Debugging\n\nLog prompt name, version, input, and output for every production call. When outputs fail, query logs by prompt version to identify regressions. Tie logs to your \"Automate Capture From Chat Sessions\" workflow for incident review.\n\n### Safety and Compliance Redlines\n\nFor engineering tasks, define 2â€“3 concrete redlines:\n- Do not fabricate API endpoints or function signatures.\n- Validate PII mask status before returning user data.\n- If a required field is missing, return a validation error, not a guess.\n\nInclude these as constraints in the system section."
      ]
    }
  ],
  "metadata": {
    "title": "Prompt Library: How to Build a System That 10x Your Productivity",
    "description": "Build a prompt library to reuse winning ChatGPT prompts, cut time by 80%, strengthen AI workflows, and impress hiring managers.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}