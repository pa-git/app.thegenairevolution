{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RivMnrrPJU5D"
      },
      "source": [
        "# ðŸ““ The GenAI Revolution Cookbook\n",
        "\n",
        "**Title:** How to Build a Stateful AI Agent with LangGraph Step-by-Step\n",
        "\n",
        "**Description:** Build reliable, stateful AI agents with LangGraph using step-by-step patterns, visual debugging, and persistenceâ€”ready for tool use and production today.\n",
        "\n",
        "---\n",
        "\n",
        "*This jupyter notebook contains executable code examples. Run the cells below to try out the code yourself!*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0aXRCJAJU5F"
      },
      "source": [
        "When building AI agents that need to make decisions, call tools, and maintain context across multiple turns, orchestration becomes critical. LangGraph provides a structured way to define agent workflows as state machines, giving you fine-grained control over how your agent reasons, acts, and responds.\n",
        "\n",
        "In this tutorial, you'll build a travel assistant agent that helps users plan trips by calling external tools to fetch weather data and search for flights. You'll learn how to define a stateful graph, integrate tool-calling logic, and trace execution step-by-step. By the end, you'll have a working agent that can handle multi-turn conversations and coordinate multiple tools to deliver useful results.\n",
        "\n",
        "## Why This Approach Works\n",
        "\n",
        "LangGraph treats agent workflows as explicit graphs where each node represents a step (like calling the LLM or executing a tool) and edges define transitions. This makes complex agent behavior easier to reason about, debug, and extend compared to implicit loops or callback-based systems.\n",
        "\n",
        "Key benefits:\n",
        "\n",
        "- **Explicit state management** â€“ You define exactly what data flows between steps, making it easier to track context and debug issues.\n",
        "- **Composable logic** â€“ Each node is a function. You can test, swap, or extend individual components without rewriting the entire agent.\n",
        "- **Built-in tracing** â€“ LangGraph logs every state transition, so you can inspect what the agent did at each step and why.\n",
        "\n",
        "This approach is especially useful when your agent needs to call multiple tools, handle conditional logic, or maintain conversation history across turns.\n",
        "\n",
        "## High-Level Overview\n",
        "\n",
        "Here's how the system works:\n",
        "\n",
        "1. **User input** â€“ The user sends a message (e.g., \"Find me flights to Tokyo and check the weather\").\n",
        "2. **LLM reasoning** â€“ The agent calls the LLM, which decides whether to respond directly or invoke tools.\n",
        "3. **Tool execution** â€“ If tools are needed, the agent executes them (e.g., `search_flights`, `get_weather`) and collects results.\n",
        "4. **LLM synthesis** â€“ The agent sends tool results back to the LLM, which generates a final response.\n",
        "5. **Output** â€“ The user receives a natural language answer informed by real data.\n",
        "\n",
        "The graph has three main nodes:\n",
        "\n",
        "- **Agent node** â€“ Calls the LLM to decide next actions.\n",
        "- **Tool node** â€“ Executes requested tools and returns results.\n",
        "- **Conditional edge** â€“ Routes to tools if needed, or ends if the agent is done.\n",
        "\n",
        "## Setup & Installation\n",
        "\n",
        "This code runs in Google Colab or any Python 3.10+ environment. Install dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-Vw4yisJU5G"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langgraph langchain-openai langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gex2o6GgJU5H"
      },
      "source": [
        "Set your OpenAI API key:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5k3eG0rkJU5H"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jwYf31WJU5I"
      },
      "source": [
        "Replace `\"your-openai-api-key\"` with your actual key. For production, use environment variables or secret management tools instead of hardcoding keys.\n",
        "\n",
        "## Step 1: Define Tools\n",
        "\n",
        "Tools are Python functions decorated with `@tool`. The LLM can call these functions when it needs external data.\n",
        "\n",
        "This example defines two tools: one for searching flights and one for fetching weather. Both return mock data for demonstration purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tl9JA60XJU5I"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def search_flights(origin: str, destination: str, date: str) -> str:\n",
        "    \"\"\"Search for available flights between two cities on a given date.\"\"\"\n",
        "    return f\"Found 3 flights from {origin} to {destination} on {date}: Flight A ($450), Flight B ($520), Flight C ($610).\"\n",
        "\n",
        "@tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Get current weather information for a city.\"\"\"\n",
        "    return f\"Weather in {city}: 22Â°C, partly cloudy, light breeze.\"\n",
        "\n",
        "tools = [search_flights, get_weather]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wBpFcqtJU5I"
      },
      "source": [
        "In a real application, replace the return statements with API calls to services like Amadeus (flights) or OpenWeatherMap (weather).\n",
        "\n",
        "## Step 2: Bind Tools to the LLM\n",
        "\n",
        "The LLM needs to know which tools are available and how to call them. Use `.bind_tools()` to attach tool schemas to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fz_exhZiJU5J"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "model_with_tools = model.bind_tools(tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmiWAiYoJU5J"
      },
      "source": [
        "Now when you call `model_with_tools`, the LLM can decide to invoke `search_flights` or `get_weather` based on the user's request.\n",
        "\n",
        "## Step 3: Define the Agent State\n",
        "\n",
        "State is a dictionary that flows through the graph. It holds the conversation history and any other data you need to track."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXATOgitJU5J"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMEYDPkEJU5J"
      },
      "source": [
        "The `add_messages` annotation tells LangGraph to append new messages to the list rather than replacing it. This preserves conversation history across turns.\n",
        "\n",
        "## Step 4: Build the Agent Node\n",
        "\n",
        "The agent node calls the LLM with the current message history. The LLM returns either a text response or a request to call tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "or-TUwsBJU5J"
      },
      "outputs": [],
      "source": [
        "def call_agent(state: State):\n",
        "    \"\"\"Invoke the LLM with the current conversation state.\"\"\"\n",
        "    response = model_with_tools.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [response]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnyOwc7KJU5K"
      },
      "source": [
        "This function takes the state, passes `state[\"messages\"]` to the model, and returns the model's response wrapped in a dictionary so LangGraph can merge it back into the state.\n",
        "\n",
        "## Step 5: Build the Tool Node\n",
        "\n",
        "LangGraph provides a `ToolNode` that automatically executes any tools the LLM requested and formats the results as messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_o-_an43JU5K"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "tool_node = ToolNode(tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibS-CkOVJU5K"
      },
      "source": [
        "When the agent node returns a message with `tool_calls`, the graph routes to this node, which runs the tools and appends their outputs to the message list.\n",
        "\n",
        "## Step 6: Define Routing Logic\n",
        "\n",
        "After the agent node runs, the graph needs to decide: should it call tools, or is the agent done?\n",
        "\n",
        "This function checks if the last message contains tool calls. If yes, route to the tool node. If no, end the conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNuIlVZmJU5K"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import END\n",
        "\n",
        "def should_continue(state: State):\n",
        "    \"\"\"Determine whether to call tools or finish.\"\"\"\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    if last_message.tool_calls:\n",
        "        return \"tools\"\n",
        "    return END"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVoYsevJJU5K"
      },
      "source": [
        "## Step 7: Assemble the Graph\n",
        "\n",
        "Now combine the nodes and edges into a state graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XEJl_OXJU5K"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START\n",
        "\n",
        "workflow = StateGraph(State)\n",
        "\n",
        "workflow.add_node(\"agent\", call_agent)\n",
        "workflow.add_node(\"tools\", tool_node)\n",
        "\n",
        "workflow.add_edge(START, \"agent\")\n",
        "workflow.add_conditional_edges(\"agent\", should_continue, {\"tools\": \"tools\", END: END})\n",
        "workflow.add_edge(\"tools\", \"agent\")\n",
        "\n",
        "graph = workflow.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz7IQzGiJU5K"
      },
      "source": [
        "Here's what each line does:\n",
        "\n",
        "- `add_node(\"agent\", call_agent)` â€“ Registers the agent node.\n",
        "- `add_node(\"tools\", tool_node)` â€“ Registers the tool execution node.\n",
        "- `add_edge(START, \"agent\")` â€“ The graph always starts at the agent node.\n",
        "- `add_conditional_edges(\"agent\", should_continue, ...)` â€“ After the agent runs, route to tools or end based on `should_continue`.\n",
        "- `add_edge(\"tools\", \"agent\")` â€“ After tools run, return to the agent so it can synthesize results.\n",
        "\n",
        "## Step 8: Run the Agent\n",
        "\n",
        "Invoke the graph with a user message. The agent will decide which tools to call and return a final answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxlqxXt3JU5K"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "user_input = \"Find me flights from San Francisco to Tokyo on March 15th and tell me the weather in Tokyo.\"\n",
        "result = graph.invoke({\"messages\": [HumanMessage(content=user_input)]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "600-2sRVJU5L"
      },
      "source": [
        "The `result` dictionary contains the full message history, including the user's input, tool calls, tool results, and the agent's final response.\n",
        "\n",
        "## Step 9: Display Results and Trace\n",
        "\n",
        "To see the final answer and understand what happened at each step, print the last AI message and trace all messages.\n",
        "\n",
        "This helper function extracts the final AI response and prints a numbered trace showing each message type, content, and metadata like tool calls or tool names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Diqfcw1VJU5L"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import AIMessage, ToolMessage\n",
        "\n",
        "def print_message_trace(result):\n",
        "    final = [m for m in result[\"messages\"] if isinstance(m, AIMessage)][-1]\n",
        "    print(final.content)\n",
        "\n",
        "    print(\"\\nFull Trace:\")\n",
        "    for i, m in enumerate(result[\"messages\"], 1):\n",
        "        role = type(m).__name__\n",
        "        meta = \"\"\n",
        "        if isinstance(m, AIMessage) and getattr(m, \"tool_calls\", None):\n",
        "            meta = f\" tool_calls={m.tool_calls}\"\n",
        "        if isinstance(m, ToolMessage):\n",
        "            meta = f\" tool_name={m.name}\"\n",
        "        print(f\"{i:02d}. {role}: {m.content}{meta}\")\n",
        "\n",
        "print_message_trace(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8-ibTkhJU5L"
      },
      "source": [
        "Example output:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtOCTNwPJU5L"
      },
      "outputs": [],
      "source": [
        "I found 3 flights from San Francisco to Tokyo on March 15th: Flight A ($450), Flight B ($520), Flight C ($610). The weather in Tokyo is currently 22Â°C, partly cloudy with a light breeze.\n",
        "\n",
        "Full Trace:\n",
        "01. HumanMessage: Find me flights from San Francisco to Tokyo on March 15th and tell me the weather in Tokyo.\n",
        "02. AIMessage:  tool_calls=[{'name': 'search_flights', 'args': {'origin': 'San Francisco', 'destination': 'Tokyo', 'date': 'March 15th'}, 'id': 'call_abc123'}, {'name': 'get_weather', 'args': {'city': 'Tokyo'}, 'id': 'call_def456'}]\n",
        "03. ToolMessage: Found 3 flights from San Francisco to Tokyo on March 15th: Flight A ($450), Flight B ($520), Flight C ($610). tool_name=search_flights\n",
        "04. ToolMessage: Weather in Tokyo: 22Â°C, partly cloudy, light breeze. tool_name=get_weather\n",
        "05. AIMessage: I found 3 flights from San Francisco to Tokyo on March 15th: Flight A ($450), Flight B ($520), Flight C ($610). The weather in Tokyo is currently 22Â°C, partly cloudy with a light breeze."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cCTUQghJU5L"
      },
      "source": [
        "This trace shows the agent called both tools in parallel, received results, and synthesized a final answer.\n",
        "\n",
        "## Run and Validate\n",
        "\n",
        "Test the agent with different inputs to confirm it routes correctly:\n",
        "\n",
        "**Single tool call:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxkoQmlEJU5L"
      },
      "outputs": [],
      "source": [
        "result = graph.invoke({\"messages\": [HumanMessage(content=\"What's the weather in Paris?\")]})\n",
        "print_message_trace(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccb3av-vJU5L"
      },
      "source": [
        "**No tool call (direct answer):**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH3V621PJU5L"
      },
      "outputs": [],
      "source": [
        "result = graph.invoke({\"messages\": [HumanMessage(content=\"What is LangGraph?\")]})\n",
        "print_message_trace(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7I9asuQJU5L"
      },
      "source": [
        "**Multi-turn conversation:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsA_H4zwJU5L"
      },
      "outputs": [],
      "source": [
        "result = graph.invoke({\"messages\": [HumanMessage(content=\"Find flights to Berlin on April 10th.\")]})\n",
        "result = graph.invoke({\"messages\": result[\"messages\"] + [HumanMessage(content=\"What about the weather there?\")]})\n",
        "print_message_trace(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCHFm0RCJU5L"
      },
      "source": [
        "In the multi-turn example, the agent maintains context from the first turn and knows \"there\" refers to Berlin.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "You've built a stateful LangGraph agent that orchestrates tool calls and maintains conversation context. The key takeaways:\n",
        "\n",
        "- **State graphs make agent logic explicit** â€“ You control exactly when the LLM is called, when tools run, and how results flow back.\n",
        "- **Tool binding is straightforward** â€“ Decorate functions with `@tool` and bind them to the model. The LLM handles the rest.\n",
        "- **Tracing is built-in** â€“ Every message and tool call is logged, making debugging and optimization easier.\n",
        "\n",
        "For readers working on data extraction challenges, our guide on [building a structured data extraction pipeline with LLMs](/blog/44830763/structured-data-extraction-with-llms-how-to-build-a-pipeline-3) offers complementary strategies for handling unstructured inputs.\n",
        "\n",
        "If you encounter unexpected model behavior, subtle bugs often stem from tokenization issuesâ€”see our article on [tokenization pitfalls and invisible characters](/blog/44830763/tokenization-pitfalls-invisible-characters-that-break-prompts-and-rag-2) for actionable solutions.\n",
        "\n",
        "When scaling to long-context applications, be aware of memory limitations. Our analysis of [context rot and memory management in LLMs](/blog/44830763/context-rot-why-llms-forget-as-their-memory-grows-3) explains why models sometimes lose track of earlier information and how to mitigate it.\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- **Add real APIs** â€“ Replace mock data with live calls to flight search APIs (e.g., Amadeus) and weather services (e.g., OpenWeatherMap).\n",
        "- **Persist state** â€“ Use LangGraph's checkpointing to save conversation history to a database, enabling multi-session continuity.\n",
        "- **Add error handling** â€“ Wrap tool calls in try-except blocks and return user-friendly error messages when APIs fail.\n",
        "- **Deploy as an API** â€“ Serve the graph via FastAPI or Flask so users can interact with it through a web interface or chat app."
      ]
    }
  ],
  "metadata": {
    "title": "How to Build a Stateful AI Agent with LangGraph Step-by-Step",
    "description": "Build reliable, stateful AI agents with LangGraph using step-by-step patterns, visual debugging, and persistenceâ€”ready for tool use and production today.",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}